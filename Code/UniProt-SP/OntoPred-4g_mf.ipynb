{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a056c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 26 11:55:31 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   48C    P0    58W / 300W |    486MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   49C    P0    56W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A    271406      C   /usr/bin/python3                  483MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86add81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb10a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 11:55:04.976545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 11:55:05.161534: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3454861046542519650\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 32479117312\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7847603573342777498\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 11:55:09.334325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 11:55:12.213472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 30974 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8be3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb404ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-1_OHJFk-h9O8eTg5a7lH4QFk4_LFHMG\n",
      "To: /home/191it109/project/home/molecular_function.csv\n",
      "100%|██████████████████████████████████████| 37.9M/37.9M [00:02<00:00, 16.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1-1_OHJFk-h9O8eTg5a7lH4QFk4_LFHMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd949fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (molecular function)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B4ESY8</td>\n",
       "      <td>URK_PROMH</td>\n",
       "      <td>Proteus mirabilis (strain HI4320)</td>\n",
       "      <td>213</td>\n",
       "      <td>MADTAHQCTIVGIAGASASGKSLIASTLYRELRAQVGDHNIGVIPE...</td>\n",
       "      <td>GO:0005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q9H479</td>\n",
       "      <td>FN3K_HUMAN</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>309</td>\n",
       "      <td>MEQLLRAELRTATLRAFGGPGAGCISEGRAYDTDAGPVFVKVNRRT...</td>\n",
       "      <td>GO:0005524;GO:0016301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B4PRE2</td>\n",
       "      <td>DGKH_DROYA</td>\n",
       "      <td>Drosophila yakuba (Fruit fly)</td>\n",
       "      <td>1917</td>\n",
       "      <td>MSHLKLDTLHVQRSPRGSRRSSRSSGRSSACSSGSISPVPIIPIIS...</td>\n",
       "      <td>GO:0005524;GO:0046872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3DMQ4</td>\n",
       "      <td>RS4_STAMF</td>\n",
       "      <td>Staphylothermus marinus (strain ATCC 43588 / D...</td>\n",
       "      <td>168</td>\n",
       "      <td>MGDPKKPRKKWEGPRHPWRKEVLVQELKLLGTYGLRNKRELWRAQT...</td>\n",
       "      <td>GO:0019843;GO:0003735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P55656</td>\n",
       "      <td>Y4SO_SINFN</td>\n",
       "      <td>Sinorhizobium fredii (strain NBRC 101917 / NGR...</td>\n",
       "      <td>705</td>\n",
       "      <td>MENKSLQPPLPRSERRIRVLHNDVTIDSYGWLRDREDPDVLAYLEA...</td>\n",
       "      <td>GO:0004252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76736</th>\n",
       "      <td>Q7U7P8</td>\n",
       "      <td>BIOB_PARMW</td>\n",
       "      <td>Parasynechococcus marenigrum (strain WH8102)</td>\n",
       "      <td>325</td>\n",
       "      <td>MTFTIRHDWTIAEIQALLELPLMELLWQAQYVHRAANPGYRVQLAS...</td>\n",
       "      <td>GO:0051537;GO:0051539;GO:0005506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76737</th>\n",
       "      <td>Q55855</td>\n",
       "      <td>GLK_SYNY3</td>\n",
       "      <td>Synechocystis sp. (strain PCC 6803 / Kazusa)</td>\n",
       "      <td>355</td>\n",
       "      <td>MGAMGVNFLAGDIGGTKTILALVTINESSPGLARPVTLFEQTYSSP...</td>\n",
       "      <td>GO:0005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76738</th>\n",
       "      <td>Q7TPM3</td>\n",
       "      <td>TRI17_MOUSE</td>\n",
       "      <td>Mus musculus (Mouse)</td>\n",
       "      <td>477</td>\n",
       "      <td>MDAVELARRLQEEATCSICLDYFTDPVMTACGHNFCRECIQMSWEK...</td>\n",
       "      <td>GO:0061630;GO:0004842;GO:0008270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76739</th>\n",
       "      <td>B1IPK9</td>\n",
       "      <td>SYT_ECOLC</td>\n",
       "      <td>Escherichia coli (strain ATCC 8739 / DSM 1576 ...</td>\n",
       "      <td>642</td>\n",
       "      <td>MPVITLPDGSQRHYDHAVSPMDVALDIGPGLAKACIAGRVNGELVD...</td>\n",
       "      <td>GO:0005524;GO:0046872;GO:0000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76740</th>\n",
       "      <td>B7I2R7</td>\n",
       "      <td>GLYA_ACIB5</td>\n",
       "      <td>Acinetobacter baumannii (strain AB0057)</td>\n",
       "      <td>417</td>\n",
       "      <td>MFANISISEFDPELAQAIASEDERQEAHIELIASENYCSPAVMEAQ...</td>\n",
       "      <td>GO:0004372;GO:0030170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76741 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry   Entry Name                                           Organism  \\\n",
       "0      B4ESY8    URK_PROMH                  Proteus mirabilis (strain HI4320)   \n",
       "1      Q9H479   FN3K_HUMAN                               Homo sapiens (Human)   \n",
       "2      B4PRE2   DGKH_DROYA                      Drosophila yakuba (Fruit fly)   \n",
       "3      A3DMQ4    RS4_STAMF  Staphylothermus marinus (strain ATCC 43588 / D...   \n",
       "4      P55656   Y4SO_SINFN  Sinorhizobium fredii (strain NBRC 101917 / NGR...   \n",
       "...       ...          ...                                                ...   \n",
       "76736  Q7U7P8   BIOB_PARMW       Parasynechococcus marenigrum (strain WH8102)   \n",
       "76737  Q55855    GLK_SYNY3       Synechocystis sp. (strain PCC 6803 / Kazusa)   \n",
       "76738  Q7TPM3  TRI17_MOUSE                               Mus musculus (Mouse)   \n",
       "76739  B1IPK9    SYT_ECOLC  Escherichia coli (strain ATCC 8739 / DSM 1576 ...   \n",
       "76740  B7I2R7   GLYA_ACIB5            Acinetobacter baumannii (strain AB0057)   \n",
       "\n",
       "       Length                                           Sequence  \\\n",
       "0         213  MADTAHQCTIVGIAGASASGKSLIASTLYRELRAQVGDHNIGVIPE...   \n",
       "1         309  MEQLLRAELRTATLRAFGGPGAGCISEGRAYDTDAGPVFVKVNRRT...   \n",
       "2        1917  MSHLKLDTLHVQRSPRGSRRSSRSSGRSSACSSGSISPVPIIPIIS...   \n",
       "3         168  MGDPKKPRKKWEGPRHPWRKEVLVQELKLLGTYGLRNKRELWRAQT...   \n",
       "4         705  MENKSLQPPLPRSERRIRVLHNDVTIDSYGWLRDREDPDVLAYLEA...   \n",
       "...       ...                                                ...   \n",
       "76736     325  MTFTIRHDWTIAEIQALLELPLMELLWQAQYVHRAANPGYRVQLAS...   \n",
       "76737     355  MGAMGVNFLAGDIGGTKTILALVTINESSPGLARPVTLFEQTYSSP...   \n",
       "76738     477  MDAVELARRLQEEATCSICLDYFTDPVMTACGHNFCRECIQMSWEK...   \n",
       "76739     642  MPVITLPDGSQRHYDHAVSPMDVALDIGPGLAKACIAGRVNGELVD...   \n",
       "76740     417  MFANISISEFDPELAQAIASEDERQEAHIELIASENYCSPAVMEAQ...   \n",
       "\n",
       "      Gene Ontology (molecular function)  \n",
       "0                             GO:0005524  \n",
       "1                  GO:0005524;GO:0016301  \n",
       "2                  GO:0005524;GO:0046872  \n",
       "3                  GO:0019843;GO:0003735  \n",
       "4                             GO:0004252  \n",
       "...                                  ...  \n",
       "76736   GO:0051537;GO:0051539;GO:0005506  \n",
       "76737                         GO:0005524  \n",
       "76738   GO:0061630;GO:0004842;GO:0008270  \n",
       "76739   GO:0005524;GO:0046872;GO:0000049  \n",
       "76740              GO:0004372;GO:0030170  \n",
       "\n",
       "[76741 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('molecular_function.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "['GO:0000049', 'GO:0000107', 'GO:0000166', 'GO:0000175', 'GO:0000287', 'GO:0000976', 'GO:0000977', 'GO:0000978', 'GO:0000981', 'GO:0001228', 'GO:0002161', 'GO:0003676', 'GO:0003677', 'GO:0003678', 'GO:0003682', 'GO:0003684', 'GO:0003690', 'GO:0003697', 'GO:0003700', 'GO:0003712', 'GO:0003713', 'GO:0003723', 'GO:0003724', 'GO:0003729', 'GO:0003735', 'GO:0003743', 'GO:0003746', 'GO:0003755', 'GO:0003779', 'GO:0003824', 'GO:0003861', 'GO:0003887', 'GO:0003899', 'GO:0003911', 'GO:0003924', 'GO:0003989', 'GO:0004017', 'GO:0004176', 'GO:0004190', 'GO:0004222', 'GO:0004252', 'GO:0004359', 'GO:0004372', 'GO:0004497', 'GO:0004519', 'GO:0004521', 'GO:0004523', 'GO:0004672', 'GO:0004674', 'GO:0004814', 'GO:0004826', 'GO:0004827', 'GO:0004834', 'GO:0004842', 'GO:0004930', 'GO:0005096', 'GO:0005102', 'GO:0005125', 'GO:0005179', 'GO:0005198', 'GO:0005344', 'GO:0005506', 'GO:0005507', 'GO:0005509', 'GO:0005516', 'GO:0005524', 'GO:0005525', 'GO:0008017', 'GO:0008083', 'GO:0008121', 'GO:0008137', 'GO:0008168', 'GO:0008233', 'GO:0008237', 'GO:0008270', 'GO:0008289', 'GO:0008483', 'GO:0008564', 'GO:0009055', 'GO:0009378', 'GO:0009381', 'GO:0010181', 'GO:0015293', 'GO:0015297', 'GO:0016149', 'GO:0016151', 'GO:0016168', 'GO:0016301', 'GO:0016462', 'GO:0016491', 'GO:0016597', 'GO:0016655', 'GO:0016705', 'GO:0016740', 'GO:0016743', 'GO:0016783', 'GO:0016787', 'GO:0016829', 'GO:0016853', 'GO:0016879', 'GO:0016887', 'GO:0019825', 'GO:0019843', 'GO:0019899', 'GO:0019901', 'GO:0019904', 'GO:0020037', 'GO:0022857', 'GO:0030145', 'GO:0030170', 'GO:0030246', 'GO:0030527', 'GO:0030976', 'GO:0030983', 'GO:0031072', 'GO:0031267', 'GO:0031625', 'GO:0032549', 'GO:0042802', 'GO:0042803', 'GO:0043022', 'GO:0043565', 'GO:0044877', 'GO:0046872', 'GO:0046933', 'GO:0046961', 'GO:0046982', 'GO:0046983', 'GO:0048038', 'GO:0050136', 'GO:0050567', 'GO:0050660', 'GO:0050661', 'GO:0051015', 'GO:0051082', 'GO:0051087', 'GO:0051287', 'GO:0051537', 'GO:0051539', 'GO:0061630', 'GO:0070180', 'GO:0071949', 'GO:0090729', 'GO:0097367', 'GO:0106029', 'GO:0106310', 'GO:0140662', 'GO:0140664', 'GO:1990837']\n"
     ]
    }
   ],
   "source": [
    "go_terms_mf = set()\n",
    "for idx, row in df.iterrows():\n",
    "  for term in row['Gene Ontology (molecular function)'].split(';'):\n",
    "    go_terms_mf.add(term)\n",
    "go_terms_mf = list(go_terms_mf)\n",
    "go_terms_mf.sort()\n",
    "print(len(go_terms_mf))\n",
    "print(go_terms_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(sequence,segment_size=100,gap=30):\n",
    "  segments = []\n",
    "  start = 0\n",
    "  end = segment_size\n",
    "  while end <= len(sequence):\n",
    "    segments.append(sequence[start:end])\n",
    "    start += gap\n",
    "    end += gap\n",
    "  last_segment = sequence[start:]\n",
    "  segments.append(last_segment)\n",
    "  \n",
    "  return segments\n",
    "\n",
    "def get_training_data(df,segment_size=100,gap=30):\n",
    "  training_data = list()\n",
    "  for idx,row in tqdm.tqdm(df.iterrows()):\n",
    "    labels = [0] * len(go_terms_mf)\n",
    "    for term in row['Gene Ontology (molecular function)'].split(';'):\n",
    "      labels[go_terms_mf.index(term)] = 1\n",
    "    segments = get_segments(row['Sequence'],segment_size,gap)\n",
    "    for segment in segments:\n",
    "      training_data.append([row['Entry'],segment,labels])\n",
    "  return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1d6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d2ab8144e6430681fec6699cad1675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872283\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data(df)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(segment,n=3):\n",
    "  ngrams = []\n",
    "  for i in range(len(segment)-n+1):\n",
    "    ngrams.append(segment[i:i+n])\n",
    "  return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5358736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8519e904f5545a691abe6ed2ab7329b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/872283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872283\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of ngrams\n",
    "training_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_ngrams.append([training_data[i][0],get_ngrams(training_data[i][1],n=4),training_data[i][2]])\n",
    "print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c435a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('mf/training_data_ngrams.npy',training_data_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6784a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load array if already stored\n",
    "# training_data_ngrams = np.load('drive/MyDrive/mp/mf/training_data_ngrams.npy',allow_pickle=True)\n",
    "# print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4acd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skip_grams(segment,skip=1,n=3):\n",
    "  skip_grams = []\n",
    "  window_size = skip + n\n",
    "  for i in range(len(segment)-window_size+1):\n",
    "    window = segment[i:i+window_size]\n",
    "    indices = list(range(window_size))\n",
    "    indices.pop(0)\n",
    "    for idx in indices[::-1]:\n",
    "      temp = ''\n",
    "      for j in range(window_size):\n",
    "        if j!=idx:\n",
    "          temp+=window[j]\n",
    "      skip_grams.append(temp)\n",
    "\n",
    "  return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa91e8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4eb1291183d44cb8a2532d04a2ca669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/872283 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872283\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of skip grams\n",
    "training_data_skip_grams = []\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_skip_grams.append([training_data[i][0],get_skip_grams(training_data[i][1],n=4),training_data[i][2]])\n",
    "print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9bc2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('mf/training_data_skip_grams.npy',training_data_skip_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aca0eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load array if already stored\n",
    "# training_data_skip_grams = np.load('mf/training_data_skip_grams.npy',allow_pickle=True)\n",
    "# print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d856c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e391f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming training_data as global variable\n",
    "\n",
    "def train_test_split(X,y,fold_no,prev_index,Kfolds=5):\n",
    "    test_split = 1/Kfolds\n",
    "    \n",
    "    start_index = prev_index\n",
    "    end_index = (fold_no + 1) * (test_split) * len(X)\n",
    "    end_index = round(end_index)\n",
    "    \n",
    "    if end_index==len(X):\n",
    "        end_index -= 1\n",
    "    \n",
    "    entry = training_data[end_index][0]\n",
    "    entries = [sample[0] for sample in training_data]\n",
    "    \n",
    "    first_occurence = entries.index(entry)\n",
    "    entries.reverse()\n",
    "    \n",
    "    last_occurence = entries.index(entry)\n",
    "    last_occurence = len(entries) - last_occurence - 1\n",
    "    \n",
    "    del entries\n",
    "    gc.collect()\n",
    "    \n",
    "    end_index = first_occurence if (abs(end_index-first_occurence) < abs(end_index-last_occurence)) else last_occurence\n",
    "    \n",
    "    X_test = X[start_index:end_index+1]\n",
    "    y_test = y[start_index:end_index+1]\n",
    "    X_train = X[:start_index]\n",
    "    X_train.extend(X[end_index+1:])\n",
    "    y_train = y[:start_index]\n",
    "    y_train.extend(y[end_index+1:])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, start_index, end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "730f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 331776\n",
    "MAX_LEN_NG = 97 #100\n",
    "MAX_LEN_SG = 384 #300\n",
    "\n",
    "def tokenization(X_train,X_test,maxlen):\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return X_train, X_test, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a7f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "false_negative_penalty = 6\n",
    "false_positive_penalty = 1\n",
    "\n",
    "def custom_loss(y_true, y_logit):\n",
    "\n",
    "    loss = float(0)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_logit = tf.cast(y_logit, tf.float32)\n",
    "    \n",
    "    first_term = false_negative_penalty * float(y_true) * - K.log(y_logit + K.epsilon())\n",
    "    second_term = false_positive_penalty * (1 - float(y_true)) * - K.log(1 - y_logit + K.epsilon())\n",
    "    \n",
    "    loss = K.mean(first_term+second_term)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    rec = recall(y_true,y_pred)\n",
    "    prec = precision(y_true,y_pred)\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c30cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True,**kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'return_sequences': self.return_sequences \n",
    "      })\n",
    "      return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6dbee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model using ngrams \n",
    "NUM_CLASSES = 149\n",
    "\n",
    "def get_model_ng(vocab_size_ng):\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,))\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "\n",
    "    LSTM_Layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer)\n",
    "    attention_output_1 = attention(return_sequences=False)(LSTM_Layer_1)\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input_ngrams, \n",
    "        outputs=dense_layer_1\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "014f93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model using skip grams \n",
    "NUM_CLASSES = 149\n",
    "\n",
    "def get_model_sg(vocab_size_sg):\n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,))\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    LSTM_Layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer)\n",
    "    attention_output_1 = attention(return_sequences=False)(LSTM_Layer_1)\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input_skip_grams, \n",
    "        outputs=dense_layer_1\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03b912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 149 #For molecular function (Change according to aspects)\n",
    "\n",
    "def get_model_ng_sg(vocab_size_ng, vocab_size_sg):\n",
    "    #Input layers\n",
    "\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,)) \n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,)) \n",
    "\n",
    "    #embeddings\n",
    "    embedding_layer_ngrams = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "    embedding_layer_skip_grams = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    #BI-LSTMs for each of the inputs\n",
    "    sequence_output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer_ngrams)\n",
    "    attention_output_1 = attention(return_sequences=False)(sequence_output_1)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_1)\n",
    "\n",
    "    sequence_output_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70, return_sequences=True))(embedding_layer_skip_grams)\n",
    "    attention_output_2 = attention(return_sequences=False)(sequence_output_2)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.3)(attention_output_2)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_2)\n",
    "\n",
    "    max_layer = tf.keras.layers.Maximum()([dense_layer_1,dense_layer_2])\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            input_ngrams,\n",
    "            input_skip_grams\n",
    "        ], \n",
    "        outputs=max_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4236670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, start_index, end_index):\n",
    "    final_predictions = []\n",
    "    actual_y_test = []\n",
    "\n",
    "    current_entry = ''\n",
    "    counter = 0\n",
    "    total_counts = 0\n",
    "\n",
    "    if len(predictions) == len(training_data[start_index: end_index]):\n",
    "        temp = np.zeros(NUM_CLASSES)\n",
    "        for i in range(len(predictions)):\n",
    "            if current_entry != training_data[start_index+i][0]:\n",
    "                #compute prev\n",
    "                if i!=0:\n",
    "                    temp /= counter\n",
    "                    final_predictions.append(temp)\n",
    "\n",
    "                #reset\n",
    "                total_counts += counter\n",
    "                counter = 1\n",
    "                temp = np.zeros(NUM_CLASSES)\n",
    "\n",
    "                #init new\n",
    "                current_entry = training_data[start_index+i][0]\n",
    "                temp += np.array(predictions[i])\n",
    "                actual_y_test.append(training_data[start_index+i][2])\n",
    "            else:\n",
    "                temp += np.array(predictions[i])\n",
    "                counter += 1\n",
    "\n",
    "        total_counts += counter\n",
    "        temp /= counter\n",
    "        final_predictions.append(temp)\n",
    "\n",
    "    else:\n",
    "        print('Lengths of predictions dont match with test data')\n",
    "    \n",
    "    final_predictions = np.array(final_predictions, dtype=float)\n",
    "    actual_y_test = np.array(actual_y_test, dtype=float)\n",
    "    \n",
    "    rec = recall(actual_y_test,final_predictions)\n",
    "    prec = precision(actual_y_test,final_predictions)\n",
    "    f1 = f1_score(actual_y_test,final_predictions)\n",
    "    \n",
    "    return rec,prec,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1454935",
   "metadata": {},
   "source": [
    "### Model using ngrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "894bcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams\n",
    "X_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6664241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 11:59:58.740915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30974 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 12:00:04.291606: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17446/17446 [==============================] - 194s 11ms/step - loss: 0.1532 - recall: 0.4815 - precision: 0.3814 - f1_score: 0.4236 - val_loss: 0.0986 - val_recall: 0.6469 - val_precision: 0.5430 - val_f1_score: 0.5894\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 188s 11ms/step - loss: 0.0776 - recall: 0.7343 - precision: 0.5993 - f1_score: 0.6590 - val_loss: 0.0670 - val_recall: 0.7709 - val_precision: 0.6544 - val_f1_score: 0.7071\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0492 - recall: 0.8445 - precision: 0.7074 - f1_score: 0.7691 - val_loss: 0.0535 - val_recall: 0.8187 - val_precision: 0.7292 - val_f1_score: 0.7707\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 189s 11ms/step - loss: 0.0339 - recall: 0.9053 - precision: 0.7774 - f1_score: 0.8357 - val_loss: 0.0468 - val_recall: 0.8470 - val_precision: 0.7717 - val_f1_score: 0.8070\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0252 - recall: 0.9367 - precision: 0.8245 - f1_score: 0.8764 - val_loss: 0.0427 - val_recall: 0.8704 - val_precision: 0.7939 - val_f1_score: 0.8299\n",
      "\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 20s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 193s 11ms/step - loss: 0.1518 - recall: 0.4848 - precision: 0.3903 - f1_score: 0.4306 - val_loss: 0.0962 - val_recall: 0.6510 - val_precision: 0.5543 - val_f1_score: 0.5979\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 192s 11ms/step - loss: 0.0760 - recall: 0.7399 - precision: 0.6075 - f1_score: 0.6662 - val_loss: 0.0655 - val_recall: 0.7605 - val_precision: 0.6782 - val_f1_score: 0.7163\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0480 - recall: 0.8503 - precision: 0.7130 - f1_score: 0.7748 - val_loss: 0.0516 - val_recall: 0.8277 - val_precision: 0.7275 - val_f1_score: 0.7737\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0331 - recall: 0.9087 - precision: 0.7808 - f1_score: 0.8392 - val_loss: 0.0464 - val_recall: 0.8458 - val_precision: 0.7782 - val_f1_score: 0.8101\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0247 - recall: 0.9386 - precision: 0.8273 - f1_score: 0.8789 - val_loss: 0.0414 - val_recall: 0.8715 - val_precision: 0.7993 - val_f1_score: 0.8333\n",
      "\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 21s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 194s 11ms/step - loss: 0.1558 - recall: 0.4717 - precision: 0.3758 - f1_score: 0.4162 - val_loss: 0.0988 - val_recall: 0.6426 - val_precision: 0.5373 - val_f1_score: 0.5843\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 189s 11ms/step - loss: 0.0766 - recall: 0.7381 - precision: 0.6035 - f1_score: 0.6630 - val_loss: 0.0649 - val_recall: 0.7715 - val_precision: 0.6682 - val_f1_score: 0.7154\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 189s 11ms/step - loss: 0.0465 - recall: 0.8563 - precision: 0.7202 - f1_score: 0.7816 - val_loss: 0.0516 - val_recall: 0.8165 - val_precision: 0.7494 - val_f1_score: 0.7810\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0313 - recall: 0.9152 - precision: 0.7912 - f1_score: 0.8480 - val_loss: 0.0441 - val_recall: 0.8610 - val_precision: 0.7764 - val_f1_score: 0.8160\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 188s 11ms/step - loss: 0.0232 - recall: 0.9435 - precision: 0.8371 - f1_score: 0.8866 - val_loss: 0.0414 - val_recall: 0.8717 - val_precision: 0.8054 - val_f1_score: 0.8368\n",
      "\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 20s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 193s 11ms/step - loss: 0.1553 - recall: 0.4738 - precision: 0.3757 - f1_score: 0.4170 - val_loss: 0.1008 - val_recall: 0.6502 - val_precision: 0.5172 - val_f1_score: 0.5751\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 191s 11ms/step - loss: 0.0792 - recall: 0.7279 - precision: 0.5925 - f1_score: 0.6522 - val_loss: 0.0675 - val_recall: 0.7575 - val_precision: 0.6688 - val_f1_score: 0.7096\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 191s 11ms/step - loss: 0.0503 - recall: 0.8407 - precision: 0.7020 - f1_score: 0.7643 - val_loss: 0.0539 - val_recall: 0.8147 - val_precision: 0.7296 - val_f1_score: 0.7692\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 191s 11ms/step - loss: 0.0351 - recall: 0.9013 - precision: 0.7705 - f1_score: 0.8301 - val_loss: 0.0469 - val_recall: 0.8479 - val_precision: 0.7669 - val_f1_score: 0.8048\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 190s 11ms/step - loss: 0.0263 - recall: 0.9331 - precision: 0.8168 - f1_score: 0.8705 - val_loss: 0.0444 - val_recall: 0.8599 - val_precision: 0.7973 - val_f1_score: 0.8269\n",
      "\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 21s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 194s 11ms/step - loss: 0.1538 - recall: 0.4816 - precision: 0.3846 - f1_score: 0.4257 - val_loss: 0.0990 - val_recall: 0.6517 - val_precision: 0.5482 - val_f1_score: 0.5945\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 189s 11ms/step - loss: 0.0796 - recall: 0.7292 - precision: 0.5968 - f1_score: 0.6553 - val_loss: 0.0690 - val_recall: 0.7514 - val_precision: 0.6666 - val_f1_score: 0.7057\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 191s 11ms/step - loss: 0.0517 - recall: 0.8371 - precision: 0.6980 - f1_score: 0.7604 - val_loss: 0.0546 - val_recall: 0.8172 - val_precision: 0.7212 - val_f1_score: 0.7655\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 191s 11ms/step - loss: 0.0368 - recall: 0.8958 - precision: 0.7637 - f1_score: 0.8238 - val_loss: 0.0487 - val_recall: 0.8421 - val_precision: 0.7633 - val_f1_score: 0.8002\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 191s 11ms/step - loss: 0.0278 - recall: 0.9284 - precision: 0.8101 - f1_score: 0.8646 - val_loss: 0.0450 - val_recall: 0.8626 - val_precision: 0.7847 - val_f1_score: 0.8213\n",
      "\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 20s 4ms/step\n",
      "Recall: 0.6909098036882323\n",
      "Precision: 0.7140626391732743\n",
      "F1-Score: 0.7022940147164707\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)\n",
    "    \n",
    "    print('Shuffling...')\n",
    "    shuffled = [[X_train_ng[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = get_model_ng(vocab_size_ng)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(X_train_ng, y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('\\nEvaluating model...')\n",
    "    predictions = model.predict(X_test_ng)\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28840b",
   "metadata": {},
   "source": [
    "### Model using skip grams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbba7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering skip grams\n",
    "X_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33e1124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 612s 35ms/step - loss: 0.1634 - recall: 0.4437 - precision: 0.3462 - f1_score: 0.3867 - val_loss: 0.1106 - val_recall: 0.6020 - val_precision: 0.4869 - val_f1_score: 0.5373\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0900 - recall: 0.6861 - precision: 0.5490 - f1_score: 0.6087 - val_loss: 0.0776 - val_recall: 0.7007 - val_precision: 0.6340 - val_f1_score: 0.6649\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0602 - recall: 0.7954 - precision: 0.6584 - f1_score: 0.7195 - val_loss: 0.0617 - val_recall: 0.7742 - val_precision: 0.6874 - val_f1_score: 0.7276\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0429 - recall: 0.8653 - precision: 0.7307 - f1_score: 0.7915 - val_loss: 0.0520 - val_recall: 0.8212 - val_precision: 0.7356 - val_f1_score: 0.7754\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 607s 35ms/step - loss: 0.0323 - recall: 0.9080 - precision: 0.7825 - f1_score: 0.8399 - val_loss: 0.0463 - val_recall: 0.8504 - val_precision: 0.7657 - val_f1_score: 0.8052\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 65s 12ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 612s 35ms/step - loss: 0.1676 - recall: 0.4310 - precision: 0.3380 - f1_score: 0.3765 - val_loss: 0.1160 - val_recall: 0.5993 - val_precision: 0.4531 - val_f1_score: 0.5149\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0940 - recall: 0.6670 - precision: 0.5320 - f1_score: 0.5907 - val_loss: 0.0799 - val_recall: 0.7126 - val_precision: 0.6020 - val_f1_score: 0.6517\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0633 - recall: 0.7840 - precision: 0.6413 - f1_score: 0.7045 - val_loss: 0.0631 - val_recall: 0.7740 - val_precision: 0.6828 - val_f1_score: 0.7248\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 609s 35ms/step - loss: 0.0461 - recall: 0.8550 - precision: 0.7137 - f1_score: 0.7771 - val_loss: 0.0545 - val_recall: 0.8090 - val_precision: 0.7318 - val_f1_score: 0.7678\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0355 - recall: 0.8978 - precision: 0.7656 - f1_score: 0.8257 - val_loss: 0.0478 - val_recall: 0.8479 - val_precision: 0.7581 - val_f1_score: 0.7999\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 65s 12ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 611s 35ms/step - loss: 0.1643 - recall: 0.4424 - precision: 0.3363 - f1_score: 0.3799 - val_loss: 0.1110 - val_recall: 0.6077 - val_precision: 0.4860 - val_f1_score: 0.5389\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 607s 35ms/step - loss: 0.0896 - recall: 0.6868 - precision: 0.5487 - f1_score: 0.6088 - val_loss: 0.0762 - val_recall: 0.7328 - val_precision: 0.6142 - val_f1_score: 0.6673\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0591 - recall: 0.8014 - precision: 0.6618 - f1_score: 0.7240 - val_loss: 0.0612 - val_recall: 0.7761 - val_precision: 0.6953 - val_f1_score: 0.7328\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0424 - recall: 0.8693 - precision: 0.7332 - f1_score: 0.7947 - val_loss: 0.0513 - val_recall: 0.8369 - val_precision: 0.7281 - val_f1_score: 0.7780\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 608s 35ms/step - loss: 0.0322 - recall: 0.9093 - precision: 0.7830 - f1_score: 0.8407 - val_loss: 0.0471 - val_recall: 0.8426 - val_precision: 0.7745 - val_f1_score: 0.8066\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 66s 12ms/step\n",
      "Recall: 0.685649278631796\n",
      "Precision: 0.7066913174446272\n",
      "F1-Score: 0.6960070211436985\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    if i>=3:\n",
    "        break\n",
    "    \n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_sg, y_train, X_test_sg, y_test, start_index, prev_index = train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer1 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "    print('Shuffling...')\n",
    "    shuffled = [[X_train_sg[i],y_train[i]] for i in range(len(X_train_sg))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_sg = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    model = get_model_sg(vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(X_train_sg, y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict(X_test_sg)\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84680b09",
   "metadata": {},
   "source": [
    "### Model using skip grams and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6163d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "X_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32366243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872283 872283\n"
     ]
    }
   ],
   "source": [
    "print(len(X_ng),len(X_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaad7bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 801s 46ms/step - loss: 0.1538 - recall: 0.4860 - precision: 0.3889 - f1_score: 0.4302 - val_loss: 0.0961 - val_recall: 0.6646 - val_precision: 0.5445 - val_f1_score: 0.5976\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 796s 46ms/step - loss: 0.0749 - recall: 0.7461 - precision: 0.6146 - f1_score: 0.6730 - val_loss: 0.0653 - val_recall: 0.7663 - val_precision: 0.6808 - val_f1_score: 0.7203\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 796s 46ms/step - loss: 0.0470 - recall: 0.8521 - precision: 0.7247 - f1_score: 0.7824 - val_loss: 0.0518 - val_recall: 0.8281 - val_precision: 0.7340 - val_f1_score: 0.7776\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 795s 46ms/step - loss: 0.0323 - recall: 0.9096 - precision: 0.7920 - f1_score: 0.8461 - val_loss: 0.0462 - val_recall: 0.8481 - val_precision: 0.7855 - val_f1_score: 0.8151\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 796s 46ms/step - loss: 0.0237 - recall: 0.9408 - precision: 0.8391 - f1_score: 0.8865 - val_loss: 0.0409 - val_recall: 0.8770 - val_precision: 0.8020 - val_f1_score: 0.8373\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 84s 15ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 799s 46ms/step - loss: 0.1605 - recall: 0.4613 - precision: 0.3548 - f1_score: 0.3989 - val_loss: 0.1018 - val_recall: 0.6550 - val_precision: 0.5128 - val_f1_score: 0.5741\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 794s 45ms/step - loss: 0.0791 - recall: 0.7341 - precision: 0.5932 - f1_score: 0.6550 - val_loss: 0.0681 - val_recall: 0.7615 - val_precision: 0.6736 - val_f1_score: 0.7141\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 793s 45ms/step - loss: 0.0497 - recall: 0.8448 - precision: 0.7076 - f1_score: 0.7693 - val_loss: 0.0537 - val_recall: 0.8224 - val_precision: 0.7264 - val_f1_score: 0.7707\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 794s 45ms/step - loss: 0.0346 - recall: 0.9034 - precision: 0.7760 - f1_score: 0.8341 - val_loss: 0.0476 - val_recall: 0.8463 - val_precision: 0.7678 - val_f1_score: 0.8046\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 793s 45ms/step - loss: 0.0258 - recall: 0.9345 - precision: 0.8227 - f1_score: 0.8745 - val_loss: 0.0430 - val_recall: 0.8678 - val_precision: 0.7947 - val_f1_score: 0.8291\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 84s 15ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 800s 46ms/step - loss: 0.1585 - recall: 0.4639 - precision: 0.3729 - f1_score: 0.4113 - val_loss: 0.1016 - val_recall: 0.6349 - val_precision: 0.5272 - val_f1_score: 0.5750\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 793s 45ms/step - loss: 0.0770 - recall: 0.7356 - precision: 0.6009 - f1_score: 0.6604 - val_loss: 0.0675 - val_recall: 0.7630 - val_precision: 0.6671 - val_f1_score: 0.7111\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 793s 45ms/step - loss: 0.0470 - recall: 0.8528 - precision: 0.7222 - f1_score: 0.7813 - val_loss: 0.0520 - val_recall: 0.8187 - val_precision: 0.7431 - val_f1_score: 0.7784\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 792s 45ms/step - loss: 0.0320 - recall: 0.9106 - precision: 0.7944 - f1_score: 0.8479 - val_loss: 0.0454 - val_recall: 0.8535 - val_precision: 0.7767 - val_f1_score: 0.8128\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 793s 45ms/step - loss: 0.0234 - recall: 0.9411 - precision: 0.8417 - f1_score: 0.8881 - val_loss: 0.0429 - val_recall: 0.8668 - val_precision: 0.8081 - val_f1_score: 0.8360\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 84s 15ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 801s 46ms/step - loss: 0.1557 - recall: 0.4713 - precision: 0.3692 - f1_score: 0.4120 - val_loss: 0.0995 - val_recall: 0.6497 - val_precision: 0.5355 - val_f1_score: 0.5861\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 794s 46ms/step - loss: 0.0761 - recall: 0.7425 - precision: 0.6068 - f1_score: 0.6668 - val_loss: 0.0654 - val_recall: 0.7619 - val_precision: 0.6831 - val_f1_score: 0.7197\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 794s 46ms/step - loss: 0.0474 - recall: 0.8519 - precision: 0.7164 - f1_score: 0.7775 - val_loss: 0.0513 - val_recall: 0.8321 - val_precision: 0.7276 - val_f1_score: 0.7756\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 795s 46ms/step - loss: 0.0330 - recall: 0.9087 - precision: 0.7823 - f1_score: 0.8401 - val_loss: 0.0464 - val_recall: 0.8533 - val_precision: 0.7644 - val_f1_score: 0.8058\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 795s 46ms/step - loss: 0.0247 - recall: 0.9386 - precision: 0.8274 - f1_score: 0.8790 - val_loss: 0.0438 - val_recall: 0.8599 - val_precision: 0.8015 - val_f1_score: 0.8292\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 84s 15ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "17446/17446 [==============================] - 798s 45ms/step - loss: 0.1542 - recall: 0.4859 - precision: 0.3783 - f1_score: 0.4233 - val_loss: 0.0971 - val_recall: 0.6622 - val_precision: 0.5417 - val_f1_score: 0.5949\n",
      "Epoch 2/5\n",
      "17446/17446 [==============================] - 792s 45ms/step - loss: 0.0754 - recall: 0.7470 - precision: 0.6102 - f1_score: 0.6706 - val_loss: 0.0645 - val_recall: 0.7689 - val_precision: 0.6867 - val_f1_score: 0.7248\n",
      "Epoch 3/5\n",
      "17446/17446 [==============================] - 792s 45ms/step - loss: 0.0464 - recall: 0.8580 - precision: 0.7243 - f1_score: 0.7847 - val_loss: 0.0501 - val_recall: 0.8417 - val_precision: 0.7371 - val_f1_score: 0.7853\n",
      "Epoch 4/5\n",
      "17446/17446 [==============================] - 792s 45ms/step - loss: 0.0319 - recall: 0.9134 - precision: 0.7930 - f1_score: 0.8483 - val_loss: 0.0449 - val_recall: 0.8628 - val_precision: 0.7740 - val_f1_score: 0.8154\n",
      "Epoch 5/5\n",
      "17446/17446 [==============================] - 792s 45ms/step - loss: 0.0236 - recall: 0.9418 - precision: 0.8376 - f1_score: 0.8861 - val_loss: 0.0412 - val_recall: 0.8756 - val_precision: 0.8036 - val_f1_score: 0.8376\n",
      "Evaluating model...\n",
      "5452/5452 [==============================] - 84s 15ms/step\n",
      "Recall: 0.6931183729704017\n",
      "Precision: 0.7137505752638327\n",
      "F1-Score: 0.7032792181426436\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index1 = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "    X_train_sg, _, X_test_sg, _, _, _= train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "    \n",
    "    prev_index = prev_index1\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)  \n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer2 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "   \n",
    "    print('Shuffling...')   \n",
    "    shuffled = [[X_train_ng[i],X_train_sg[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    X_train_sg = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][2] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    model = get_model_ng_sg(vocab_size_ng, vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "\n",
    "    print('Training...')\n",
    "    history = model.fit([X_train_ng,X_train_sg], y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict([X_test_ng,X_test_sg])\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
