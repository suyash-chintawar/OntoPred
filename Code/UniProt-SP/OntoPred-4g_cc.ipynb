{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a056c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 10 01:09:20 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    52W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86add81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb10a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 01:12:18.795674: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-10 01:12:18.964155: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11854364064996641973\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 32476168192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8365724523644016377\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 01:12:22.391989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-10 01:12:26.562337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8be3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce40988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'cellular_component.csv'\n",
    "if not os.path.exists(file):\n",
    "    url = \"https://drive.google.com/file/d/1eYWHvzPtjrY67-h2iDybuROW0not95dG/view?usp=share_link\"\n",
    "    output = file\n",
    "    gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd949fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (cellular component)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F4KFS5</td>\n",
       "      <td>GMI1_ARATH</td>\n",
       "      <td>Arabidopsis thaliana (Mouse-ear cress)</td>\n",
       "      <td>1598</td>\n",
       "      <td>MSSRRSVKRSLVLDDDDDEDIFYNFKVLLPNGTSVKLTLKNPEPEI...</td>\n",
       "      <td>GO:0005634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q54NM7</td>\n",
       "      <td>Y6364_DICDI</td>\n",
       "      <td>Dictyostelium discoideum (Slime mold)</td>\n",
       "      <td>219</td>\n",
       "      <td>MIINNQNSPQSINTPSSVSSRQHINKSKKKKENVIKRMLIRLSNSN...</td>\n",
       "      <td>GO:0016021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B4ESY8</td>\n",
       "      <td>URK_PROMH</td>\n",
       "      <td>Proteus mirabilis (strain HI4320)</td>\n",
       "      <td>213</td>\n",
       "      <td>MADTAHQCTIVGIAGASASGKSLIASTLYRELRAQVGDHNIGVIPE...</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9H479</td>\n",
       "      <td>FN3K_HUMAN</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>309</td>\n",
       "      <td>MEQLLRAELRTATLRAFGGPGAGCISEGRAYDTDAGPVFVKVNRRT...</td>\n",
       "      <td>GO:0005829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B4PRE2</td>\n",
       "      <td>DGKH_DROYA</td>\n",
       "      <td>Drosophila yakuba (Fruit fly)</td>\n",
       "      <td>1917</td>\n",
       "      <td>MSHLKLDTLHVQRSPRGSRRSSRSSGRSSACSSGSISPVPIIPIIS...</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95312</th>\n",
       "      <td>Q8A9V4</td>\n",
       "      <td>ATPB_BACTN</td>\n",
       "      <td>Bacteroides thetaiotaomicron (strain ATCC 2914...</td>\n",
       "      <td>505</td>\n",
       "      <td>MSQIIGHISQVIGPVVDVYFEGTDAELMLPSIHDALEIKRPNGKIL...</td>\n",
       "      <td>GO:0005886;GO:0045261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95313</th>\n",
       "      <td>A1BCE9</td>\n",
       "      <td>MACB3_PARDP</td>\n",
       "      <td>Paracoccus denitrificans (strain Pd 1222)</td>\n",
       "      <td>640</td>\n",
       "      <td>MPLIRIRGLHRVFGEGAARAHVLRGIDLDIHAGEFVAIVGTSGSGK...</td>\n",
       "      <td>GO:0016021;GO:0005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95314</th>\n",
       "      <td>Q9HIS8</td>\n",
       "      <td>RL30_THEAC</td>\n",
       "      <td>Thermoplasma acidophilum (strain ATCC 25905 / ...</td>\n",
       "      <td>165</td>\n",
       "      <td>MLAVIRIRGRTGIKEDIADTAHLMRLNRINHLVLLNENEVVKGMLQ...</td>\n",
       "      <td>GO:0015934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95315</th>\n",
       "      <td>Q3J2I9</td>\n",
       "      <td>AROK_CERS4</td>\n",
       "      <td>Cereibacter sphaeroides (strain ATCC 17023 / D...</td>\n",
       "      <td>199</td>\n",
       "      <td>MKVGAEVRRRGNREDGRQVMARLKKTVVMVGMMGAGKTAVGSALAR...</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95316</th>\n",
       "      <td>Q5TF21</td>\n",
       "      <td>SOGA3_HUMAN</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>947</td>\n",
       "      <td>MSQPPIGGAAPATAAASPAAAATEARLHPEGSSRKQQRAQSPARPR...</td>\n",
       "      <td>GO:0005615;GO:0016021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95317 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry   Entry Name                                           Organism  \\\n",
       "0      F4KFS5   GMI1_ARATH             Arabidopsis thaliana (Mouse-ear cress)   \n",
       "1      Q54NM7  Y6364_DICDI              Dictyostelium discoideum (Slime mold)   \n",
       "2      B4ESY8    URK_PROMH                  Proteus mirabilis (strain HI4320)   \n",
       "3      Q9H479   FN3K_HUMAN                               Homo sapiens (Human)   \n",
       "4      B4PRE2   DGKH_DROYA                      Drosophila yakuba (Fruit fly)   \n",
       "...       ...          ...                                                ...   \n",
       "95312  Q8A9V4   ATPB_BACTN  Bacteroides thetaiotaomicron (strain ATCC 2914...   \n",
       "95313  A1BCE9  MACB3_PARDP          Paracoccus denitrificans (strain Pd 1222)   \n",
       "95314  Q9HIS8   RL30_THEAC  Thermoplasma acidophilum (strain ATCC 25905 / ...   \n",
       "95315  Q3J2I9   AROK_CERS4  Cereibacter sphaeroides (strain ATCC 17023 / D...   \n",
       "95316  Q5TF21  SOGA3_HUMAN                               Homo sapiens (Human)   \n",
       "\n",
       "       Length                                           Sequence  \\\n",
       "0        1598  MSSRRSVKRSLVLDDDDDEDIFYNFKVLLPNGTSVKLTLKNPEPEI...   \n",
       "1         219  MIINNQNSPQSINTPSSVSSRQHINKSKKKKENVIKRMLIRLSNSN...   \n",
       "2         213  MADTAHQCTIVGIAGASASGKSLIASTLYRELRAQVGDHNIGVIPE...   \n",
       "3         309  MEQLLRAELRTATLRAFGGPGAGCISEGRAYDTDAGPVFVKVNRRT...   \n",
       "4        1917  MSHLKLDTLHVQRSPRGSRRSSRSSGRSSACSSGSISPVPIIPIIS...   \n",
       "...       ...                                                ...   \n",
       "95312     505  MSQIIGHISQVIGPVVDVYFEGTDAELMLPSIHDALEIKRPNGKIL...   \n",
       "95313     640  MPLIRIRGLHRVFGEGAARAHVLRGIDLDIHAGEFVAIVGTSGSGK...   \n",
       "95314     165  MLAVIRIRGRTGIKEDIADTAHLMRLNRINHLVLLNENEVVKGMLQ...   \n",
       "95315     199  MKVGAEVRRRGNREDGRQVMARLKKTVVMVGMMGAGKTAVGSALAR...   \n",
       "95316     947  MSQPPIGGAAPATAAASPAAAATEARLHPEGSSRKQQRAQSPARPR...   \n",
       "\n",
       "      Gene Ontology (cellular component)  \n",
       "0                             GO:0005634  \n",
       "1                             GO:0016021  \n",
       "2                             GO:0005737  \n",
       "3                             GO:0005829  \n",
       "4                             GO:0005737  \n",
       "...                                  ...  \n",
       "95312              GO:0005886;GO:0045261  \n",
       "95313              GO:0016021;GO:0005886  \n",
       "95314                         GO:0015934  \n",
       "95315                         GO:0005737  \n",
       "95316              GO:0005615;GO:0016021  \n",
       "\n",
       "[95317 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "['GO:0000015', 'GO:0000139', 'GO:0000428', 'GO:0000776', 'GO:0000785', 'GO:0000786', 'GO:0005576', 'GO:0005615', 'GO:0005634', 'GO:0005635', 'GO:0005654', 'GO:0005667', 'GO:0005694', 'GO:0005730', 'GO:0005737', 'GO:0005739', 'GO:0005741', 'GO:0005743', 'GO:0005758', 'GO:0005759', 'GO:0005764', 'GO:0005765', 'GO:0005768', 'GO:0005769', 'GO:0005773', 'GO:0005774', 'GO:0005777', 'GO:0005783', 'GO:0005789', 'GO:0005794', 'GO:0005802', 'GO:0005813', 'GO:0005829', 'GO:0005833', 'GO:0005840', 'GO:0005856', 'GO:0005874', 'GO:0005886', 'GO:0005887', 'GO:0005925', 'GO:0005929', 'GO:0005938', 'GO:0009279', 'GO:0009295', 'GO:0009317', 'GO:0009376', 'GO:0009380', 'GO:0009507', 'GO:0009523', 'GO:0009535', 'GO:0009536', 'GO:0009570', 'GO:0009897', 'GO:0009986', 'GO:0010008', 'GO:0014069', 'GO:0015629', 'GO:0015934', 'GO:0015935', 'GO:0016020', 'GO:0016021', 'GO:0016282', 'GO:0016323', 'GO:0016324', 'GO:0016607', 'GO:0019013', 'GO:0019031', 'GO:0020002', 'GO:0022625', 'GO:0022627', 'GO:0030176', 'GO:0030288', 'GO:0030424', 'GO:0030425', 'GO:0030430', 'GO:0030956', 'GO:0031012', 'GO:0031225', 'GO:0031410', 'GO:0031676', 'GO:0031965', 'GO:0031966', 'GO:0032153', 'GO:0032991', 'GO:0033290', 'GO:0042025', 'GO:0042597', 'GO:0043005', 'GO:0043025', 'GO:0043190', 'GO:0043204', 'GO:0043231', 'GO:0045121', 'GO:0045202', 'GO:0045261', 'GO:0045263', 'GO:0045275', 'GO:0048471', 'GO:0055036', 'GO:0062023', 'GO:0070062', 'GO:0070161', 'GO:0070469', 'GO:0098978', 'GO:1990904']\n"
     ]
    }
   ],
   "source": [
    "go_terms_cc = set()\n",
    "for idx, row in df.iterrows():\n",
    "    for term in row['Gene Ontology (cellular component)'].split(';'):\n",
    "        go_terms_cc.add(term)\n",
    "go_terms_cc = list(go_terms_cc)\n",
    "go_terms_cc.sort()\n",
    "print(len(go_terms_cc))\n",
    "print(go_terms_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(sequence,segment_size=100,gap=30):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    end = segment_size\n",
    "    while end <= len(sequence):\n",
    "        segments.append(sequence[start:end])\n",
    "        start += gap\n",
    "        end += gap\n",
    "    last_segment = sequence[start:]\n",
    "    segments.append(last_segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def get_training_data(df,segment_size=100,gap=30):\n",
    "    training_data = list()\n",
    "    for idx,row in tqdm.tqdm(df.iterrows()):\n",
    "        labels = [0] * len(go_terms_cc)\n",
    "        for term in row['Gene Ontology (cellular component)'].split(';'):\n",
    "            labels[go_terms_cc.index(term)] = 1\n",
    "        segments = get_segments(row['Sequence'],segment_size,gap)\n",
    "        for segment in segments:\n",
    "            training_data.append([row['Entry'],segment,labels])\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1d6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8051c068a90744f280ffdad787dcfdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data(df)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(segment,n=3):\n",
    "    ngrams = []\n",
    "    for i in range(len(segment)-n+1):\n",
    "        ngrams.append(segment[i:i+n])\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5358736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of ngrams\n",
    "if os.path.exists('cc/training_data_4grams.npy'):\n",
    "    training_data_ngrams = np.load('cc/training_data_4grams.npy',allow_pickle=True)\n",
    "else:\n",
    "    training_data_ngrams = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(training_data))):\n",
    "        training_data_ngrams.append([training_data[i][0],get_ngrams(training_data[i][1],n=4),training_data[i][2]])\n",
    "        \n",
    "    np.save('cc/training_data_4grams.npy',training_data_ngrams)\n",
    "    \n",
    "print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4acd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skip_grams(segment,skip=1,n=3):\n",
    "    skip_grams = []\n",
    "    window_size = skip + n\n",
    "    for i in range(len(segment)-window_size+1):\n",
    "        window = segment[i:i+window_size]\n",
    "        indices = list(range(window_size))\n",
    "        indices.pop(0)\n",
    "        for idx in indices[::-1]:\n",
    "            temp = ''\n",
    "            for j in range(window_size):\n",
    "                if j!=idx:\n",
    "                    temp+=window[j]\n",
    "            skip_grams.append(temp)\n",
    "\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa91e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('cc/training_data_skip1_4grams.npy'):\n",
    "    training_data_skip_grams = np.load('cc/training_data_skip1_4grams.npy',allow_pickle=True)\n",
    "else:\n",
    "    training_data_skip_grams = []\n",
    "    for i in tqdm.tqdm(range(len(training_data))):\n",
    "        training_data_skip_grams.append([training_data[i][0],get_skip_grams(training_data[i][1],n=4),training_data[i][2]])\n",
    "    np.save('cc/training_data_skip1_4grams.npy',training_data_skip_grams)\n",
    "print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d856c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e391f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming training_data as global variable\n",
    "\n",
    "def train_test_split(X,y,fold_no,prev_index,Kfolds=5):\n",
    "    test_split = 1/Kfolds\n",
    "    \n",
    "    start_index = prev_index\n",
    "    end_index = (fold_no + 1) * (test_split) * len(X)\n",
    "    end_index = round(end_index)\n",
    "    \n",
    "    if end_index==len(X):\n",
    "        end_index -= 1\n",
    "    \n",
    "    entry = training_data[end_index][0]\n",
    "    entries = [sample[0] for sample in training_data]\n",
    "    \n",
    "    first_occurence = entries.index(entry)\n",
    "    entries.reverse()\n",
    "    \n",
    "    last_occurence = entries.index(entry)\n",
    "    last_occurence = len(entries) - last_occurence - 1\n",
    "    \n",
    "    del entries\n",
    "    gc.collect()\n",
    "    \n",
    "    end_index = first_occurence if (abs(end_index-first_occurence) < abs(end_index-last_occurence)) else last_occurence\n",
    "    \n",
    "    X_test = X[start_index:end_index+1]\n",
    "    y_test = y[start_index:end_index+1]\n",
    "    X_train = X[:start_index]\n",
    "    X_train.extend(X[end_index+1:])\n",
    "    y_train = y[:start_index]\n",
    "    y_train.extend(y[end_index+1:])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, start_index, end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "730f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 331776\n",
    "MAX_LEN_NG = 97 #100\n",
    "MAX_LEN_SG = 384 #300\n",
    "\n",
    "def tokenization(X_train,X_test,maxlen):\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return X_train, X_test, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a7f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "false_negative_penalty = 6\n",
    "false_positive_penalty = 1\n",
    "\n",
    "def custom_loss(y_true, y_logit):\n",
    "\n",
    "    loss = float(0)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_logit = tf.cast(y_logit, tf.float32)\n",
    "    \n",
    "    first_term = false_negative_penalty * float(y_true) * - K.log(y_logit + K.epsilon())\n",
    "    second_term = false_positive_penalty * (1 - float(y_true)) * - K.log(1 - y_logit + K.epsilon())\n",
    "    \n",
    "    loss = K.mean(first_term+second_term)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    rec = recall(y_true,y_pred)\n",
    "    prec = precision(y_true,y_pred)\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c30cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True,**kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'return_sequences': self.return_sequences \n",
    "      })\n",
    "      return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6dbee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model using ngrams \n",
    "NUM_CLASSES = 105\n",
    "\n",
    "def get_model_ng(vocab_size_ng):\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,))\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "\n",
    "    LSTM_Layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer)\n",
    "    attention_output_1 = attention(return_sequences=False)(LSTM_Layer_1)\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input_ngrams, \n",
    "        outputs=dense_layer_1\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "014f93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model using skip grams \n",
    "NUM_CLASSES = 105\n",
    "\n",
    "def get_model_sg(vocab_size_sg):\n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,))\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    LSTM_Layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer)\n",
    "    attention_output_1 = attention(return_sequences=False)(LSTM_Layer_1)\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input_skip_grams, \n",
    "        outputs=dense_layer_1\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 105 #For molecular function (Change according to aspects)\n",
    "\n",
    "def get_model_ng_sg(vocab_size_ng, vocab_size_sg):\n",
    "    #Input layers\n",
    "\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,)) \n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,)) \n",
    "\n",
    "    #embeddings\n",
    "    embedding_layer_ngrams = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "    embedding_layer_skip_grams = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    #BI-LSTMs for each of the inputs\n",
    "    sequence_output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer_ngrams)\n",
    "    attention_output_1 = attention(return_sequences=False)(sequence_output_1)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_1)\n",
    "\n",
    "    sequence_output_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70, return_sequences=True))(embedding_layer_skip_grams)\n",
    "    attention_output_2 = attention(return_sequences=False)(sequence_output_2)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.3)(attention_output_2)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_2)\n",
    "\n",
    "    max_layer = tf.keras.layers.Maximum()([dense_layer_1,dense_layer_2])\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            input_ngrams,\n",
    "            input_skip_grams\n",
    "        ], \n",
    "        outputs=max_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4236670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, start_index, end_index):\n",
    "    final_predictions = []\n",
    "    actual_y_test = []\n",
    "\n",
    "    current_entry = ''\n",
    "    counter = 0\n",
    "    total_counts = 0\n",
    "\n",
    "    if len(predictions) == len(training_data[start_index: end_index]):\n",
    "        temp = np.zeros(NUM_CLASSES)\n",
    "        for i in range(len(predictions)):\n",
    "            if current_entry != training_data[start_index+i][0]:\n",
    "                #compute prev\n",
    "                if i!=0:\n",
    "                    temp /= counter\n",
    "                    final_predictions.append(temp)\n",
    "\n",
    "                #reset\n",
    "                total_counts += counter\n",
    "                counter = 1\n",
    "                temp = np.zeros(NUM_CLASSES)\n",
    "\n",
    "                #init new\n",
    "                current_entry = training_data[start_index+i][0]\n",
    "                temp += np.array(predictions[i])\n",
    "                actual_y_test.append(training_data[start_index+i][2])\n",
    "            else:\n",
    "                temp += np.array(predictions[i])\n",
    "                counter += 1\n",
    "\n",
    "        total_counts += counter\n",
    "        temp /= counter\n",
    "        final_predictions.append(temp)\n",
    "\n",
    "    else:\n",
    "        print('Lengths of predictions dont match with test data')\n",
    "    \n",
    "    final_predictions = np.array(final_predictions, dtype=float)\n",
    "    actual_y_test = np.array(actual_y_test, dtype=float)\n",
    "    \n",
    "    rec = recall(actual_y_test,final_predictions)\n",
    "    prec = precision(actual_y_test,final_predictions)\n",
    "    f1 = f1_score(actual_y_test,final_predictions)\n",
    "    \n",
    "    return rec,prec,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1454935",
   "metadata": {},
   "source": [
    "### Model using ngrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "894bcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams\n",
    "X_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6664241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 253s 12ms/step - loss: 0.1705 - recall: 0.6389 - precision: 0.4827 - f1_score: 0.5474 - val_loss: 0.1320 - val_recall: 0.7312 - val_precision: 0.5666 - val_f1_score: 0.6373\n",
      "Epoch 2/5\n",
      "20651/21384 [===========================>..] - ETA: 7s - loss: 0.1114 - recall: 0.7806 - precision: 0.6068 - f1_score: 0.6816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384/21384 [==============================] - 248s 12ms/step - loss: 0.0621 - recall: 0.9055 - precision: 0.7321 - f1_score: 0.8087 - val_loss: 0.0767 - val_recall: 0.8646 - val_precision: 0.7126 - val_f1_score: 0.7805\n",
      "Epoch 5/5\n",
      "  636/21384 [..............................] - ETA: 3:35 - loss: 0.0469 - recall: 0.9408 - precision: 0.7875 - f1_score: 0.8566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384/21384 [==============================] - 247s 12ms/step - loss: 0.0490 - recall: 0.9328 - precision: 0.7782 - f1_score: 0.8478 - val_loss: 0.0728 - val_recall: 0.8709 - val_precision: 0.7440 - val_f1_score: 0.8017\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 254s 12ms/step - loss: 0.1723 - recall: 0.6339 - precision: 0.4756 - f1_score: 0.5409 - val_loss: 0.1355 - val_recall: 0.7077 - val_precision: 0.5728 - val_f1_score: 0.6322\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 248s 12ms/step - loss: 0.1135 - recall: 0.7750 - precision: 0.5998 - f1_score: 0.6751 - val_loss: 0.1058 - val_recall: 0.7990 - val_precision: 0.6215 - val_f1_score: 0.6981\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 248s 12ms/step - loss: 0.0839 - recall: 0.8523 - precision: 0.6704 - f1_score: 0.7494 - val_loss: 0.0909 - val_recall: 0.8242 - val_precision: 0.6776 - val_f1_score: 0.7429\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 247s 12ms/step - loss: 0.0648 - recall: 0.8996 - precision: 0.7252 - f1_score: 0.8021 - val_loss: 0.0801 - val_recall: 0.8568 - val_precision: 0.7035 - val_f1_score: 0.7718\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0513 - recall: 0.9284 - precision: 0.7719 - f1_score: 0.8421 - val_loss: 0.0743 - val_recall: 0.8657 - val_precision: 0.7436 - val_f1_score: 0.7993\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1749 - recall: 0.6260 - precision: 0.4699 - f1_score: 0.5341 - val_loss: 0.1362 - val_recall: 0.7138 - val_precision: 0.5611 - val_f1_score: 0.6272\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.1145 - recall: 0.7710 - precision: 0.6013 - f1_score: 0.6745 - val_loss: 0.1075 - val_recall: 0.7776 - val_precision: 0.6330 - val_f1_score: 0.6970\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0855 - recall: 0.8471 - precision: 0.6683 - f1_score: 0.7461 - val_loss: 0.0903 - val_recall: 0.8407 - val_precision: 0.6543 - val_f1_score: 0.7348\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 248s 12ms/step - loss: 0.0660 - recall: 0.8957 - precision: 0.7232 - f1_score: 0.7993 - val_loss: 0.0790 - val_recall: 0.8586 - val_precision: 0.7028 - val_f1_score: 0.7721\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0520 - recall: 0.9266 - precision: 0.7703 - f1_score: 0.8404 - val_loss: 0.0733 - val_recall: 0.8667 - val_precision: 0.7398 - val_f1_score: 0.7975\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 254s 12ms/step - loss: 0.1707 - recall: 0.6409 - precision: 0.4794 - f1_score: 0.5459 - val_loss: 0.1308 - val_recall: 0.7236 - val_precision: 0.5737 - val_f1_score: 0.6390\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.1114 - recall: 0.7831 - precision: 0.6041 - f1_score: 0.6809 - val_loss: 0.1052 - val_recall: 0.7784 - val_precision: 0.6423 - val_f1_score: 0.7029\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0836 - recall: 0.8539 - precision: 0.6680 - f1_score: 0.7485 - val_loss: 0.0897 - val_recall: 0.8333 - val_precision: 0.6695 - val_f1_score: 0.7415\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0651 - recall: 0.8989 - precision: 0.7236 - f1_score: 0.8009 - val_loss: 0.0813 - val_recall: 0.8505 - val_precision: 0.7113 - val_f1_score: 0.7739\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 248s 12ms/step - loss: 0.0520 - recall: 0.9274 - precision: 0.7698 - f1_score: 0.8405 - val_loss: 0.0721 - val_recall: 0.8763 - val_precision: 0.7291 - val_f1_score: 0.7951\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 253s 12ms/step - loss: 0.1700 - recall: 0.6383 - precision: 0.4849 - f1_score: 0.5487 - val_loss: 0.1344 - val_recall: 0.7128 - val_precision: 0.5697 - val_f1_score: 0.6322\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 247s 12ms/step - loss: 0.1105 - recall: 0.7818 - precision: 0.6083 - f1_score: 0.6830 - val_loss: 0.1057 - val_recall: 0.7759 - val_precision: 0.6441 - val_f1_score: 0.7030\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0815 - recall: 0.8578 - precision: 0.6760 - f1_score: 0.7551 - val_loss: 0.0886 - val_recall: 0.8319 - val_precision: 0.6808 - val_f1_score: 0.7480\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 248s 12ms/step - loss: 0.0631 - recall: 0.9033 - precision: 0.7298 - f1_score: 0.8064 - val_loss: 0.0780 - val_recall: 0.8653 - val_precision: 0.7111 - val_f1_score: 0.7798\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 249s 12ms/step - loss: 0.0501 - recall: 0.9312 - precision: 0.7762 - f1_score: 0.8459 - val_loss: 0.0721 - val_recall: 0.8699 - val_precision: 0.7495 - val_f1_score: 0.8045\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 26s 4ms/step\n",
      "Recall: 0.7241480378376719\n",
      "Precision: 0.7130075278406792\n",
      "F1-Score: 0.7185158422321545\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)\n",
    "    \n",
    "    print('Shuffling...')\n",
    "    shuffled = [[X_train_ng[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = get_model_ng(vocab_size_ng)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(X_train_ng, y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('\\nEvaluating model...')\n",
    "    predictions = model.predict(X_test_ng)\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28840b",
   "metadata": {},
   "source": [
    "### Model using skip grams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbba7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering skip grams\n",
    "X_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33e1124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 647s 30ms/step - loss: 0.1741 - recall: 0.6289 - precision: 0.4730 - f1_score: 0.5373 - val_loss: 0.1395 - val_recall: 0.7038 - val_precision: 0.5525 - val_f1_score: 0.6179\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 641s 30ms/step - loss: 0.1222 - recall: 0.7486 - precision: 0.5783 - f1_score: 0.6513 - val_loss: 0.1153 - val_recall: 0.7577 - val_precision: 0.6076 - val_f1_score: 0.6734\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 647s 30ms/step - loss: 0.0950 - recall: 0.8191 - precision: 0.6371 - f1_score: 0.7156 - val_loss: 0.0979 - val_recall: 0.8079 - val_precision: 0.6438 - val_f1_score: 0.7156\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 643s 30ms/step - loss: 0.0752 - recall: 0.8712 - precision: 0.6890 - f1_score: 0.7684 - val_loss: 0.0855 - val_recall: 0.8602 - val_precision: 0.6551 - val_f1_score: 0.7427\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 643s 30ms/step - loss: 0.0608 - recall: 0.9063 - precision: 0.7334 - f1_score: 0.8098 - val_loss: 0.0767 - val_recall: 0.8616 - val_precision: 0.7092 - val_f1_score: 0.7772\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 75s 11ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 649s 30ms/step - loss: 0.1743 - recall: 0.6279 - precision: 0.4743 - f1_score: 0.5378 - val_loss: 0.1406 - val_recall: 0.7221 - val_precision: 0.5298 - val_f1_score: 0.6100\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 645s 30ms/step - loss: 0.1221 - recall: 0.7478 - precision: 0.5790 - f1_score: 0.6515 - val_loss: 0.1147 - val_recall: 0.7680 - val_precision: 0.6048 - val_f1_score: 0.6757\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 641s 30ms/step - loss: 0.0951 - recall: 0.8188 - precision: 0.6382 - f1_score: 0.7162 - val_loss: 0.0979 - val_recall: 0.8099 - val_precision: 0.6435 - val_f1_score: 0.7162\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 642s 30ms/step - loss: 0.0758 - recall: 0.8701 - precision: 0.6883 - f1_score: 0.7676 - val_loss: 0.0867 - val_recall: 0.8337 - val_precision: 0.6853 - val_f1_score: 0.7514\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 643s 30ms/step - loss: 0.0621 - recall: 0.9036 - precision: 0.7324 - f1_score: 0.8081 - val_loss: 0.0791 - val_recall: 0.8538 - val_precision: 0.7129 - val_f1_score: 0.7762\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 74s 11ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 650s 30ms/step - loss: 0.1781 - recall: 0.6185 - precision: 0.4636 - f1_score: 0.5273 - val_loss: 0.1429 - val_recall: 0.6897 - val_precision: 0.5462 - val_f1_score: 0.6086\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 643s 30ms/step - loss: 0.1235 - recall: 0.7441 - precision: 0.5754 - f1_score: 0.6478 - val_loss: 0.1154 - val_recall: 0.7518 - val_precision: 0.6153 - val_f1_score: 0.6759\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 642s 30ms/step - loss: 0.0952 - recall: 0.8173 - precision: 0.6373 - f1_score: 0.7150 - val_loss: 0.0998 - val_recall: 0.7902 - val_precision: 0.6550 - val_f1_score: 0.7154\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 646s 30ms/step - loss: 0.0761 - recall: 0.8680 - precision: 0.6887 - f1_score: 0.7670 - val_loss: 0.0860 - val_recall: 0.8398 - val_precision: 0.6766 - val_f1_score: 0.7485\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 645s 30ms/step - loss: 0.0623 - recall: 0.9024 - precision: 0.7319 - f1_score: 0.8074 - val_loss: 0.0796 - val_recall: 0.8513 - val_precision: 0.7162 - val_f1_score: 0.7771\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 74s 11ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 645s 30ms/step - loss: 0.1827 - recall: 0.6044 - precision: 0.4562 - f1_score: 0.5171 - val_loss: 0.1472 - val_recall: 0.6867 - val_precision: 0.5289 - val_f1_score: 0.5965\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 644s 30ms/step - loss: 0.1270 - recall: 0.7317 - precision: 0.5717 - f1_score: 0.6407 - val_loss: 0.1177 - val_recall: 0.7560 - val_precision: 0.6018 - val_f1_score: 0.6691\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 641s 30ms/step - loss: 0.0982 - recall: 0.8097 - precision: 0.6336 - f1_score: 0.7099 - val_loss: 0.1001 - val_recall: 0.8102 - val_precision: 0.6360 - val_f1_score: 0.7116\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 643s 30ms/step - loss: 0.0780 - recall: 0.8639 - precision: 0.6857 - f1_score: 0.7636 - val_loss: 0.0876 - val_recall: 0.8446 - val_precision: 0.6659 - val_f1_score: 0.7437\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 645s 30ms/step - loss: 0.0634 - recall: 0.9005 - precision: 0.7298 - f1_score: 0.8053 - val_loss: 0.0813 - val_recall: 0.8488 - val_precision: 0.7087 - val_f1_score: 0.7717\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 74s 11ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 651s 30ms/step - loss: 0.1773 - recall: 0.6173 - precision: 0.4650 - f1_score: 0.5277 - val_loss: 0.1430 - val_recall: 0.6833 - val_precision: 0.5541 - val_f1_score: 0.6109\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 646s 30ms/step - loss: 0.1236 - recall: 0.7423 - precision: 0.5758 - f1_score: 0.6473 - val_loss: 0.1152 - val_recall: 0.7649 - val_precision: 0.6018 - val_f1_score: 0.6726\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 644s 30ms/step - loss: 0.0947 - recall: 0.8192 - precision: 0.6378 - f1_score: 0.7161 - val_loss: 0.0987 - val_recall: 0.7977 - val_precision: 0.6581 - val_f1_score: 0.7203\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 646s 30ms/step - loss: 0.0751 - recall: 0.8710 - precision: 0.6903 - f1_score: 0.7692 - val_loss: 0.0866 - val_recall: 0.8389 - val_precision: 0.6761 - val_f1_score: 0.7479\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 645s 30ms/step - loss: 0.0611 - recall: 0.9056 - precision: 0.7347 - f1_score: 0.8103 - val_loss: 0.0782 - val_recall: 0.8558 - val_precision: 0.7150 - val_f1_score: 0.7783\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 76s 11ms/step\n",
      "Recall: 0.72174213056965\n",
      "Precision: 0.7010352320921\n",
      "F1-Score: 0.7112293378125193\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_sg, y_train, X_test_sg, y_test, start_index, prev_index = train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer1 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "    print('Shuffling...')\n",
    "    shuffled = [[X_train_sg[i],y_train[i]] for i in range(len(X_train_sg))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_sg = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    model = get_model_sg(vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(X_train_sg, y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict(X_test_sg)\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84680b09",
   "metadata": {},
   "source": [
    "### Model using skip grams and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6163d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "X_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32366243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179 1069179\n"
     ]
    }
   ],
   "source": [
    "print(len(X_ng),len(X_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaad7bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 01:35:10.628987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 01:35:20.760119: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384/21384 [==============================] - 906s 42ms/step - loss: 0.1679 - recall: 0.6470 - precision: 0.4895 - f1_score: 0.5548 - val_loss: 0.1304 - val_recall: 0.7333 - val_precision: 0.5683 - val_f1_score: 0.6393\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 902s 42ms/step - loss: 0.1109 - recall: 0.7820 - precision: 0.6087 - f1_score: 0.6834 - val_loss: 0.1047 - val_recall: 0.7943 - val_precision: 0.6304 - val_f1_score: 0.7020\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 902s 42ms/step - loss: 0.0829 - recall: 0.8549 - precision: 0.6730 - f1_score: 0.7521 - val_loss: 0.0883 - val_recall: 0.8348 - val_precision: 0.6800 - val_f1_score: 0.7486\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 901s 42ms/step - loss: 0.0640 - recall: 0.9010 - precision: 0.7260 - f1_score: 0.8032 - val_loss: 0.0788 - val_recall: 0.8543 - val_precision: 0.7152 - val_f1_score: 0.7778\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 898s 42ms/step - loss: 0.0507 - recall: 0.9298 - precision: 0.7733 - f1_score: 0.8436 - val_loss: 0.0723 - val_recall: 0.8762 - val_precision: 0.7307 - val_f1_score: 0.7961\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 98s 14ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 913s 42ms/step - loss: 0.1705 - recall: 0.6407 - precision: 0.4789 - f1_score: 0.5455 - val_loss: 0.1307 - val_recall: 0.7213 - val_precision: 0.5808 - val_f1_score: 0.6425\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 910s 43ms/step - loss: 0.1095 - recall: 0.7839 - precision: 0.6125 - f1_score: 0.6865 - val_loss: 0.1053 - val_recall: 0.7886 - val_precision: 0.6437 - val_f1_score: 0.7079\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 905s 42ms/step - loss: 0.0806 - recall: 0.8567 - precision: 0.6801 - f1_score: 0.7572 - val_loss: 0.0882 - val_recall: 0.8356 - val_precision: 0.6759 - val_f1_score: 0.7464\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 913s 43ms/step - loss: 0.0616 - recall: 0.9038 - precision: 0.7358 - f1_score: 0.8103 - val_loss: 0.0797 - val_recall: 0.8557 - val_precision: 0.7212 - val_f1_score: 0.7820\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 910s 43ms/step - loss: 0.0481 - recall: 0.9329 - precision: 0.7851 - f1_score: 0.8519 - val_loss: 0.0711 - val_recall: 0.8768 - val_precision: 0.7454 - val_f1_score: 0.8051\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 99s 15ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 919s 43ms/step - loss: 0.1722 - recall: 0.6411 - precision: 0.4755 - f1_score: 0.5430 - val_loss: 0.1348 - val_recall: 0.7228 - val_precision: 0.5659 - val_f1_score: 0.6338\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 910s 43ms/step - loss: 0.1123 - recall: 0.7794 - precision: 0.6069 - f1_score: 0.6813 - val_loss: 0.1050 - val_recall: 0.7938 - val_precision: 0.6317 - val_f1_score: 0.7026\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 912s 43ms/step - loss: 0.0836 - recall: 0.8523 - precision: 0.6721 - f1_score: 0.7505 - val_loss: 0.0900 - val_recall: 0.8315 - val_precision: 0.6688 - val_f1_score: 0.7405\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 911s 43ms/step - loss: 0.0653 - recall: 0.8975 - precision: 0.7234 - f1_score: 0.8002 - val_loss: 0.0800 - val_recall: 0.8541 - val_precision: 0.7103 - val_f1_score: 0.7748\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 912s 43ms/step - loss: 0.0521 - recall: 0.9267 - precision: 0.7692 - f1_score: 0.8399 - val_loss: 0.0728 - val_recall: 0.8760 - val_precision: 0.7269 - val_f1_score: 0.7937\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 97s 14ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 898s 42ms/step - loss: 0.1701 - recall: 0.6473 - precision: 0.4779 - f1_score: 0.5471 - val_loss: 0.1321 - val_recall: 0.7120 - val_precision: 0.5845 - val_f1_score: 0.6410\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 890s 42ms/step - loss: 0.1110 - recall: 0.7829 - precision: 0.6073 - f1_score: 0.6829 - val_loss: 0.1058 - val_recall: 0.7870 - val_precision: 0.6412 - val_f1_score: 0.7057\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 890s 42ms/step - loss: 0.0831 - recall: 0.8543 - precision: 0.6737 - f1_score: 0.7523 - val_loss: 0.0893 - val_recall: 0.8437 - val_precision: 0.6605 - val_f1_score: 0.7400\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 895s 42ms/step - loss: 0.0652 - recall: 0.8983 - precision: 0.7251 - f1_score: 0.8016 - val_loss: 0.0812 - val_recall: 0.8504 - val_precision: 0.7108 - val_f1_score: 0.7736\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 893s 42ms/step - loss: 0.0526 - recall: 0.9261 - precision: 0.7694 - f1_score: 0.8397 - val_loss: 0.0745 - val_recall: 0.8647 - val_precision: 0.7374 - val_f1_score: 0.7952\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 99s 15ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 909s 42ms/step - loss: 0.1745 - recall: 0.6319 - precision: 0.4744 - f1_score: 0.5395 - val_loss: 0.1405 - val_recall: 0.6936 - val_precision: 0.5639 - val_f1_score: 0.6210\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 903s 42ms/step - loss: 0.1197 - recall: 0.7555 - precision: 0.5866 - f1_score: 0.6592 - val_loss: 0.1125 - val_recall: 0.7608 - val_precision: 0.6199 - val_f1_score: 0.6823\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 901s 42ms/step - loss: 0.0909 - recall: 0.8296 - precision: 0.6524 - f1_score: 0.7293 - val_loss: 0.0945 - val_recall: 0.8280 - val_precision: 0.6412 - val_f1_score: 0.7217\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 901s 42ms/step - loss: 0.0715 - recall: 0.8797 - precision: 0.7063 - f1_score: 0.7825 - val_loss: 0.0843 - val_recall: 0.8432 - val_precision: 0.6860 - val_f1_score: 0.7556\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 901s 42ms/step - loss: 0.0576 - recall: 0.9129 - precision: 0.7518 - f1_score: 0.8237 - val_loss: 0.0765 - val_recall: 0.8586 - val_precision: 0.7336 - val_f1_score: 0.7905\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 98s 14ms/step\n",
      "Recall: 0.724712150778677\n",
      "Precision: 0.7075647948940114\n",
      "F1-Score: 0.7160202245595115\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index1 = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "    X_train_sg, _, X_test_sg, _, _, _= train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "    \n",
    "    prev_index = prev_index1\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)  \n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer2 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "   \n",
    "    print('Shuffling...')   \n",
    "    shuffled = [[X_train_ng[i],X_train_sg[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    X_train_sg = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][2] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    model = get_model_ng_sg(vocab_size_ng, vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "\n",
    "    print('Training...')\n",
    "    history = model.fit([X_train_ng,X_train_sg], y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict([X_test_ng,X_test_sg])\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
