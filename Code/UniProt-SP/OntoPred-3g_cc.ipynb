{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a056c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  6 01:45:03 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   298W / 300W |  18066MiB / 32508MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    39W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    41W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    41W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   3712897      C   python                          18063MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86add81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb10a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 01:45:04.952604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 01:45:05.147178: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7002604964028122203\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 32476168192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3611980115607987456\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 01:45:08.526860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 01:45:09.412816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8be3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce40988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'cellular_component.csv'\n",
    "if not os.path.exists(file):\n",
    "    url = \"https://drive.google.com/file/d/1eYWHvzPtjrY67-h2iDybuROW0not95dG/view?usp=share_link\"\n",
    "    output = file\n",
    "    gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd949fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Entry Name</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (cellular component)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F4KFS5</td>\n",
       "      <td>GMI1_ARATH</td>\n",
       "      <td>Arabidopsis thaliana (Mouse-ear cress)</td>\n",
       "      <td>1598</td>\n",
       "      <td>MSSRRSVKRSLVLDDDDDEDIFYNFKVLLPNGTSVKLTLKNPEPEI...</td>\n",
       "      <td>GO:0005634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q54NM7</td>\n",
       "      <td>Y6364_DICDI</td>\n",
       "      <td>Dictyostelium discoideum (Slime mold)</td>\n",
       "      <td>219</td>\n",
       "      <td>MIINNQNSPQSINTPSSVSSRQHINKSKKKKENVIKRMLIRLSNSN...</td>\n",
       "      <td>GO:0016021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B4ESY8</td>\n",
       "      <td>URK_PROMH</td>\n",
       "      <td>Proteus mirabilis (strain HI4320)</td>\n",
       "      <td>213</td>\n",
       "      <td>MADTAHQCTIVGIAGASASGKSLIASTLYRELRAQVGDHNIGVIPE...</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9H479</td>\n",
       "      <td>FN3K_HUMAN</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>309</td>\n",
       "      <td>MEQLLRAELRTATLRAFGGPGAGCISEGRAYDTDAGPVFVKVNRRT...</td>\n",
       "      <td>GO:0005829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B4PRE2</td>\n",
       "      <td>DGKH_DROYA</td>\n",
       "      <td>Drosophila yakuba (Fruit fly)</td>\n",
       "      <td>1917</td>\n",
       "      <td>MSHLKLDTLHVQRSPRGSRRSSRSSGRSSACSSGSISPVPIIPIIS...</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95312</th>\n",
       "      <td>Q8A9V4</td>\n",
       "      <td>ATPB_BACTN</td>\n",
       "      <td>Bacteroides thetaiotaomicron (strain ATCC 2914...</td>\n",
       "      <td>505</td>\n",
       "      <td>MSQIIGHISQVIGPVVDVYFEGTDAELMLPSIHDALEIKRPNGKIL...</td>\n",
       "      <td>GO:0005886;GO:0045261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95313</th>\n",
       "      <td>A1BCE9</td>\n",
       "      <td>MACB3_PARDP</td>\n",
       "      <td>Paracoccus denitrificans (strain Pd 1222)</td>\n",
       "      <td>640</td>\n",
       "      <td>MPLIRIRGLHRVFGEGAARAHVLRGIDLDIHAGEFVAIVGTSGSGK...</td>\n",
       "      <td>GO:0016021;GO:0005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95314</th>\n",
       "      <td>Q9HIS8</td>\n",
       "      <td>RL30_THEAC</td>\n",
       "      <td>Thermoplasma acidophilum (strain ATCC 25905 / ...</td>\n",
       "      <td>165</td>\n",
       "      <td>MLAVIRIRGRTGIKEDIADTAHLMRLNRINHLVLLNENEVVKGMLQ...</td>\n",
       "      <td>GO:0015934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95315</th>\n",
       "      <td>Q3J2I9</td>\n",
       "      <td>AROK_CERS4</td>\n",
       "      <td>Cereibacter sphaeroides (strain ATCC 17023 / D...</td>\n",
       "      <td>199</td>\n",
       "      <td>MKVGAEVRRRGNREDGRQVMARLKKTVVMVGMMGAGKTAVGSALAR...</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95316</th>\n",
       "      <td>Q5TF21</td>\n",
       "      <td>SOGA3_HUMAN</td>\n",
       "      <td>Homo sapiens (Human)</td>\n",
       "      <td>947</td>\n",
       "      <td>MSQPPIGGAAPATAAASPAAAATEARLHPEGSSRKQQRAQSPARPR...</td>\n",
       "      <td>GO:0005615;GO:0016021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95317 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry   Entry Name                                           Organism  \\\n",
       "0      F4KFS5   GMI1_ARATH             Arabidopsis thaliana (Mouse-ear cress)   \n",
       "1      Q54NM7  Y6364_DICDI              Dictyostelium discoideum (Slime mold)   \n",
       "2      B4ESY8    URK_PROMH                  Proteus mirabilis (strain HI4320)   \n",
       "3      Q9H479   FN3K_HUMAN                               Homo sapiens (Human)   \n",
       "4      B4PRE2   DGKH_DROYA                      Drosophila yakuba (Fruit fly)   \n",
       "...       ...          ...                                                ...   \n",
       "95312  Q8A9V4   ATPB_BACTN  Bacteroides thetaiotaomicron (strain ATCC 2914...   \n",
       "95313  A1BCE9  MACB3_PARDP          Paracoccus denitrificans (strain Pd 1222)   \n",
       "95314  Q9HIS8   RL30_THEAC  Thermoplasma acidophilum (strain ATCC 25905 / ...   \n",
       "95315  Q3J2I9   AROK_CERS4  Cereibacter sphaeroides (strain ATCC 17023 / D...   \n",
       "95316  Q5TF21  SOGA3_HUMAN                               Homo sapiens (Human)   \n",
       "\n",
       "       Length                                           Sequence  \\\n",
       "0        1598  MSSRRSVKRSLVLDDDDDEDIFYNFKVLLPNGTSVKLTLKNPEPEI...   \n",
       "1         219  MIINNQNSPQSINTPSSVSSRQHINKSKKKKENVIKRMLIRLSNSN...   \n",
       "2         213  MADTAHQCTIVGIAGASASGKSLIASTLYRELRAQVGDHNIGVIPE...   \n",
       "3         309  MEQLLRAELRTATLRAFGGPGAGCISEGRAYDTDAGPVFVKVNRRT...   \n",
       "4        1917  MSHLKLDTLHVQRSPRGSRRSSRSSGRSSACSSGSISPVPIIPIIS...   \n",
       "...       ...                                                ...   \n",
       "95312     505  MSQIIGHISQVIGPVVDVYFEGTDAELMLPSIHDALEIKRPNGKIL...   \n",
       "95313     640  MPLIRIRGLHRVFGEGAARAHVLRGIDLDIHAGEFVAIVGTSGSGK...   \n",
       "95314     165  MLAVIRIRGRTGIKEDIADTAHLMRLNRINHLVLLNENEVVKGMLQ...   \n",
       "95315     199  MKVGAEVRRRGNREDGRQVMARLKKTVVMVGMMGAGKTAVGSALAR...   \n",
       "95316     947  MSQPPIGGAAPATAAASPAAAATEARLHPEGSSRKQQRAQSPARPR...   \n",
       "\n",
       "      Gene Ontology (cellular component)  \n",
       "0                             GO:0005634  \n",
       "1                             GO:0016021  \n",
       "2                             GO:0005737  \n",
       "3                             GO:0005829  \n",
       "4                             GO:0005737  \n",
       "...                                  ...  \n",
       "95312              GO:0005886;GO:0045261  \n",
       "95313              GO:0016021;GO:0005886  \n",
       "95314                         GO:0015934  \n",
       "95315                         GO:0005737  \n",
       "95316              GO:0005615;GO:0016021  \n",
       "\n",
       "[95317 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "['GO:0000015', 'GO:0000139', 'GO:0000428', 'GO:0000776', 'GO:0000785', 'GO:0000786', 'GO:0005576', 'GO:0005615', 'GO:0005634', 'GO:0005635', 'GO:0005654', 'GO:0005667', 'GO:0005694', 'GO:0005730', 'GO:0005737', 'GO:0005739', 'GO:0005741', 'GO:0005743', 'GO:0005758', 'GO:0005759', 'GO:0005764', 'GO:0005765', 'GO:0005768', 'GO:0005769', 'GO:0005773', 'GO:0005774', 'GO:0005777', 'GO:0005783', 'GO:0005789', 'GO:0005794', 'GO:0005802', 'GO:0005813', 'GO:0005829', 'GO:0005833', 'GO:0005840', 'GO:0005856', 'GO:0005874', 'GO:0005886', 'GO:0005887', 'GO:0005925', 'GO:0005929', 'GO:0005938', 'GO:0009279', 'GO:0009295', 'GO:0009317', 'GO:0009376', 'GO:0009380', 'GO:0009507', 'GO:0009523', 'GO:0009535', 'GO:0009536', 'GO:0009570', 'GO:0009897', 'GO:0009986', 'GO:0010008', 'GO:0014069', 'GO:0015629', 'GO:0015934', 'GO:0015935', 'GO:0016020', 'GO:0016021', 'GO:0016282', 'GO:0016323', 'GO:0016324', 'GO:0016607', 'GO:0019013', 'GO:0019031', 'GO:0020002', 'GO:0022625', 'GO:0022627', 'GO:0030176', 'GO:0030288', 'GO:0030424', 'GO:0030425', 'GO:0030430', 'GO:0030956', 'GO:0031012', 'GO:0031225', 'GO:0031410', 'GO:0031676', 'GO:0031965', 'GO:0031966', 'GO:0032153', 'GO:0032991', 'GO:0033290', 'GO:0042025', 'GO:0042597', 'GO:0043005', 'GO:0043025', 'GO:0043190', 'GO:0043204', 'GO:0043231', 'GO:0045121', 'GO:0045202', 'GO:0045261', 'GO:0045263', 'GO:0045275', 'GO:0048471', 'GO:0055036', 'GO:0062023', 'GO:0070062', 'GO:0070161', 'GO:0070469', 'GO:0098978', 'GO:1990904']\n"
     ]
    }
   ],
   "source": [
    "go_terms_cc = set()\n",
    "for idx, row in df.iterrows():\n",
    "    for term in row['Gene Ontology (cellular component)'].split(';'):\n",
    "        go_terms_cc.add(term)\n",
    "go_terms_cc = list(go_terms_cc)\n",
    "go_terms_cc.sort()\n",
    "print(len(go_terms_cc))\n",
    "print(go_terms_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(sequence,segment_size=100,gap=30):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    end = segment_size\n",
    "    while end <= len(sequence):\n",
    "        segments.append(sequence[start:end])\n",
    "        start += gap\n",
    "        end += gap\n",
    "    last_segment = sequence[start:]\n",
    "    segments.append(last_segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def get_training_data(df,segment_size=100,gap=30):\n",
    "    training_data = list()\n",
    "    for idx,row in tqdm.tqdm(df.iterrows()):\n",
    "        labels = [0] * len(go_terms_cc)\n",
    "        for term in row['Gene Ontology (cellular component)'].split(';'):\n",
    "            labels[go_terms_cc.index(term)] = 1\n",
    "        segments = get_segments(row['Sequence'],segment_size,gap)\n",
    "        for segment in segments:\n",
    "            training_data.append([row['Entry'],segment,labels])\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f1d6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dafddd36a24bfdbd36d2686be5980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data(df)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(segment,n=3):\n",
    "    ngrams = []\n",
    "    for i in range(len(segment)-n+1):\n",
    "        ngrams.append(segment[i:i+n])\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5358736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of ngrams\n",
    "if os.path.exists('cc/training_data_3grams.npy'):\n",
    "    training_data_ngrams = np.load('cc/training_data_3grams.npy',allow_pickle=True)\n",
    "else:\n",
    "    training_data_ngrams = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(training_data))):\n",
    "        training_data_ngrams.append([training_data[i][0],get_ngrams(training_data[i][1],n=3),training_data[i][2]])\n",
    "        \n",
    "    np.save('cc/training_data_3grams.npy',training_data_ngrams)\n",
    "    \n",
    "print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4acd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skip_grams(segment,skip=1,n=3):\n",
    "    skip_grams = []\n",
    "    window_size = skip + n\n",
    "    for i in range(len(segment)-window_size+1):\n",
    "        window = segment[i:i+window_size]\n",
    "        indices = list(range(window_size))\n",
    "        indices.pop(0)\n",
    "        for idx in indices[::-1]:\n",
    "            temp = ''\n",
    "            for j in range(window_size):\n",
    "                if j!=idx:\n",
    "                    temp+=window[j]\n",
    "            skip_grams.append(temp)\n",
    "\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa91e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('cc/training_data_skip1_3grams.npy'):\n",
    "    training_data_skip_grams = np.load('cc/training_data_skip1_3grams.npy',allow_pickle=True)\n",
    "else:\n",
    "    training_data_skip_grams = []\n",
    "    for i in tqdm.tqdm(range(len(training_data))):\n",
    "        training_data_skip_grams.append([training_data[i][0],get_skip_grams(training_data[i][1],n=3),training_data[i][2]])\n",
    "    np.save('cc/training_data_skip1_3grams.npy',training_data_skip_grams)\n",
    "print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11d856c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e391f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming training_data as global variable\n",
    "\n",
    "def train_test_split(X,y,fold_no,prev_index,Kfolds=5):\n",
    "    test_split = 1/Kfolds\n",
    "    \n",
    "    start_index = prev_index\n",
    "    end_index = (fold_no + 1) * (test_split) * len(X)\n",
    "    end_index = round(end_index)\n",
    "    \n",
    "    if end_index==len(X):\n",
    "        end_index -= 1\n",
    "    \n",
    "    entry = training_data[end_index][0]\n",
    "    entries = [sample[0] for sample in training_data]\n",
    "    \n",
    "    first_occurence = entries.index(entry)\n",
    "    entries.reverse()\n",
    "    \n",
    "    last_occurence = entries.index(entry)\n",
    "    last_occurence = len(entries) - last_occurence - 1\n",
    "    \n",
    "    del entries\n",
    "    gc.collect()\n",
    "    \n",
    "    end_index = first_occurence if (abs(end_index-first_occurence) < abs(end_index-last_occurence)) else last_occurence\n",
    "    \n",
    "    X_test = X[start_index:end_index+1]\n",
    "    y_test = y[start_index:end_index+1]\n",
    "    X_train = X[:start_index]\n",
    "    X_train.extend(X[end_index+1:])\n",
    "    y_train = y[:start_index]\n",
    "    y_train.extend(y[end_index+1:])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, start_index, end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "730f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 13824\n",
    "MAX_LEN_NG = 98 #100\n",
    "MAX_LEN_SG = 291 #300\n",
    "\n",
    "def tokenization(X_train,X_test,maxlen):\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return X_train, X_test, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a7f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "false_negative_penalty = 6\n",
    "false_positive_penalty = 1\n",
    "\n",
    "def custom_loss(y_true, y_logit):\n",
    "\n",
    "    loss = float(0)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_logit = tf.cast(y_logit, tf.float32)\n",
    "    \n",
    "    first_term = false_negative_penalty * float(y_true) * - K.log(y_logit + K.epsilon())\n",
    "    second_term = false_positive_penalty * (1 - float(y_true)) * - K.log(1 - y_logit + K.epsilon())\n",
    "    \n",
    "    loss = K.mean(first_term+second_term)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    rec = recall(y_true,y_pred)\n",
    "    prec = precision(y_true,y_pred)\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36c30cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True,**kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'return_sequences': self.return_sequences \n",
    "      })\n",
    "      return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6dbee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model using ngrams \n",
    "NUM_CLASSES = 105\n",
    "\n",
    "def get_model_ng(vocab_size_ng):\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,))\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "\n",
    "    LSTM_Layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer)\n",
    "    attention_output_1 = attention(return_sequences=False)(LSTM_Layer_1)\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input_ngrams, \n",
    "        outputs=dense_layer_1\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "014f93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base model using skip grams \n",
    "NUM_CLASSES = 105\n",
    "\n",
    "def get_model_sg(vocab_size_sg):\n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,))\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    LSTM_Layer_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer)\n",
    "    attention_output_1 = attention(return_sequences=False)(LSTM_Layer_1)\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=input_skip_grams, \n",
    "        outputs=dense_layer_1\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03b912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 105 #For molecular function (Change according to aspects)\n",
    "\n",
    "def get_model_ng_sg(vocab_size_ng, vocab_size_sg):\n",
    "    #Input layers\n",
    "\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,)) \n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,)) \n",
    "\n",
    "    #embeddings\n",
    "    embedding_layer_ngrams = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "    embedding_layer_skip_grams = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    #BI-LSTMs for each of the inputs\n",
    "    sequence_output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70,return_sequences=True))(embedding_layer_ngrams)\n",
    "    attention_output_1 = attention(return_sequences=False)(sequence_output_1)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_1)\n",
    "\n",
    "    sequence_output_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(70, return_sequences=True))(embedding_layer_skip_grams)\n",
    "    attention_output_2 = attention(return_sequences=False)(sequence_output_2)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.3)(attention_output_2)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_2)\n",
    "\n",
    "    max_layer = tf.keras.layers.Maximum()([dense_layer_1,dense_layer_2])\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            input_ngrams,\n",
    "            input_skip_grams\n",
    "        ], \n",
    "        outputs=max_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4236670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, start_index, end_index):\n",
    "    final_predictions = []\n",
    "    actual_y_test = []\n",
    "\n",
    "    current_entry = ''\n",
    "    counter = 0\n",
    "    total_counts = 0\n",
    "\n",
    "    if len(predictions) == len(training_data[start_index: end_index]):\n",
    "        temp = np.zeros(NUM_CLASSES)\n",
    "        for i in range(len(predictions)):\n",
    "            if current_entry != training_data[start_index+i][0]:\n",
    "                #compute prev\n",
    "                if i!=0:\n",
    "                    temp /= counter\n",
    "                    final_predictions.append(temp)\n",
    "\n",
    "                #reset\n",
    "                total_counts += counter\n",
    "                counter = 1\n",
    "                temp = np.zeros(NUM_CLASSES)\n",
    "\n",
    "                #init new\n",
    "                current_entry = training_data[start_index+i][0]\n",
    "                temp += np.array(predictions[i])\n",
    "                actual_y_test.append(training_data[start_index+i][2])\n",
    "            else:\n",
    "                temp += np.array(predictions[i])\n",
    "                counter += 1\n",
    "\n",
    "        total_counts += counter\n",
    "        temp /= counter\n",
    "        final_predictions.append(temp)\n",
    "\n",
    "    else:\n",
    "        print('Lengths of predictions dont match with test data')\n",
    "    \n",
    "    final_predictions = np.array(final_predictions, dtype=float)\n",
    "    actual_y_test = np.array(actual_y_test, dtype=float)\n",
    "    \n",
    "    rec = recall(actual_y_test,final_predictions)\n",
    "    prec = precision(actual_y_test,final_predictions)\n",
    "    f1 = f1_score(actual_y_test,final_predictions)\n",
    "    \n",
    "    return rec,prec,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1454935",
   "metadata": {},
   "source": [
    "### Model using ngrams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "894bcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams\n",
    "X_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6664241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 15:21:42.615791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 15:21:52.100608: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384/21384 [==============================] - 263s 12ms/step - loss: 0.1983 - recall: 0.5760 - precision: 0.4222 - f1_score: 0.4845 - val_loss: 0.1778 - val_recall: 0.6283 - val_precision: 0.4645 - val_f1_score: 0.5328\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1716 - recall: 0.6421 - precision: 0.4806 - f1_score: 0.5483 - val_loss: 0.1645 - val_recall: 0.6627 - val_precision: 0.4926 - val_f1_score: 0.5639\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1594 - recall: 0.6663 - precision: 0.5059 - f1_score: 0.5738 - val_loss: 0.1565 - val_recall: 0.6611 - val_precision: 0.5324 - val_f1_score: 0.5886\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 253s 12ms/step - loss: 0.1505 - recall: 0.6837 - precision: 0.5212 - f1_score: 0.5902 - val_loss: 0.1503 - val_recall: 0.6809 - val_precision: 0.5342 - val_f1_score: 0.5976\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1434 - recall: 0.6977 - precision: 0.5318 - f1_score: 0.6024 - val_loss: 0.1461 - val_recall: 0.6976 - val_precision: 0.5286 - val_f1_score: 0.6002\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 258s 12ms/step - loss: 0.1984 - recall: 0.5780 - precision: 0.4224 - f1_score: 0.4855 - val_loss: 0.1777 - val_recall: 0.6264 - val_precision: 0.4738 - val_f1_score: 0.5382\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 254s 12ms/step - loss: 0.1716 - recall: 0.6433 - precision: 0.4829 - f1_score: 0.5502 - val_loss: 0.1642 - val_recall: 0.6525 - val_precision: 0.5108 - val_f1_score: 0.5719\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 254s 12ms/step - loss: 0.1595 - recall: 0.6676 - precision: 0.5073 - f1_score: 0.5752 - val_loss: 0.1562 - val_recall: 0.6757 - val_precision: 0.5194 - val_f1_score: 0.5861\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 254s 12ms/step - loss: 0.1506 - recall: 0.6845 - precision: 0.5221 - f1_score: 0.5911 - val_loss: 0.1505 - val_recall: 0.6824 - val_precision: 0.5283 - val_f1_score: 0.5944\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1436 - recall: 0.6983 - precision: 0.5324 - f1_score: 0.6029 - val_loss: 0.1470 - val_recall: 0.6927 - val_precision: 0.5325 - val_f1_score: 0.6009\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 259s 12ms/step - loss: 0.1968 - recall: 0.5811 - precision: 0.4257 - f1_score: 0.4886 - val_loss: 0.1764 - val_recall: 0.6383 - val_precision: 0.4651 - val_f1_score: 0.5367\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 255s 12ms/step - loss: 0.1704 - recall: 0.6461 - precision: 0.4849 - f1_score: 0.5525 - val_loss: 0.1636 - val_recall: 0.6474 - val_precision: 0.5108 - val_f1_score: 0.5699\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 256s 12ms/step - loss: 0.1581 - recall: 0.6702 - precision: 0.5083 - f1_score: 0.5768 - val_loss: 0.1547 - val_recall: 0.6781 - val_precision: 0.5189 - val_f1_score: 0.5867\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 255s 12ms/step - loss: 0.1489 - recall: 0.6883 - precision: 0.5227 - f1_score: 0.5929 - val_loss: 0.1485 - val_recall: 0.6830 - val_precision: 0.5386 - val_f1_score: 0.6011\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 254s 12ms/step - loss: 0.1419 - recall: 0.7020 - precision: 0.5333 - f1_score: 0.6049 - val_loss: 0.1444 - val_recall: 0.7052 - val_precision: 0.5248 - val_f1_score: 0.6005\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 255s 12ms/step - loss: 0.1977 - recall: 0.5799 - precision: 0.4223 - f1_score: 0.4859 - val_loss: 0.1773 - val_recall: 0.6137 - val_precision: 0.4925 - val_f1_score: 0.5452\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 251s 12ms/step - loss: 0.1709 - recall: 0.6451 - precision: 0.4815 - f1_score: 0.5499 - val_loss: 0.1645 - val_recall: 0.6724 - val_precision: 0.4845 - val_f1_score: 0.5619\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 250s 12ms/step - loss: 0.1587 - recall: 0.6701 - precision: 0.5054 - f1_score: 0.5749 - val_loss: 0.1569 - val_recall: 0.6665 - val_precision: 0.5298 - val_f1_score: 0.5892\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1499 - recall: 0.6862 - precision: 0.5200 - f1_score: 0.5904 - val_loss: 0.1512 - val_recall: 0.6767 - val_precision: 0.5361 - val_f1_score: 0.5972\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 250s 12ms/step - loss: 0.1430 - recall: 0.6998 - precision: 0.5310 - f1_score: 0.6026 - val_loss: 0.1467 - val_recall: 0.7003 - val_precision: 0.5309 - val_f1_score: 0.6028\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 257s 12ms/step - loss: 0.2003 - recall: 0.5735 - precision: 0.4129 - f1_score: 0.4771 - val_loss: 0.1793 - val_recall: 0.6118 - val_precision: 0.4789 - val_f1_score: 0.5360\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1725 - recall: 0.6401 - precision: 0.4826 - f1_score: 0.5488 - val_loss: 0.1648 - val_recall: 0.6532 - val_precision: 0.4968 - val_f1_score: 0.5632\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 251s 12ms/step - loss: 0.1598 - recall: 0.6659 - precision: 0.5067 - f1_score: 0.5742 - val_loss: 0.1561 - val_recall: 0.6698 - val_precision: 0.5197 - val_f1_score: 0.5842\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 252s 12ms/step - loss: 0.1506 - recall: 0.6839 - precision: 0.5214 - f1_score: 0.5904 - val_loss: 0.1504 - val_recall: 0.6740 - val_precision: 0.5422 - val_f1_score: 0.5998\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 250s 12ms/step - loss: 0.1433 - recall: 0.6976 - precision: 0.5319 - f1_score: 0.6024 - val_loss: 0.1456 - val_recall: 0.7035 - val_precision: 0.5268 - val_f1_score: 0.6012\n",
      "\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 27s 4ms/step\n",
      "Recall: 0.7247567383179374\n",
      "Precision: 0.6159969875313563\n",
      "F1-Score: 0.6659568287010074\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)\n",
    "    \n",
    "    print('Shuffling...')\n",
    "    shuffled = [[X_train_ng[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = get_model_ng(vocab_size_ng)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(X_train_ng, y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('\\nEvaluating model...')\n",
    "    predictions = model.predict(X_test_ng)\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28840b",
   "metadata": {},
   "source": [
    "### Model using skip grams only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbba7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering skip grams\n",
    "X_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 17:39:47.284624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 17:39:53.993803: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384/21384 [==============================] - 557s 26ms/step - loss: 0.1993 - recall: 0.5741 - precision: 0.4177 - f1_score: 0.4810 - val_loss: 0.1806 - val_recall: 0.6024 - val_precision: 0.4882 - val_f1_score: 0.5380\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 551s 26ms/step - loss: 0.1734 - recall: 0.6401 - precision: 0.4770 - f1_score: 0.5452 - val_loss: 0.1662 - val_recall: 0.6701 - val_precision: 0.4749 - val_f1_score: 0.5545\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 549s 26ms/step - loss: 0.1606 - recall: 0.6654 - precision: 0.5028 - f1_score: 0.5714 - val_loss: 0.1579 - val_recall: 0.6658 - val_precision: 0.5175 - val_f1_score: 0.5812\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 552s 26ms/step - loss: 0.1517 - recall: 0.6815 - precision: 0.5180 - f1_score: 0.5873 - val_loss: 0.1516 - val_recall: 0.6782 - val_precision: 0.5285 - val_f1_score: 0.5929\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 551s 26ms/step - loss: 0.1449 - recall: 0.6945 - precision: 0.5291 - f1_score: 0.5994 - val_loss: 0.1474 - val_recall: 0.6902 - val_precision: 0.5328 - val_f1_score: 0.6002\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 67s 10ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 554s 26ms/step - loss: 0.1979 - recall: 0.5773 - precision: 0.4251 - f1_score: 0.4871 - val_loss: 0.1788 - val_recall: 0.6134 - val_precision: 0.4894 - val_f1_score: 0.5431\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 552s 26ms/step - loss: 0.1730 - recall: 0.6412 - precision: 0.4840 - f1_score: 0.5501 - val_loss: 0.1657 - val_recall: 0.6593 - val_precision: 0.5025 - val_f1_score: 0.5690\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 551s 26ms/step - loss: 0.1608 - recall: 0.6651 - precision: 0.5083 - f1_score: 0.5749 - val_loss: 0.1576 - val_recall: 0.6734 - val_precision: 0.5140 - val_f1_score: 0.5818\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 552s 26ms/step - loss: 0.1517 - recall: 0.6821 - precision: 0.5224 - f1_score: 0.5904 - val_loss: 0.1525 - val_recall: 0.6959 - val_precision: 0.5125 - val_f1_score: 0.5889\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 553s 26ms/step - loss: 0.1448 - recall: 0.6953 - precision: 0.5328 - f1_score: 0.6020 - val_loss: 0.1481 - val_recall: 0.6793 - val_precision: 0.5455 - val_f1_score: 0.6040\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 67s 10ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 555s 26ms/step - loss: 0.1992 - recall: 0.5756 - precision: 0.4185 - f1_score: 0.4820 - val_loss: 0.1795 - val_recall: 0.6307 - val_precision: 0.4584 - val_f1_score: 0.5295\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 550s 26ms/step - loss: 0.1733 - recall: 0.6404 - precision: 0.4790 - f1_score: 0.5466 - val_loss: 0.1664 - val_recall: 0.6429 - val_precision: 0.5085 - val_f1_score: 0.5667\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 551s 26ms/step - loss: 0.1611 - recall: 0.6652 - precision: 0.5052 - f1_score: 0.5729 - val_loss: 0.1573 - val_recall: 0.6661 - val_precision: 0.5225 - val_f1_score: 0.5845\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 549s 26ms/step - loss: 0.1521 - recall: 0.6822 - precision: 0.5214 - f1_score: 0.5897 - val_loss: 0.1513 - val_recall: 0.6849 - val_precision: 0.5260 - val_f1_score: 0.5938\n",
      "Epoch 5/5\n",
      " 8986/21384 [===========>..................] - ETA: 4:48 - loss: 0.1453 - recall: 0.6943 - precision: 0.5305 - f1_score: 0.6002"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_sg, y_train, X_test_sg, y_test, start_index, prev_index = train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "\n",
    "    print('Tokenizing...')\n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer1 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "    print('Shuffling...')\n",
    "    shuffled = [[X_train_sg[i],y_train[i]] for i in range(len(X_train_sg))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_sg = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "\n",
    "    model = get_model_sg(vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "    \n",
    "    print('Training...')\n",
    "    history = model.fit(X_train_sg, y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict(X_test_sg)\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84680b09",
   "metadata": {},
   "source": [
    "### Model using skip grams and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6163d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "X_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32366243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069179 1069179\n"
     ]
    }
   ],
   "source": [
    "print(len(X_ng),len(X_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaad7bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****Fold: 1 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 01:54:29.048860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 01:54:39.482304: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384/21384 [==============================] - 719s 33ms/step - loss: 0.1974 - recall: 0.5788 - precision: 0.4226 - f1_score: 0.4859 - val_loss: 0.1784 - val_recall: 0.6294 - val_precision: 0.4571 - val_f1_score: 0.5282\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 710s 33ms/step - loss: 0.1744 - recall: 0.6373 - precision: 0.4743 - f1_score: 0.5423 - val_loss: 0.1682 - val_recall: 0.6308 - val_precision: 0.5170 - val_f1_score: 0.5672\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 711s 33ms/step - loss: 0.1636 - recall: 0.6590 - precision: 0.4983 - f1_score: 0.5661 - val_loss: 0.1599 - val_recall: 0.6737 - val_precision: 0.5002 - val_f1_score: 0.5729\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 710s 33ms/step - loss: 0.1551 - recall: 0.6740 - precision: 0.5142 - f1_score: 0.5820 - val_loss: 0.1546 - val_recall: 0.6806 - val_precision: 0.5139 - val_f1_score: 0.5844\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 709s 33ms/step - loss: 0.1485 - recall: 0.6864 - precision: 0.5254 - f1_score: 0.5939 - val_loss: 0.1499 - val_recall: 0.6754 - val_precision: 0.5372 - val_f1_score: 0.5973\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 89s 13ms/step\n",
      "\n",
      "\n",
      "****Fold: 2 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 734s 34ms/step - loss: 0.1965 - recall: 0.5882 - precision: 0.4308 - f1_score: 0.4948 - val_loss: 0.1769 - val_recall: 0.6507 - val_precision: 0.4481 - val_f1_score: 0.5293\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1700 - recall: 0.6516 - precision: 0.4873 - f1_score: 0.5562 - val_loss: 0.1630 - val_recall: 0.6652 - val_precision: 0.5018 - val_f1_score: 0.5708\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1578 - recall: 0.6760 - precision: 0.5082 - f1_score: 0.5788 - val_loss: 0.1544 - val_recall: 0.6846 - val_precision: 0.5121 - val_f1_score: 0.5846\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1481 - recall: 0.6950 - precision: 0.5221 - f1_score: 0.5950 - val_loss: 0.1488 - val_recall: 0.6952 - val_precision: 0.5180 - val_f1_score: 0.5924\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1405 - recall: 0.7102 - precision: 0.5338 - f1_score: 0.6082 - val_loss: 0.1437 - val_recall: 0.6990 - val_precision: 0.5396 - val_f1_score: 0.6078\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 89s 13ms/step\n",
      "\n",
      "\n",
      "****Fold: 3 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 730s 34ms/step - loss: 0.1964 - recall: 0.5885 - precision: 0.4331 - f1_score: 0.4964 - val_loss: 0.1783 - val_recall: 0.6212 - val_precision: 0.4756 - val_f1_score: 0.5375\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 721s 34ms/step - loss: 0.1717 - recall: 0.6461 - precision: 0.4858 - f1_score: 0.5532 - val_loss: 0.1656 - val_recall: 0.6453 - val_precision: 0.5062 - val_f1_score: 0.5661\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 722s 34ms/step - loss: 0.1595 - recall: 0.6698 - precision: 0.5077 - f1_score: 0.5762 - val_loss: 0.1571 - val_recall: 0.6789 - val_precision: 0.5141 - val_f1_score: 0.5839\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 719s 34ms/step - loss: 0.1502 - recall: 0.6873 - precision: 0.5227 - f1_score: 0.5925 - val_loss: 0.1514 - val_recall: 0.6820 - val_precision: 0.5272 - val_f1_score: 0.5935\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 719s 34ms/step - loss: 0.1431 - recall: 0.7006 - precision: 0.5333 - f1_score: 0.6043 - val_loss: 0.1467 - val_recall: 0.6942 - val_precision: 0.5333 - val_f1_score: 0.6020\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 88s 13ms/step\n",
      "\n",
      "\n",
      "****Fold: 4 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 735s 34ms/step - loss: 0.1978 - recall: 0.5785 - precision: 0.4220 - f1_score: 0.4854 - val_loss: 0.1790 - val_recall: 0.6350 - val_precision: 0.4529 - val_f1_score: 0.5273\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1724 - recall: 0.6417 - precision: 0.4809 - f1_score: 0.5483 - val_loss: 0.1656 - val_recall: 0.6597 - val_precision: 0.4986 - val_f1_score: 0.5667\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1601 - recall: 0.6659 - precision: 0.5078 - f1_score: 0.5748 - val_loss: 0.1572 - val_recall: 0.6715 - val_precision: 0.5208 - val_f1_score: 0.5855\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1512 - recall: 0.6820 - precision: 0.5241 - f1_score: 0.5914 - val_loss: 0.1515 - val_recall: 0.6858 - val_precision: 0.5310 - val_f1_score: 0.5974\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 726s 34ms/step - loss: 0.1443 - recall: 0.6952 - precision: 0.5351 - f1_score: 0.6035 - val_loss: 0.1474 - val_recall: 0.6904 - val_precision: 0.5360 - val_f1_score: 0.6024\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 88s 13ms/step\n",
      "\n",
      "\n",
      "****Fold: 5 ****\n",
      "Splitting into train-test...\n",
      "Tokenizing...\n",
      "Shuffling...\n",
      "Training...\n",
      "Epoch 1/5\n",
      "21384/21384 [==============================] - 724s 34ms/step - loss: 0.1976 - recall: 0.5791 - precision: 0.4223 - f1_score: 0.4858 - val_loss: 0.1783 - val_recall: 0.6264 - val_precision: 0.4713 - val_f1_score: 0.5365\n",
      "Epoch 2/5\n",
      "21384/21384 [==============================] - 716s 33ms/step - loss: 0.1716 - recall: 0.6446 - precision: 0.4796 - f1_score: 0.5485 - val_loss: 0.1647 - val_recall: 0.6548 - val_precision: 0.5048 - val_f1_score: 0.5688\n",
      "Epoch 3/5\n",
      "21384/21384 [==============================] - 716s 33ms/step - loss: 0.1585 - recall: 0.6715 - precision: 0.5040 - f1_score: 0.5744 - val_loss: 0.1561 - val_recall: 0.6805 - val_precision: 0.5084 - val_f1_score: 0.5808\n",
      "Epoch 4/5\n",
      "21384/21384 [==============================] - 716s 34ms/step - loss: 0.1486 - recall: 0.6902 - precision: 0.5198 - f1_score: 0.5917 - val_loss: 0.1499 - val_recall: 0.6833 - val_precision: 0.5308 - val_f1_score: 0.5962\n",
      "Epoch 5/5\n",
      "21384/21384 [==============================] - 717s 34ms/step - loss: 0.1409 - recall: 0.7053 - precision: 0.5309 - f1_score: 0.6045 - val_loss: 0.1452 - val_recall: 0.6852 - val_precision: 0.5458 - val_f1_score: 0.6065\n",
      "Evaluating model...\n",
      "6683/6683 [==============================] - 88s 13ms/step\n",
      "Recall: 0.7157639211190479\n",
      "Precision: 0.6188008603773549\n",
      "F1-Score: 0.6637320829174087\n"
     ]
    }
   ],
   "source": [
    "Kfolds = 5\n",
    "prev_index = 0\n",
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(Kfolds):\n",
    "    print('\\n\\n****Fold:', i+1,'****')\n",
    "    \n",
    "    print('Splitting into train-test...')\n",
    "    X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index1 = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "    X_train_sg, _, X_test_sg, _, _, _= train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "    \n",
    "    prev_index = prev_index1\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)  \n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer2 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "   \n",
    "    print('Shuffling...')   \n",
    "    shuffled = [[X_train_ng[i],X_train_sg[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    X_train_sg = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][2] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    model = get_model_ng_sg(vocab_size_ng, vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "\n",
    "    print('Training...')\n",
    "    history = model.fit([X_train_ng,X_train_sg], y_train, batch_size=32, epochs=5,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict([X_test_ng,X_test_sg])\n",
    "    \n",
    "    rec, prec, f1 = compute_metrics(predictions, start_index, prev_index)\n",
    "    \n",
    "    recs.append(rec.numpy())\n",
    "    precs.append(prec.numpy())\n",
    "    f1s.append(f1.numpy())\n",
    "\n",
    "print('Recall:',sum(recs)/len(recs))\n",
    "print('Precision:',sum(precs)/len(precs))\n",
    "print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
