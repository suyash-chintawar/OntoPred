{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a056c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 29 16:28:05 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    52W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86add81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb10a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 16:28:07.538848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 16:28:07.700793: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10161890724206226324\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 16:28:10.894631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 16:28:10.912796: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-03-29 16:28:10.912825: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dgx\n",
      "2023-03-29 16:28:10.912836: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dgx\n",
      "2023-03-29 16:28:10.912888: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-03-29 16:28:10.912920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.106.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8be3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import math\n",
    "# import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e98a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = ['molecular','function']\n",
    "aspect_abbr = 'mf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce40988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'golabeler_train/mf_df.csv'\n",
    "# if not os.path.exists(file):\n",
    "#     url = \"https://drive.google.com/file/d/1RyeLQPFTMWAIr-OzELTWIx60ln-mZ7g_/view?usp=sharing\"\n",
    "#     output = file\n",
    "#     gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd949fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Entry</th>\n",
       "      <th>accessions</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (molecular function)</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>128UP_DROME</td>\n",
       "      <td>P32234; Q9V648;</td>\n",
       "      <td>MSTILEKISAIESEMARTQKNKATSAHLGLLKAKLAKLRRELISPK...</td>\n",
       "      <td>GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...</td>\n",
       "      <td>['IPR031167', 'IPR031662', 'IPR006074', 'IPR00...</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261</td>\n",
       "      <td>14310_ARATH</td>\n",
       "      <td>P48347; Q9LME5;</td>\n",
       "      <td>MENEREKQVYLAKLSEQTERYDEMVEAMKKVAQLDVELTVEERNLV...</td>\n",
       "      <td>GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>263</td>\n",
       "      <td>14311_ARATH</td>\n",
       "      <td>Q9S9Z8; A0JQ87; F4HWN0; Q0WL19;</td>\n",
       "      <td>MENERAKQVYLAKLNEQAERYDEMVEAMKKVAALDVELTIEERNLL...</td>\n",
       "      <td>GO:0051117;GO:0005515;GO:0005488;GO:0019899;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287</td>\n",
       "      <td>14333_ARATH</td>\n",
       "      <td>P42644; F4KBI7; Q945L2;</td>\n",
       "      <td>MSTREENVYMAKLAEQAERYEEMVEFMEKVAKTVDVEELSVEERNL...</td>\n",
       "      <td>GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296</td>\n",
       "      <td>14335_ARATH</td>\n",
       "      <td>P42645;</td>\n",
       "      <td>MSSDSSREENVYLAKLAEQAERYEEMVEFMEKVAKTVETEELTVEE...</td>\n",
       "      <td>GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34483</th>\n",
       "      <td>550264</td>\n",
       "      <td>ZYM1_SCHPO</td>\n",
       "      <td>Q9UTC0;</td>\n",
       "      <td>MEHTTQCKSKQGKPCDCQSKCGCQDCKESCGCKSSAVDNCKCSSCK...</td>\n",
       "      <td>GO:0043167;GO:0046914;GO:0043169;GO:0046872;GO...</td>\n",
       "      <td>['IPR001008']</td>\n",
       "      <td>284812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34484</th>\n",
       "      <td>550266</td>\n",
       "      <td>ZYX_CAEEL</td>\n",
       "      <td>Q9U3F4; H2L2F5; H2L2F6; H2L2F7; Q9U3F5;</td>\n",
       "      <td>MGPPPPPPPPPLLPSGEILPSRKWKTEDAPRRNNHPAPAPPKPSRP...</td>\n",
       "      <td>GO:0003674;GO:0005515;GO:0005488;GO:0019899</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34485</th>\n",
       "      <td>550267</td>\n",
       "      <td>ZYX_CHICK</td>\n",
       "      <td>Q04584;</td>\n",
       "      <td>MASPGTPGTRMTTTVSINISTPSFYNPQKKFAPVVAPKPKVNPFKT...</td>\n",
       "      <td>GO:0003674;GO:0008092;GO:0005515;GO:0005488</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>9031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34486</th>\n",
       "      <td>550268</td>\n",
       "      <td>ZYX_HUMAN</td>\n",
       "      <td>Q15942; A4D2G6; B4DQX7; Q6I9S4;</td>\n",
       "      <td>MAAPRPSPAISVSVSAPAFYAPQKKFGPVVAPKPKVNPFRPGDSEP...</td>\n",
       "      <td>GO:0003676;GO:0005488;GO:0003723;GO:0003674;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34487</th>\n",
       "      <td>550270</td>\n",
       "      <td>ZYX_XENLA</td>\n",
       "      <td>A5H447;</td>\n",
       "      <td>MDPAAPATRMTSSFTINISTPSFYNPPKKFAPVVPPKPKINPFKAP...</td>\n",
       "      <td>GO:0003674;GO:0005515;GO:0005488;GO:0008134</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>8355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34488 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        Entry                               accessions  \\\n",
       "0         240  128UP_DROME                          P32234; Q9V648;   \n",
       "1         261  14310_ARATH                          P48347; Q9LME5;   \n",
       "2         263  14311_ARATH          Q9S9Z8; A0JQ87; F4HWN0; Q0WL19;   \n",
       "3         287  14333_ARATH                  P42644; F4KBI7; Q945L2;   \n",
       "4         296  14335_ARATH                                  P42645;   \n",
       "...       ...          ...                                      ...   \n",
       "34483  550264   ZYM1_SCHPO                                  Q9UTC0;   \n",
       "34484  550266    ZYX_CAEEL  Q9U3F4; H2L2F5; H2L2F6; H2L2F7; Q9U3F5;   \n",
       "34485  550267    ZYX_CHICK                                  Q04584;   \n",
       "34486  550268    ZYX_HUMAN          Q15942; A4D2G6; B4DQX7; Q6I9S4;   \n",
       "34487  550270    ZYX_XENLA                                  A5H447;   \n",
       "\n",
       "                                                Sequence  \\\n",
       "0      MSTILEKISAIESEMARTQKNKATSAHLGLLKAKLAKLRRELISPK...   \n",
       "1      MENEREKQVYLAKLSEQTERYDEMVEAMKKVAQLDVELTVEERNLV...   \n",
       "2      MENERAKQVYLAKLNEQAERYDEMVEAMKKVAALDVELTIEERNLL...   \n",
       "3      MSTREENVYMAKLAEQAERYEEMVEFMEKVAKTVDVEELSVEERNL...   \n",
       "4      MSSDSSREENVYLAKLAEQAERYEEMVEFMEKVAKTVETEELTVEE...   \n",
       "...                                                  ...   \n",
       "34483  MEHTTQCKSKQGKPCDCQSKCGCQDCKESCGCKSSAVDNCKCSSCK...   \n",
       "34484  MGPPPPPPPPPLLPSGEILPSRKWKTEDAPRRNNHPAPAPPKPSRP...   \n",
       "34485  MASPGTPGTRMTTTVSINISTPSFYNPQKKFAPVVAPKPKVNPFKT...   \n",
       "34486  MAAPRPSPAISVSVSAPAFYAPQKKFGPVVAPKPKVNPFRPGDSEP...   \n",
       "34487  MDPAAPATRMTSSFTINISTPSFYNPPKKFAPVVPPKPKINPFKAP...   \n",
       "\n",
       "                      Gene Ontology (molecular function)  \\\n",
       "0      GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...   \n",
       "1      GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...   \n",
       "2      GO:0051117;GO:0005515;GO:0005488;GO:0019899;GO...   \n",
       "3      GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...   \n",
       "4      GO:0036094;GO:0043167;GO:0032553;GO:0017076;GO...   \n",
       "...                                                  ...   \n",
       "34483  GO:0043167;GO:0046914;GO:0043169;GO:0046872;GO...   \n",
       "34484        GO:0003674;GO:0005515;GO:0005488;GO:0019899   \n",
       "34485        GO:0003674;GO:0008092;GO:0005515;GO:0005488   \n",
       "34486  GO:0003676;GO:0005488;GO:0003723;GO:0003674;GO...   \n",
       "34487        GO:0003674;GO:0005515;GO:0005488;GO:0008134   \n",
       "\n",
       "                                               interpros    orgs  \n",
       "0      ['IPR031167', 'IPR031662', 'IPR006074', 'IPR00...    7227  \n",
       "1                ['IPR000308', 'IPR023409', 'IPR023410']    3702  \n",
       "2                ['IPR000308', 'IPR023409', 'IPR023410']    3702  \n",
       "3                ['IPR000308', 'IPR023409', 'IPR023410']    3702  \n",
       "4                ['IPR000308', 'IPR023409', 'IPR023410']    3702  \n",
       "...                                                  ...     ...  \n",
       "34483                                      ['IPR001008']  284812  \n",
       "34484                                      ['IPR001781']    6239  \n",
       "34485                                      ['IPR001781']    9031  \n",
       "34486                                      ['IPR001781']    9606  \n",
       "34487                                      ['IPR001781']    8355  \n",
       "\n",
       "[34488 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n"
     ]
    }
   ],
   "source": [
    "go_terms_bp = set()\n",
    "for idx, row in df.iterrows():\n",
    "    for term in row['Gene Ontology ('+' '.join(aspect)+')'].split(';'):\n",
    "        go_terms_bp.add(term)\n",
    "go_terms_bp = list(go_terms_bp)\n",
    "go_terms_bp.sort()\n",
    "print(len(go_terms_bp))\n",
    "# print(go_terms_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(sequence,segment_size=100,gap=30):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    end = segment_size\n",
    "    while end <= len(sequence):\n",
    "        segments.append(sequence[start:end])\n",
    "        start += gap\n",
    "        end += gap\n",
    "    last_segment = sequence[start:]\n",
    "    segments.append(last_segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def get_training_data(df,segment_size=100,gap=30):\n",
    "    training_data = list()\n",
    "    for idx,row in tqdm.tqdm(df.iterrows()):\n",
    "        labels = [0] * len(go_terms_bp)\n",
    "        for term in row['Gene Ontology ('+' '.join(aspect)+')'].split(';'):\n",
    "            labels[go_terms_bp.index(term)] = 1\n",
    "        segments = get_segments(row['Sequence'],segment_size,gap)\n",
    "        for segment in segments:\n",
    "            training_data.append([row['Entry'],segment,labels])\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1d6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c861be80b147ec804edf91b96d693e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601353\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data(df,gap=30)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(segment,n=3):\n",
    "    ngrams = []\n",
    "    for i in range(len(segment)-n+1):\n",
    "        ngrams.append(segment[i:i+n])\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5358736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecd234472c9429a89cfae86245c6b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of ngrams\n",
    "# if os.path.exists('bp/training_data_4grams.npy'):\n",
    "#     print('Loading saved ngrams...')\n",
    "#     training_data_ngrams = np.load('bp/training_data_4grams.npy',allow_pickle=True)\n",
    "# else:\n",
    "print('Preparing from scratch...')\n",
    "training_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_ngrams.append([training_data[i][0],get_ngrams(training_data[i][1],n=4),training_data[i][2]])\n",
    "        \n",
    "#     np.save('bp/training_data_4grams.npy',training_data_ngrams)\n",
    "    \n",
    "print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skip_grams(segment,skip=1,n=3):\n",
    "    skip_grams = []\n",
    "    window_size = skip + n\n",
    "    for i in range(len(segment)-window_size+1):\n",
    "        window = segment[i:i+window_size]\n",
    "        indices = list(range(window_size))\n",
    "        indices.pop(0)\n",
    "        for idx in indices[::-1]:\n",
    "            temp = ''\n",
    "            for j in range(window_size):\n",
    "                if j!=idx:\n",
    "                    temp+=window[j]\n",
    "            skip_grams.append(temp)\n",
    "\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa91e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6deeec7a6645be94db66083858dc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists('bp/training_data_skip1_4grams.npy'):\n",
    "#     print('Loading saved skip grams...')\n",
    "#     training_data_skip_grams = np.load('bp/training_data_skip1_4grams.npy',allow_pickle=True)\n",
    "# else:\n",
    "print('Preparing from scratch...')\n",
    "training_data_skip_grams = []\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_skip_grams.append([training_data[i][0],get_skip_grams(training_data[i][1],n=4),training_data[i][2]])\n",
    "#     np.save('bp/training_data_skip1_4grams.npy',training_data_skip_grams)\n",
    "print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d856c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4445aae0c090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e391f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming training_data as global variable\n",
    "\n",
    "def train_test_split(X,y,fold_no,prev_index,Kfolds=5):\n",
    "    test_split = 1/Kfolds\n",
    "    \n",
    "    start_index = prev_index\n",
    "    end_index = (fold_no + 1) * (test_split) * len(X)\n",
    "    end_index = round(end_index)\n",
    "    \n",
    "    if end_index==len(X):\n",
    "        end_index -= 1\n",
    "    \n",
    "    entry = training_data[end_index][0]\n",
    "    entries = [sample[0] for sample in training_data]\n",
    "    \n",
    "    first_occurence = entries.index(entry)\n",
    "    entries.reverse()\n",
    "    \n",
    "    last_occurence = entries.index(entry)\n",
    "    last_occurence = len(entries) - last_occurence - 1\n",
    "    \n",
    "    del entries\n",
    "    gc.collect()\n",
    "    \n",
    "    end_index = first_occurence if (abs(end_index-first_occurence) < abs(end_index-last_occurence)) else last_occurence\n",
    "    \n",
    "    X_test = X[start_index:end_index+1]\n",
    "    y_test = y[start_index:end_index+1]\n",
    "    X_train = X[:start_index]\n",
    "    X_train.extend(X[end_index+1:])\n",
    "    y_train = y[:start_index]\n",
    "    y_train.extend(y[end_index+1:])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, start_index, end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_WORDS = 13824\n",
    "# MAX_LEN_NG = 98 #100\n",
    "# MAX_LEN_SG = 291 #300\n",
    "MAX_WORDS = 331776\n",
    "MAX_LEN_NG = 97 #100\n",
    "MAX_LEN_SG = 384 #300\n",
    "# MAX_WORDS = 7962624\n",
    "# MAX_LEN_NG = 96 #100\n",
    "# MAX_LEN_SG = 475 #300\n",
    "\n",
    "def tokenization(X_train,X_test,maxlen):\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return X_train, X_test, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a7f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "false_negative_penalty = 6\n",
    "false_positive_penalty = 1\n",
    "\n",
    "def custom_loss(y_true, y_logit):\n",
    "\n",
    "    loss = float(0)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_logit = tf.cast(y_logit, tf.float32)\n",
    "    \n",
    "    first_term = false_negative_penalty * float(y_true) * - K.log(y_logit + K.epsilon())\n",
    "    second_term = false_positive_penalty * (1 - float(y_true)) * - K.log(1 - y_logit + K.epsilon())\n",
    "    \n",
    "    loss = K.mean(first_term+second_term)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    rec = recall(y_true,y_pred)\n",
    "    prec = precision(y_true,y_pred)\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c30cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True,**kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'return_sequences': self.return_sequences \n",
    "      })\n",
    "      return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03b912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 677 #For bp (Change according to aspects)\n",
    "\n",
    "def get_model_ng_sg(vocab_size_ng, vocab_size_sg):\n",
    "    #Input layers\n",
    "\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,)) \n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,)) \n",
    "\n",
    "    #embeddings\n",
    "    embedding_layer_ngrams = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "    embedding_layer_skip_grams = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    #BI-LSTMs for each of the inputs\n",
    "    sequence_output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True))(embedding_layer_ngrams)\n",
    "    attention_output_1 = attention(return_sequences=False)(sequence_output_1)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_1)\n",
    "\n",
    "    sequence_output_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(embedding_layer_skip_grams)\n",
    "    attention_output_2 = attention(return_sequences=False)(sequence_output_2)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.3)(attention_output_2)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_2)\n",
    "\n",
    "    max_layer = tf.keras.layers.Maximum()([dense_layer_1,dense_layer_2])\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            input_ngrams,\n",
    "            input_skip_grams\n",
    "        ], \n",
    "        outputs=max_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84680b09",
   "metadata": {},
   "source": [
    "### Model using skip grams and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6163d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_train_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "X_train_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y_train = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32366243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802 848802\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_ng),len(X_train_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27dfda2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Entry</th>\n",
       "      <th>accessions</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (molecular function)</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181</td>\n",
       "      <td>1028</td>\n",
       "      <td>3BHS7_MOUSE</td>\n",
       "      <td>Q9EQC1; A2RTR5;</td>\n",
       "      <td>MADSAQVPTLVYLVTGGCGFLGEHIVRMLLEREPRLRELRVFDLHL...</td>\n",
       "      <td>GO:0016491;GO:0003824;GO:0003674;GO:0016616;GO...</td>\n",
       "      <td>['IPR002225', 'IPR016040']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>1043</td>\n",
       "      <td>3BP1_MOUSE</td>\n",
       "      <td>P55194; E9QMQ2; Q99KK8;</td>\n",
       "      <td>MAESFKELDPDSSMGKALEMTCAIQNQLARILAEFEMTLERDVLQP...</td>\n",
       "      <td>GO:0017124;GO:0005515;GO:0005488;GO:0003674;GO...</td>\n",
       "      <td>['IPR027267', 'IPR004148', 'IPR008936', 'IPR00...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392</td>\n",
       "      <td>3170</td>\n",
       "      <td>AA3R_MOUSE</td>\n",
       "      <td>Q61618; Q9R202;</td>\n",
       "      <td>MEADNTTETDWLNITYITMEAAIGLCAVVGNMLVIWVVKLNPTLRT...</td>\n",
       "      <td>GO:0004930;GO:0004872;GO:0003674;GO:0004871;GO...</td>\n",
       "      <td>['IPR000466', 'IPR001634', 'IPR000276', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>462</td>\n",
       "      <td>3586</td>\n",
       "      <td>AARE_ARATH</td>\n",
       "      <td>Q84LM4; O23313;</td>\n",
       "      <td>MDSSGTDSAKELHVGLDPTTEEEYATQSKLLQEFINIPSIDKAWIF...</td>\n",
       "      <td>GO:0008233;GO:0017171;GO:0016787;GO:0008236;GO...</td>\n",
       "      <td>['IPR011042', 'IPR029058', 'IPR011659', 'IPR00...</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>4346</td>\n",
       "      <td>ABHD2_HUMAN</td>\n",
       "      <td>P08910; Q53G48; Q53GU0; Q5FVD9; Q8TC79;</td>\n",
       "      <td>MNAMLETPELPAVFDGVKLAAVAAVLYVIVRCLNLKSPTAPPDLYF...</td>\n",
       "      <td>GO:0005488;GO:0016787;GO:0016298;GO:0052689;GO...</td>\n",
       "      <td>['IPR029058', 'IPR000073', 'IPR000952', 'IPR01...</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>55712</td>\n",
       "      <td>551992</td>\n",
       "      <td>ZN683_HUMAN</td>\n",
       "      <td>Q8IZ20; Q5T141; Q5T146; Q5T147; Q5T149; Q8NEN4;</td>\n",
       "      <td>MKEESAAQLGCCHRPMALGGTGGSLSPSLDFQLFRGDQVFSACRPL...</td>\n",
       "      <td>GO:0044212;GO:0001191;GO:0005515;GO:0005488;GO...</td>\n",
       "      <td>['IPR007087', 'IPR015880', 'IPR013087']</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>55713</td>\n",
       "      <td>551993</td>\n",
       "      <td>ZN683_MOUSE</td>\n",
       "      <td>I7HJS4;</td>\n",
       "      <td>MKALDGLRESLYPSLDFQLYQDDQVCSADASQPLADSVGAHDLAWS...</td>\n",
       "      <td>GO:0044877;GO:0005488;GO:0003674;GO:0003682</td>\n",
       "      <td>['IPR007087', 'IPR015880', 'IPR013087']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>55718</td>\n",
       "      <td>552022</td>\n",
       "      <td>ZN704_MOUSE</td>\n",
       "      <td>Q9ERQ3; Q7TQL8; Q8BJW9;</td>\n",
       "      <td>MQARRLAKRPSLGSRRGGAAPAPAPEAAALGLPPPGPSPAAAPGSW...</td>\n",
       "      <td>GO:0035326;GO:0003690;GO:0044212;GO:0003676;GO...</td>\n",
       "      <td>['IPR007087']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>55732</td>\n",
       "      <td>552113</td>\n",
       "      <td>ZN809_MOUSE</td>\n",
       "      <td>G3X9G7; Q4KL58; Q8BIJ2;</td>\n",
       "      <td>MGLVSFEDVAVDFTLEEWQDLDAAQRTLYRDVMLETYSSLVFLDPC...</td>\n",
       "      <td>GO:0004527;GO:0016779;GO:0016772;GO:0016740;GO...</td>\n",
       "      <td>['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>55796</td>\n",
       "      <td>552531</td>\n",
       "      <td>ZOP1_ARATH</td>\n",
       "      <td>Q7XA66; Q94AV7; Q9FX87;</td>\n",
       "      <td>MTEYWVSQGNKWCEFCKIWIQNNPTSIRNHDLGKRHRECVDKKLTD...</td>\n",
       "      <td>GO:0003690;GO:0003676;GO:0005488;GO:0003723;GO...</td>\n",
       "      <td>['IPR000690', 'IPR003604', 'IPR013085']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0   index        Entry  \\\n",
       "0        181    1028  3BHS7_MOUSE   \n",
       "1        183    1043   3BP1_MOUSE   \n",
       "2        392    3170   AA3R_MOUSE   \n",
       "3        462    3586   AARE_ARATH   \n",
       "4        716    4346  ABHD2_HUMAN   \n",
       "..       ...     ...          ...   \n",
       "674    55712  551992  ZN683_HUMAN   \n",
       "675    55713  551993  ZN683_MOUSE   \n",
       "676    55718  552022  ZN704_MOUSE   \n",
       "677    55732  552113  ZN809_MOUSE   \n",
       "678    55796  552531   ZOP1_ARATH   \n",
       "\n",
       "                                          accessions  \\\n",
       "0                                    Q9EQC1; A2RTR5;   \n",
       "1                            P55194; E9QMQ2; Q99KK8;   \n",
       "2                                    Q61618; Q9R202;   \n",
       "3                                    Q84LM4; O23313;   \n",
       "4            P08910; Q53G48; Q53GU0; Q5FVD9; Q8TC79;   \n",
       "..                                               ...   \n",
       "674  Q8IZ20; Q5T141; Q5T146; Q5T147; Q5T149; Q8NEN4;   \n",
       "675                                          I7HJS4;   \n",
       "676                          Q9ERQ3; Q7TQL8; Q8BJW9;   \n",
       "677                          G3X9G7; Q4KL58; Q8BIJ2;   \n",
       "678                          Q7XA66; Q94AV7; Q9FX87;   \n",
       "\n",
       "                                              Sequence  \\\n",
       "0    MADSAQVPTLVYLVTGGCGFLGEHIVRMLLEREPRLRELRVFDLHL...   \n",
       "1    MAESFKELDPDSSMGKALEMTCAIQNQLARILAEFEMTLERDVLQP...   \n",
       "2    MEADNTTETDWLNITYITMEAAIGLCAVVGNMLVIWVVKLNPTLRT...   \n",
       "3    MDSSGTDSAKELHVGLDPTTEEEYATQSKLLQEFINIPSIDKAWIF...   \n",
       "4    MNAMLETPELPAVFDGVKLAAVAAVLYVIVRCLNLKSPTAPPDLYF...   \n",
       "..                                                 ...   \n",
       "674  MKEESAAQLGCCHRPMALGGTGGSLSPSLDFQLFRGDQVFSACRPL...   \n",
       "675  MKALDGLRESLYPSLDFQLYQDDQVCSADASQPLADSVGAHDLAWS...   \n",
       "676  MQARRLAKRPSLGSRRGGAAPAPAPEAAALGLPPPGPSPAAAPGSW...   \n",
       "677  MGLVSFEDVAVDFTLEEWQDLDAAQRTLYRDVMLETYSSLVFLDPC...   \n",
       "678  MTEYWVSQGNKWCEFCKIWIQNNPTSIRNHDLGKRHRECVDKKLTD...   \n",
       "\n",
       "                    Gene Ontology (molecular function)  \\\n",
       "0    GO:0016491;GO:0003824;GO:0003674;GO:0016616;GO...   \n",
       "1    GO:0017124;GO:0005515;GO:0005488;GO:0003674;GO...   \n",
       "2    GO:0004930;GO:0004872;GO:0003674;GO:0004871;GO...   \n",
       "3    GO:0008233;GO:0017171;GO:0016787;GO:0008236;GO...   \n",
       "4    GO:0005488;GO:0016787;GO:0016298;GO:0052689;GO...   \n",
       "..                                                 ...   \n",
       "674  GO:0044212;GO:0001191;GO:0005515;GO:0005488;GO...   \n",
       "675        GO:0044877;GO:0005488;GO:0003674;GO:0003682   \n",
       "676  GO:0035326;GO:0003690;GO:0044212;GO:0003676;GO...   \n",
       "677  GO:0004527;GO:0016779;GO:0016772;GO:0016740;GO...   \n",
       "678  GO:0003690;GO:0003676;GO:0005488;GO:0003723;GO...   \n",
       "\n",
       "                                             interpros   orgs  \n",
       "0                           ['IPR002225', 'IPR016040']  10090  \n",
       "1    ['IPR027267', 'IPR004148', 'IPR008936', 'IPR00...  10090  \n",
       "2    ['IPR000466', 'IPR001634', 'IPR000276', 'IPR01...  10090  \n",
       "3    ['IPR011042', 'IPR029058', 'IPR011659', 'IPR00...   3702  \n",
       "4    ['IPR029058', 'IPR000073', 'IPR000952', 'IPR01...   9606  \n",
       "..                                                 ...    ...  \n",
       "674            ['IPR007087', 'IPR015880', 'IPR013087']   9606  \n",
       "675            ['IPR007087', 'IPR015880', 'IPR013087']  10090  \n",
       "676                                      ['IPR007087']  10090  \n",
       "677  ['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...  10090  \n",
       "678            ['IPR000690', 'IPR003604', 'IPR013085']   3702  \n",
       "\n",
       "[679 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('golabeler_test/mf_df.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37914add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5772c20c4ea49a2b6292b2cd51c26ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9913\n"
     ]
    }
   ],
   "source": [
    "testing_data = get_training_data(test_df,gap=30)\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedb4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e24c753a794bbb9664055045e11f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print('Preparing from scratch...')\n",
    "testing_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(testing_data))):\n",
    "    testing_data_ngrams.append([testing_data[i][0],get_ngrams(testing_data[i][1],n=4),testing_data[i][2]])\n",
    "    \n",
    "print(len(testing_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1d8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42add90f6e914a2897ef1ee3742b221c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print('Preparing from scratch...')\n",
    "testing_data_skip_grams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(testing_data))):\n",
    "    testing_data_skip_grams.append([testing_data[i][0],get_skip_grams(testing_data[i][1],n=4),testing_data[i][2]])\n",
    "    \n",
    "print(len(testing_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eac38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_test_ng = [' '.join(sample[1]) for sample in testing_data_ngrams]\n",
    "X_test_sg = [' '.join(sample[1]) for sample in testing_data_skip_grams]\n",
    "y_test = [sample[2] for sample in testing_data]\n",
    "\n",
    "del testing_data_ngrams\n",
    "del testing_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2079b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753 22753\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test_ng),len(X_test_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f8a951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recs = []\n",
    "# precs = []\n",
    "# f1s = []\n",
    "\n",
    "# for i in range(1):\n",
    "    \n",
    "# #     print('Splitting into train-test...')\n",
    "# #     X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index1 = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "# #     X_train_sg, _, X_test_sg, _, _, _= train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "    \n",
    "# #     prev_index = prev_index1\n",
    "    \n",
    "#     print('Tokenizing...')\n",
    "#     X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)  \n",
    "#     X_train_sg, X_test_sg, vocabsize_sg, tokenizer2 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "   \n",
    "# print('Shuffling...')   \n",
    "#     shuffled = [[X_train_ng[i],X_train_sg[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "#     np.random.shuffle(shuffled)\n",
    "\n",
    "#     X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "#     X_train_sg = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "#     y_train = [shuffled[i][2] for i in range(len(shuffled))]\n",
    "#     X_train_ng = np.array(X_train_ng)\n",
    "#     X_train_sg = np.array(X_train_sg)\n",
    "#     y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "#     model = get_model_ng_sg(vocab_size_ng, vocab_size_sg)\n",
    "    \n",
    "#     model.compile(\n",
    "#         loss=custom_loss, \n",
    "#         optimizer='adam', \n",
    "#         metrics=[\n",
    "#             recall,\n",
    "#             precision,\n",
    "#             f1_score\n",
    "#         ])\n",
    "\n",
    "#     print('Training...')\n",
    "#     history = model.fit([X_train_ng,X_train_sg], y_train, batch_size=32, epochs=10,validation_split=0.2)\n",
    "    \n",
    "#     print('Evaluating model...')\n",
    "#     predictions = model.predict([X_test_ng,X_test_sg])\n",
    "    \n",
    "#     print('Computing Metrics...\\n')\n",
    "#     compute_metrics(predictions)\n",
    "    \n",
    "# #     recs.append(rec.numpy())\n",
    "# #     precs.append(prec.numpy())\n",
    "# #     f1s.append(f1.numpy())\n",
    "\n",
    "# # print('Recall:',sum(recs)/len(recs))\n",
    "# # print('Precision:',sum(precs)/len(precs))\n",
    "# # print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66234f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FUNC_DICT, Ontology, NAMESPACES\n",
    "NUM_CLASSES = 652\n",
    "\n",
    "train_df_original = pd.read_pickle('data_golabeler/train_data.pkl')\n",
    "test_df_original = pd.read_pickle('data_golabeler/test_data.pkl')\n",
    "annotations = train_df_original['annotations'].values\n",
    "annotations = list(map(lambda x: set(x), annotations))\n",
    "test_annotations = test_df_original['annotations'].values\n",
    "test_annotations = list(map(lambda x: set(x), test_annotations))\n",
    "\n",
    "go_rels = Ontology('data_golabeler/go.obo', with_rels=True)\n",
    "go_rels.calculate_ic(annotations + test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08fb6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_annotations(real_annots, pred_annots):\n",
    "    total = 0\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    p_total= 0\n",
    "    fps = []\n",
    "    fns = []\n",
    "    ru = 0.0\n",
    "    mi = 0.0\n",
    "    for i in range(len(real_annots)):\n",
    "        if len(real_annots[i]) == 0:\n",
    "            continue\n",
    "        tp = set(real_annots[i]).intersection(set(pred_annots[i]))\n",
    "        fp = set(pred_annots[i]) - tp\n",
    "        fn = set(real_annots[i]) - tp\n",
    "        for go_id in fp:\n",
    "            mi += go_rels.get_ic(go_id)\n",
    "        for go_id in fn:\n",
    "            ru += go_rels.get_ic(go_id)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        tpn = len(tp)\n",
    "        fpn = len(fp)\n",
    "        fnn = len(fn)\n",
    "        total += 1\n",
    "        recall = tpn / (1.0 * (tpn + fnn))\n",
    "        r += recall\n",
    "        if len(pred_annots[i]) > 0:\n",
    "            p_total += 1\n",
    "            precision = tpn / (1.0 * (tpn + fpn))\n",
    "            p += precision\n",
    "    ru /= total\n",
    "    mi /= total\n",
    "    r /= total\n",
    "    if p_total > 0:\n",
    "        p /= p_total\n",
    "    f = 0.0\n",
    "    if p + r > 0:\n",
    "        f = 2 * p * r / (p + r)\n",
    "    s = math.sqrt(ru * ru + mi * mi)\n",
    "    return f, p, r, fps, fns, s, ru, mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d5d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d734cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('bp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb50bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('bp_predictions',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab990bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9913\n"
     ]
    }
   ],
   "source": [
    "predictions = np.load('mf_predictions.npy')\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "704437fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.37002205e-05, 4.73381428e-04, 6.45921682e-06, ...,\n",
       "        1.07720567e-04, 4.05911322e-07, 9.59987392e-06],\n",
       "       [2.45178535e-06, 4.49660118e-04, 2.21478680e-04, ...,\n",
       "        1.64869925e-05, 8.39662562e-07, 2.57629199e-06],\n",
       "       [9.05660499e-07, 1.17652562e-04, 1.58497423e-04, ...,\n",
       "        6.34262096e-06, 2.14534225e-07, 3.66777499e-07],\n",
       "       ...,\n",
       "       [6.85388441e-05, 1.38855372e-02, 4.80502385e-05, ...,\n",
       "        1.02323656e-05, 2.29324291e-06, 3.51360562e-04],\n",
       "       [2.12440835e-04, 2.94244587e-02, 1.14580682e-04, ...,\n",
       "        1.02944352e-04, 1.29467971e-05, 1.06858926e-04],\n",
       "       [1.63179466e-05, 1.78359970e-02, 5.94522979e-04, ...,\n",
       "        8.51146528e-04, 1.42767021e-04, 1.12166964e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2506bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = []\n",
    "for i in range(len(df)):\n",
    "    terms_set = set(df.iloc[i]['Gene Ontology ('+' '.join(aspect)+')'].split(';'))\n",
    "    train_annotations.append(terms_set)\n",
    "\n",
    "prot_index = {}\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    prot_index[row.Entry] = i\n",
    "\n",
    "diamond_scores_file = 'data_golabeler/golabeler_matches_mf.tsv'\n",
    "diamond_scores = {}\n",
    "with open(diamond_scores_file) as f:\n",
    "    for line in f:\n",
    "        it = line.strip().split()\n",
    "        if it[0] not in diamond_scores:\n",
    "            diamond_scores[it[0]] = {}\n",
    "        diamond_scores[it[0]][it[1]] = float(it[2])\n",
    "\n",
    "blast_preds = []\n",
    "#print('Diamond preds')\n",
    "for i, row in enumerate(test_df.itertuples()):\n",
    "    annots = {}\n",
    "    prot_id = row.Entry\n",
    "    # BlastKNN\n",
    "    if prot_id in diamond_scores:\n",
    "        sim_prots = diamond_scores[prot_id]\n",
    "        allgos = set()\n",
    "        total_score = 0.0\n",
    "        for p_id, score in sim_prots.items():\n",
    "            allgos |= train_annotations[prot_index[p_id]]\n",
    "            total_score += score\n",
    "        allgos = list(sorted(allgos))\n",
    "        sim = np.zeros(len(allgos), dtype=np.float32)\n",
    "        for j, go_id in enumerate(allgos):\n",
    "            s = 0.0\n",
    "            for p_id, score in sim_prots.items():\n",
    "                if go_id in train_annotations[prot_index[p_id]]:\n",
    "                    s += score\n",
    "            sim[j] = s / total_score\n",
    "        ind = np.argsort(-sim)\n",
    "        for go_id, score in zip(allgos, sim):\n",
    "            annots[go_id] = score\n",
    "    blast_preds.append(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "746a9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for term in blast_preds[0].keys():\n",
    "    if term not in go_terms_bp:\n",
    "        print(term)\n",
    "        count+=1\n",
    "print(count)\n",
    "print(len(blast_preds[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "537c58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "actual_y_test = []\n",
    "\n",
    "current_entry = ''\n",
    "counter = 0\n",
    "total_counts = 0\n",
    "start_index = 0\n",
    "\n",
    "if len(predictions) == len(testing_data):\n",
    "    temp = np.zeros(NUM_CLASSES)\n",
    "    for i in range(len(predictions)):\n",
    "        if current_entry != testing_data[start_index+i][0]:\n",
    "            #compute prev\n",
    "            if i!=0:\n",
    "                temp /= counter\n",
    "                final_predictions.append(temp)\n",
    "\n",
    "            #reset\n",
    "            total_counts += counter\n",
    "            counter = 1\n",
    "            temp = np.zeros(NUM_CLASSES)\n",
    "\n",
    "            #init new\n",
    "            current_entry = testing_data[start_index+i][0]\n",
    "            temp += np.array(predictions[i])\n",
    "            actual_y_test.append(testing_data[start_index+i][2])\n",
    "        else:\n",
    "            temp += np.array(predictions[i])\n",
    "            counter += 1\n",
    "\n",
    "    total_counts += counter\n",
    "    temp /= counter\n",
    "    final_predictions.append(temp)\n",
    "\n",
    "else:\n",
    "    print('Lengths of predictions dont match with test data')\n",
    "\n",
    "final_predictions = np.array(final_predictions, dtype=float)\n",
    "actual_y_test = np.array(actual_y_test, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f4065d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c8c15f77544163a49c9ce2e3d0934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fmax: 0.644, Smin: 6.984, threshold: 0.5, AUPR: 0.616\n"
     ]
    }
   ],
   "source": [
    "best_fmax = 0.0    \n",
    "final_predictions_avg = copy.deepcopy(final_predictions)\n",
    "for i in range(len(final_predictions_avg)):\n",
    "    for j in range(len(go_terms_bp)):\n",
    "        if go_terms_bp[j] in blast_preds[i].keys():\n",
    "            final_predictions_avg[i][j] = (blast_preds[i][go_terms_bp[j]] + final_predictions_avg[i][j])/2\n",
    "\n",
    "fmax = 0.0\n",
    "tmax = 0.0\n",
    "precisions = []\n",
    "recalls = []\n",
    "smin = 1000000.0\n",
    "rus = []\n",
    "mis = []\n",
    "    \n",
    "\n",
    "for t in tqdm.tqdm(range(0, 101)):\n",
    "\n",
    "    threshold = t / 100.0\n",
    "    pred_annots = []\n",
    "    real_annots = []\n",
    "    for i in range(len(final_predictions_avg)):\n",
    "        new_preds = []\n",
    "        new_ys = []\n",
    "        for j in range(NUM_CLASSES):\n",
    "            if final_predictions_avg[i][j]>=threshold:\n",
    "                new_preds.append(go_terms_bp[j]) #GO_TERMS_BP\n",
    "            if actual_y_test[i][j]==1:\n",
    "                new_ys.append(go_terms_bp[j])\n",
    "        pred_annots.append(new_preds)\n",
    "        real_annots.append(new_ys)\n",
    "\n",
    "    fscore, prec, rec, fps, fns, s, ru, mi = evaluate_annotations(real_annots, pred_annots)\n",
    "    avg_fp = sum(map(lambda x: len(x), fps)) / len(fps)\n",
    "    avg_ic = sum(map(lambda x: sum(map(lambda go_id: go_rels.get_ic(go_id), x)), fps)) / len(fps)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "    if fmax < fscore:\n",
    "        fmax = fscore\n",
    "        tmax = threshold\n",
    "    if smin > s:\n",
    "        smin = s\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "sorted_index = np.argsort(recalls)\n",
    "recalls = recalls[sorted_index]\n",
    "precisions = precisions[sorted_index]\n",
    "aupr = np.trapz(precisions, recalls)\n",
    "\n",
    "print(f'Fmax: {fmax:0.3f}, Smin: {smin:0.3f}, threshold: {tmax}, AUPR: {aupr:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7e2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
