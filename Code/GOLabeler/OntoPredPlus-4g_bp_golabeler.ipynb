{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a056c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 29 16:28:05 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    52W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86add81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb10a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 16:28:07.538848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 16:28:07.700793: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10161890724206226324\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 16:28:10.894631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 16:28:10.912796: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-03-29 16:28:10.912825: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dgx\n",
      "2023-03-29 16:28:10.912836: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dgx\n",
      "2023-03-29 16:28:10.912888: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2023-03-29 16:28:10.912920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.106.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8be3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import math\n",
    "# import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e98a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = ['biological','process']\n",
    "aspect_abbr = 'bp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce40988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'golabeler_train/bp_df.csv'\n",
    "# if not os.path.exists(file):\n",
    "#     url = \"https://drive.google.com/file/d/1RyeLQPFTMWAIr-OzELTWIx60ln-mZ7g_/view?usp=sharing\"\n",
    "#     output = file\n",
    "#     gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd949fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Entry</th>\n",
       "      <th>accessions</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (biological process)</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>140U_DROME</td>\n",
       "      <td>P81928; Q9VFM8;</td>\n",
       "      <td>MNFLWKGRRFLIAGILPTFEGAADEIVDKENKTYKAFLASKPPEET...</td>\n",
       "      <td>GO:0007275;GO:0044707;GO:0032502;GO:0044699;GO...</td>\n",
       "      <td>['IPR003397']</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261</td>\n",
       "      <td>14310_ARATH</td>\n",
       "      <td>P48347; Q9LME5;</td>\n",
       "      <td>MENEREKQVYLAKLSEQTERYDEMVEAMKKVAQLDVELTVEERNLV...</td>\n",
       "      <td>GO:0014070;GO:0043401;GO:0001101;GO:0051716;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>265</td>\n",
       "      <td>14331_ARATH</td>\n",
       "      <td>P42643; Q945M2; Q9M0S7;</td>\n",
       "      <td>MATPGASSARDEFVYMAKLAEQAERYEEMVEFMEKVAKAVDKDELT...</td>\n",
       "      <td>GO:0050789;GO:0019222;GO:0065007;GO:0008150;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266</td>\n",
       "      <td>14331_CAEEL</td>\n",
       "      <td>P41932; Q21537;</td>\n",
       "      <td>MSDTVEELVQRAKLAEQAERYDDMAAAMKKVTEQGQELSNEERNLL...</td>\n",
       "      <td>GO:0009792;GO:0009566;GO:0040001;GO:0044763;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>14332_ARATH</td>\n",
       "      <td>Q01525;</td>\n",
       "      <td>MASGREEFVYMAKLAEQAERYEEMVEFMEKVSAAVDGDELTVEERN...</td>\n",
       "      <td>GO:0014070;GO:0043401;GO:0051716;GO:0065007;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51711</th>\n",
       "      <td>550266</td>\n",
       "      <td>ZYX_CAEEL</td>\n",
       "      <td>Q9U3F4; H2L2F5; H2L2F6; H2L2F7; Q9U3F5;</td>\n",
       "      <td>MGPPPPPPPPPLLPSGEILPSRKWKTEDAPRRNNHPAPAPPKPSRP...</td>\n",
       "      <td>GO:0000003;GO:0008150</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51712</th>\n",
       "      <td>550268</td>\n",
       "      <td>ZYX_HUMAN</td>\n",
       "      <td>Q15942; A4D2G6; B4DQX7; Q6I9S4;</td>\n",
       "      <td>MAAPRPSPAISVSVSAPAFYAPQKKFGPVVAPKPKVNPFRPGDSEP...</td>\n",
       "      <td>GO:1902589;GO:0051716;GO:0065007;GO:0007167;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51713</th>\n",
       "      <td>550269</td>\n",
       "      <td>ZYX_MOUSE</td>\n",
       "      <td>Q62523; P70461; Q3UGQ3;</td>\n",
       "      <td>MAAPRPPPAISVSVSAPAFYAPQKKFAPVVAPKPKVNPFRPGDSEP...</td>\n",
       "      <td>GO:0051716;GO:0065007;GO:0007179;GO:0007167;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51714</th>\n",
       "      <td>550270</td>\n",
       "      <td>ZYX_XENLA</td>\n",
       "      <td>A5H447;</td>\n",
       "      <td>MDPAAPATRMTSSFTINISTPSFYNPPKKFAPVVPPKPKINPFKAP...</td>\n",
       "      <td>GO:0019438;GO:0019222;GO:0044237;GO:0006725;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>8355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51715</th>\n",
       "      <td>550274</td>\n",
       "      <td>ZZZ3_HUMAN</td>\n",
       "      <td>Q8IYH5; B7WPC6; Q6N004; Q6N070; Q8IYP0; Q8IYR1...</td>\n",
       "      <td>MAASRSTRVTRSTVGLNGLDESFCGRTLRNRSIAHPEEISSNSQVR...</td>\n",
       "      <td>GO:0006325;GO:0071840;GO:0051276;GO:0016043;GO...</td>\n",
       "      <td>['IPR009057', 'IPR017930', 'IPR001005', 'IPR00...</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51716 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        Entry                                         accessions  \\\n",
       "0         259   140U_DROME                                    P81928; Q9VFM8;   \n",
       "1         261  14310_ARATH                                    P48347; Q9LME5;   \n",
       "2         265  14331_ARATH                            P42643; Q945M2; Q9M0S7;   \n",
       "3         266  14331_CAEEL                                    P41932; Q21537;   \n",
       "4         276  14332_ARATH                                            Q01525;   \n",
       "...       ...          ...                                                ...   \n",
       "51711  550266    ZYX_CAEEL            Q9U3F4; H2L2F5; H2L2F6; H2L2F7; Q9U3F5;   \n",
       "51712  550268    ZYX_HUMAN                    Q15942; A4D2G6; B4DQX7; Q6I9S4;   \n",
       "51713  550269    ZYX_MOUSE                            Q62523; P70461; Q3UGQ3;   \n",
       "51714  550270    ZYX_XENLA                                            A5H447;   \n",
       "51715  550274   ZZZ3_HUMAN  Q8IYH5; B7WPC6; Q6N004; Q6N070; Q8IYP0; Q8IYR1...   \n",
       "\n",
       "                                                Sequence  \\\n",
       "0      MNFLWKGRRFLIAGILPTFEGAADEIVDKENKTYKAFLASKPPEET...   \n",
       "1      MENEREKQVYLAKLSEQTERYDEMVEAMKKVAQLDVELTVEERNLV...   \n",
       "2      MATPGASSARDEFVYMAKLAEQAERYEEMVEFMEKVAKAVDKDELT...   \n",
       "3      MSDTVEELVQRAKLAEQAERYDDMAAAMKKVTEQGQELSNEERNLL...   \n",
       "4      MASGREEFVYMAKLAEQAERYEEMVEFMEKVSAAVDGDELTVEERN...   \n",
       "...                                                  ...   \n",
       "51711  MGPPPPPPPPPLLPSGEILPSRKWKTEDAPRRNNHPAPAPPKPSRP...   \n",
       "51712  MAAPRPSPAISVSVSAPAFYAPQKKFGPVVAPKPKVNPFRPGDSEP...   \n",
       "51713  MAAPRPPPAISVSVSAPAFYAPQKKFAPVVAPKPKVNPFRPGDSEP...   \n",
       "51714  MDPAAPATRMTSSFTINISTPSFYNPPKKFAPVVPPKPKINPFKAP...   \n",
       "51715  MAASRSTRVTRSTVGLNGLDESFCGRTLRNRSIAHPEEISSNSQVR...   \n",
       "\n",
       "                      Gene Ontology (biological process)  \\\n",
       "0      GO:0007275;GO:0044707;GO:0032502;GO:0044699;GO...   \n",
       "1      GO:0014070;GO:0043401;GO:0001101;GO:0051716;GO...   \n",
       "2      GO:0050789;GO:0019222;GO:0065007;GO:0008150;GO...   \n",
       "3      GO:0009792;GO:0009566;GO:0040001;GO:0044763;GO...   \n",
       "4      GO:0014070;GO:0043401;GO:0051716;GO:0065007;GO...   \n",
       "...                                                  ...   \n",
       "51711                              GO:0000003;GO:0008150   \n",
       "51712  GO:1902589;GO:0051716;GO:0065007;GO:0007167;GO...   \n",
       "51713  GO:0051716;GO:0065007;GO:0007179;GO:0007167;GO...   \n",
       "51714  GO:0019438;GO:0019222;GO:0044237;GO:0006725;GO...   \n",
       "51715  GO:0006325;GO:0071840;GO:0051276;GO:0016043;GO...   \n",
       "\n",
       "                                               interpros   orgs  \n",
       "0                                          ['IPR003397']   7227  \n",
       "1                ['IPR000308', 'IPR023409', 'IPR023410']   3702  \n",
       "2                ['IPR000308', 'IPR023409', 'IPR023410']   3702  \n",
       "3                ['IPR000308', 'IPR023409', 'IPR023410']   6239  \n",
       "4                ['IPR000308', 'IPR023409', 'IPR023410']   3702  \n",
       "...                                                  ...    ...  \n",
       "51711                                      ['IPR001781']   6239  \n",
       "51712                                      ['IPR001781']   9606  \n",
       "51713                                      ['IPR001781']  10090  \n",
       "51714                                      ['IPR001781']   8355  \n",
       "51715  ['IPR009057', 'IPR017930', 'IPR001005', 'IPR00...   9606  \n",
       "\n",
       "[51716 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3904\n"
     ]
    }
   ],
   "source": [
    "go_terms_bp = set()\n",
    "for idx, row in df.iterrows():\n",
    "    for term in row['Gene Ontology ('+' '.join(aspect)+')'].split(';'):\n",
    "        go_terms_bp.add(term)\n",
    "go_terms_bp = list(go_terms_bp)\n",
    "go_terms_bp.sort()\n",
    "print(len(go_terms_bp))\n",
    "# print(go_terms_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(sequence,segment_size=100,gap=30):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    end = segment_size\n",
    "    while end <= len(sequence):\n",
    "        segments.append(sequence[start:end])\n",
    "        start += gap\n",
    "        end += gap\n",
    "    last_segment = sequence[start:]\n",
    "    segments.append(last_segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def get_training_data(df,segment_size=100,gap=30):\n",
    "    training_data = list()\n",
    "    for idx,row in tqdm.tqdm(df.iterrows()):\n",
    "        labels = [0] * len(go_terms_bp)\n",
    "        for term in row['Gene Ontology ('+' '.join(aspect)+')'].split(';'):\n",
    "            labels[go_terms_bp.index(term)] = 1\n",
    "        segments = get_segments(row['Sequence'],segment_size,gap)\n",
    "        for segment in segments:\n",
    "            training_data.append([row['Entry'],segment,labels])\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1d6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c861be80b147ec804edf91b96d693e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601353\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data(df,gap=30)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(segment,n=3):\n",
    "    ngrams = []\n",
    "    for i in range(len(segment)-n+1):\n",
    "        ngrams.append(segment[i:i+n])\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5358736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecd234472c9429a89cfae86245c6b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of ngrams\n",
    "# if os.path.exists('bp/training_data_4grams.npy'):\n",
    "#     print('Loading saved ngrams...')\n",
    "#     training_data_ngrams = np.load('bp/training_data_4grams.npy',allow_pickle=True)\n",
    "# else:\n",
    "print('Preparing from scratch...')\n",
    "training_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_ngrams.append([training_data[i][0],get_ngrams(training_data[i][1],n=4),training_data[i][2]])\n",
    "        \n",
    "#     np.save('bp/training_data_4grams.npy',training_data_ngrams)\n",
    "    \n",
    "print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skip_grams(segment,skip=1,n=3):\n",
    "    skip_grams = []\n",
    "    window_size = skip + n\n",
    "    for i in range(len(segment)-window_size+1):\n",
    "        window = segment[i:i+window_size]\n",
    "        indices = list(range(window_size))\n",
    "        indices.pop(0)\n",
    "        for idx in indices[::-1]:\n",
    "            temp = ''\n",
    "            for j in range(window_size):\n",
    "                if j!=idx:\n",
    "                    temp+=window[j]\n",
    "            skip_grams.append(temp)\n",
    "\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa91e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6deeec7a6645be94db66083858dc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists('bp/training_data_skip1_4grams.npy'):\n",
    "#     print('Loading saved skip grams...')\n",
    "#     training_data_skip_grams = np.load('bp/training_data_skip1_4grams.npy',allow_pickle=True)\n",
    "# else:\n",
    "print('Preparing from scratch...')\n",
    "training_data_skip_grams = []\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_skip_grams.append([training_data[i][0],get_skip_grams(training_data[i][1],n=4),training_data[i][2]])\n",
    "#     np.save('bp/training_data_skip1_4grams.npy',training_data_skip_grams)\n",
    "print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d856c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4445aae0c090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e391f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming training_data as global variable\n",
    "\n",
    "def train_test_split(X,y,fold_no,prev_index,Kfolds=5):\n",
    "    test_split = 1/Kfolds\n",
    "    \n",
    "    start_index = prev_index\n",
    "    end_index = (fold_no + 1) * (test_split) * len(X)\n",
    "    end_index = round(end_index)\n",
    "    \n",
    "    if end_index==len(X):\n",
    "        end_index -= 1\n",
    "    \n",
    "    entry = training_data[end_index][0]\n",
    "    entries = [sample[0] for sample in training_data]\n",
    "    \n",
    "    first_occurence = entries.index(entry)\n",
    "    entries.reverse()\n",
    "    \n",
    "    last_occurence = entries.index(entry)\n",
    "    last_occurence = len(entries) - last_occurence - 1\n",
    "    \n",
    "    del entries\n",
    "    gc.collect()\n",
    "    \n",
    "    end_index = first_occurence if (abs(end_index-first_occurence) < abs(end_index-last_occurence)) else last_occurence\n",
    "    \n",
    "    X_test = X[start_index:end_index+1]\n",
    "    y_test = y[start_index:end_index+1]\n",
    "    X_train = X[:start_index]\n",
    "    X_train.extend(X[end_index+1:])\n",
    "    y_train = y[:start_index]\n",
    "    y_train.extend(y[end_index+1:])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, start_index, end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_WORDS = 13824\n",
    "# MAX_LEN_NG = 98 #100\n",
    "# MAX_LEN_SG = 291 #300\n",
    "MAX_WORDS = 331776\n",
    "MAX_LEN_NG = 97 #100\n",
    "MAX_LEN_SG = 384 #300\n",
    "# MAX_WORDS = 7962624\n",
    "# MAX_LEN_NG = 96 #100\n",
    "# MAX_LEN_SG = 475 #300\n",
    "\n",
    "def tokenization(X_train,X_test,maxlen):\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return X_train, X_test, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a7f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "false_negative_penalty = 6\n",
    "false_positive_penalty = 1\n",
    "\n",
    "def custom_loss(y_true, y_logit):\n",
    "\n",
    "    loss = float(0)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_logit = tf.cast(y_logit, tf.float32)\n",
    "    \n",
    "    first_term = false_negative_penalty * float(y_true) * - K.log(y_logit + K.epsilon())\n",
    "    second_term = false_positive_penalty * (1 - float(y_true)) * - K.log(1 - y_logit + K.epsilon())\n",
    "    \n",
    "    loss = K.mean(first_term+second_term)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    rec = recall(y_true,y_pred)\n",
    "    prec = precision(y_true,y_pred)\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c30cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True,**kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'return_sequences': self.return_sequences \n",
    "      })\n",
    "      return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03b912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 677 #For bp (Change according to aspects)\n",
    "\n",
    "def get_model_ng_sg(vocab_size_ng, vocab_size_sg):\n",
    "    #Input layers\n",
    "\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,)) \n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,)) \n",
    "\n",
    "    #embeddings\n",
    "    embedding_layer_ngrams = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "    embedding_layer_skip_grams = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    #BI-LSTMs for each of the inputs\n",
    "    sequence_output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True))(embedding_layer_ngrams)\n",
    "    attention_output_1 = attention(return_sequences=False)(sequence_output_1)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_1)\n",
    "\n",
    "    sequence_output_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(embedding_layer_skip_grams)\n",
    "    attention_output_2 = attention(return_sequences=False)(sequence_output_2)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.3)(attention_output_2)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_2)\n",
    "\n",
    "    max_layer = tf.keras.layers.Maximum()([dense_layer_1,dense_layer_2])\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            input_ngrams,\n",
    "            input_skip_grams\n",
    "        ], \n",
    "        outputs=max_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84680b09",
   "metadata": {},
   "source": [
    "### Model using skip grams and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6163d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_train_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "X_train_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y_train = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32366243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802 848802\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_ng),len(X_train_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dfda2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Entry</th>\n",
       "      <th>accessions</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (biological process)</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>617</td>\n",
       "      <td>1B48_HUMAN</td>\n",
       "      <td>P30486; Q29764;</td>\n",
       "      <td>MLVMAPRTVLLLLSAALALTETWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n",
       "      <td>GO:0045087;GO:0051716;GO:0006952;GO:0071346;GO...</td>\n",
       "      <td>['IPR007110', 'IPR013783', 'IPR003006', 'IPR00...</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>1028</td>\n",
       "      <td>3BHS7_MOUSE</td>\n",
       "      <td>Q9EQC1; A2RTR5;</td>\n",
       "      <td>MADSAQVPTLVYLVTGGCGFLGEHIVRMLLEREPRLRELRVFDLHL...</td>\n",
       "      <td>GO:0044710;GO:0051716;GO:0009605;GO:0048870;GO...</td>\n",
       "      <td>['IPR002225', 'IPR016040']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>2418</td>\n",
       "      <td>6PGD_DROME</td>\n",
       "      <td>P41572; Q9W519;</td>\n",
       "      <td>MSGQADIALIGLAVMGQNLILNMDEKGFVVCAYNRTVAKVKEFLAN...</td>\n",
       "      <td>GO:0019222;GO:0044237;GO:0065007;GO:0005996;GO...</td>\n",
       "      <td>['IPR008927', 'IPR013328', 'IPR012284', 'IPR00...</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326</td>\n",
       "      <td>2607</td>\n",
       "      <td>8ODP_RAT</td>\n",
       "      <td>P53369;</td>\n",
       "      <td>MSTSRLYTLVLVLQPQRVLLGMKKRGFGAGRWNGFGGKVQEGETIE...</td>\n",
       "      <td>GO:0000003;GO:0007548;GO:0003006;GO:0022414;GO...</td>\n",
       "      <td>['IPR020476', 'IPR020084', 'IPR000086', 'IPR01...</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392</td>\n",
       "      <td>3170</td>\n",
       "      <td>AA3R_MOUSE</td>\n",
       "      <td>Q61618; Q9R202;</td>\n",
       "      <td>MEADNTTETDWLNITYITMEAAIGLCAVVGNMLVIWVVKLNPTLRT...</td>\n",
       "      <td>GO:0002279;GO:0009611;GO:0009605;GO:0002694;GO...</td>\n",
       "      <td>['IPR000466', 'IPR001634', 'IPR000276', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>55718</td>\n",
       "      <td>552022</td>\n",
       "      <td>ZN704_MOUSE</td>\n",
       "      <td>Q9ERQ3; Q7TQL8; Q8BJW9;</td>\n",
       "      <td>MQARRLAKRPSLGSRRGGAAPAPAPEAAALGLPPPGPSPAAAPGSW...</td>\n",
       "      <td>GO:0019222;GO:0044237;GO:0019438;GO:0006725;GO...</td>\n",
       "      <td>['IPR007087']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>55732</td>\n",
       "      <td>552113</td>\n",
       "      <td>ZN809_MOUSE</td>\n",
       "      <td>G3X9G7; Q4KL58; Q8BIJ2;</td>\n",
       "      <td>MGLVSFEDVAVDFTLEEWQDLDAAQRTLYRDVMLETYSSLVFLDPC...</td>\n",
       "      <td>GO:0006260;GO:0019083;GO:0090305;GO:0060255;GO...</td>\n",
       "      <td>['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>55751</td>\n",
       "      <td>552243</td>\n",
       "      <td>ZNF8_MOUSE</td>\n",
       "      <td>Q8BGV5; Q52KP6; Q8BJ50;</td>\n",
       "      <td>MDHQDKAATVAMASRPQATQLQEPVTFRDVAVDFTQEEWGQLDPTQ...</td>\n",
       "      <td>GO:0006355;GO:0060255;GO:0044763;GO:1901360;GO...</td>\n",
       "      <td>['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>55763</td>\n",
       "      <td>552282</td>\n",
       "      <td>ZNRF4_HUMAN</td>\n",
       "      <td>Q8WWF5; A8K886; O75866;</td>\n",
       "      <td>MPLCRPEHLMPRASRVPVAASLPLSHAVIPTQLPSRPGHRPPGRPR...</td>\n",
       "      <td>GO:0009057;GO:0044237;GO:0043412;GO:0036211;GO...</td>\n",
       "      <td>['IPR003137', 'IPR001841', 'IPR013083']</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>55796</td>\n",
       "      <td>552531</td>\n",
       "      <td>ZOP1_ARATH</td>\n",
       "      <td>Q7XA66; Q94AV7; Q9FX87;</td>\n",
       "      <td>MTEYWVSQGNKWCEFCKIWIQNNPTSIRNHDLGKRHRECVDKKLTD...</td>\n",
       "      <td>GO:0044237;GO:0016458;GO:0019222;GO:0006725;GO...</td>\n",
       "      <td>['IPR000690', 'IPR003604', 'IPR013085']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0   index        Entry               accessions  \\\n",
       "0          84     617   1B48_HUMAN          P30486; Q29764;   \n",
       "1         181    1028  3BHS7_MOUSE          Q9EQC1; A2RTR5;   \n",
       "2         304    2418   6PGD_DROME          P41572; Q9W519;   \n",
       "3         326    2607     8ODP_RAT                  P53369;   \n",
       "4         392    3170   AA3R_MOUSE          Q61618; Q9R202;   \n",
       "...       ...     ...          ...                      ...   \n",
       "1429    55718  552022  ZN704_MOUSE  Q9ERQ3; Q7TQL8; Q8BJW9;   \n",
       "1430    55732  552113  ZN809_MOUSE  G3X9G7; Q4KL58; Q8BIJ2;   \n",
       "1431    55751  552243   ZNF8_MOUSE  Q8BGV5; Q52KP6; Q8BJ50;   \n",
       "1432    55763  552282  ZNRF4_HUMAN  Q8WWF5; A8K886; O75866;   \n",
       "1433    55796  552531   ZOP1_ARATH  Q7XA66; Q94AV7; Q9FX87;   \n",
       "\n",
       "                                               Sequence  \\\n",
       "0     MLVMAPRTVLLLLSAALALTETWAGSHSMRYFYTSVSRPGRGEPRF...   \n",
       "1     MADSAQVPTLVYLVTGGCGFLGEHIVRMLLEREPRLRELRVFDLHL...   \n",
       "2     MSGQADIALIGLAVMGQNLILNMDEKGFVVCAYNRTVAKVKEFLAN...   \n",
       "3     MSTSRLYTLVLVLQPQRVLLGMKKRGFGAGRWNGFGGKVQEGETIE...   \n",
       "4     MEADNTTETDWLNITYITMEAAIGLCAVVGNMLVIWVVKLNPTLRT...   \n",
       "...                                                 ...   \n",
       "1429  MQARRLAKRPSLGSRRGGAAPAPAPEAAALGLPPPGPSPAAAPGSW...   \n",
       "1430  MGLVSFEDVAVDFTLEEWQDLDAAQRTLYRDVMLETYSSLVFLDPC...   \n",
       "1431  MDHQDKAATVAMASRPQATQLQEPVTFRDVAVDFTQEEWGQLDPTQ...   \n",
       "1432  MPLCRPEHLMPRASRVPVAASLPLSHAVIPTQLPSRPGHRPPGRPR...   \n",
       "1433  MTEYWVSQGNKWCEFCKIWIQNNPTSIRNHDLGKRHRECVDKKLTD...   \n",
       "\n",
       "                     Gene Ontology (biological process)  \\\n",
       "0     GO:0045087;GO:0051716;GO:0006952;GO:0071346;GO...   \n",
       "1     GO:0044710;GO:0051716;GO:0009605;GO:0048870;GO...   \n",
       "2     GO:0019222;GO:0044237;GO:0065007;GO:0005996;GO...   \n",
       "3     GO:0000003;GO:0007548;GO:0003006;GO:0022414;GO...   \n",
       "4     GO:0002279;GO:0009611;GO:0009605;GO:0002694;GO...   \n",
       "...                                                 ...   \n",
       "1429  GO:0019222;GO:0044237;GO:0019438;GO:0006725;GO...   \n",
       "1430  GO:0006260;GO:0019083;GO:0090305;GO:0060255;GO...   \n",
       "1431  GO:0006355;GO:0060255;GO:0044763;GO:1901360;GO...   \n",
       "1432  GO:0009057;GO:0044237;GO:0043412;GO:0036211;GO...   \n",
       "1433  GO:0044237;GO:0016458;GO:0019222;GO:0006725;GO...   \n",
       "\n",
       "                                              interpros   orgs  \n",
       "0     ['IPR007110', 'IPR013783', 'IPR003006', 'IPR00...   9606  \n",
       "1                            ['IPR002225', 'IPR016040']  10090  \n",
       "2     ['IPR008927', 'IPR013328', 'IPR012284', 'IPR00...   7227  \n",
       "3     ['IPR020476', 'IPR020084', 'IPR000086', 'IPR01...  10116  \n",
       "4     ['IPR000466', 'IPR001634', 'IPR000276', 'IPR01...  10090  \n",
       "...                                                 ...    ...  \n",
       "1429                                      ['IPR007087']  10090  \n",
       "1430  ['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...  10090  \n",
       "1431  ['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...  10090  \n",
       "1432            ['IPR003137', 'IPR001841', 'IPR013083']   9606  \n",
       "1433            ['IPR000690', 'IPR003604', 'IPR013085']   3702  \n",
       "\n",
       "[1434 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('golabeler_test/bp_df.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37914add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348e2d8cd25843a8a2779acd6607a6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "testing_data = get_training_data(test_df,gap=30)\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedb4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e24c753a794bbb9664055045e11f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print('Preparing from scratch...')\n",
    "testing_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(testing_data))):\n",
    "    testing_data_ngrams.append([testing_data[i][0],get_ngrams(testing_data[i][1],n=4),testing_data[i][2]])\n",
    "    \n",
    "print(len(testing_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1d8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42add90f6e914a2897ef1ee3742b221c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print('Preparing from scratch...')\n",
    "testing_data_skip_grams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(testing_data))):\n",
    "    testing_data_skip_grams.append([testing_data[i][0],get_skip_grams(testing_data[i][1],n=4),testing_data[i][2]])\n",
    "    \n",
    "print(len(testing_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eac38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_test_ng = [' '.join(sample[1]) for sample in testing_data_ngrams]\n",
    "X_test_sg = [' '.join(sample[1]) for sample in testing_data_skip_grams]\n",
    "y_test = [sample[2] for sample in testing_data]\n",
    "\n",
    "del testing_data_ngrams\n",
    "del testing_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2079b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753 22753\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test_ng),len(X_test_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8a951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# recs = []\n",
    "# precs = []\n",
    "# f1s = []\n",
    "\n",
    "# for i in range(1):\n",
    "    \n",
    "# #     print('Splitting into train-test...')\n",
    "# #     X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index1 = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "# #     X_train_sg, _, X_test_sg, _, _, _= train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "    \n",
    "# #     prev_index = prev_index1\n",
    "    \n",
    "#     print('Tokenizing...')\n",
    "#     X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)  \n",
    "#     X_train_sg, X_test_sg, vocabsize_sg, tokenizer2 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "   \n",
    "# print('Shuffling...')   \n",
    "#     shuffled = [[X_train_ng[i],X_train_sg[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "#     np.random.shuffle(shuffled)\n",
    "\n",
    "#     X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "#     X_train_sg = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "#     y_train = [shuffled[i][2] for i in range(len(shuffled))]\n",
    "#     X_train_ng = np.array(X_train_ng)\n",
    "#     X_train_sg = np.array(X_train_sg)\n",
    "#     y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "#     model = get_model_ng_sg(vocab_size_ng, vocab_size_sg)\n",
    "    \n",
    "#     model.compile(\n",
    "#         loss=custom_loss, \n",
    "#         optimizer='adam', \n",
    "#         metrics=[\n",
    "#             recall,\n",
    "#             precision,\n",
    "#             f1_score\n",
    "#         ])\n",
    "\n",
    "#     print('Training...')\n",
    "#     history = model.fit([X_train_ng,X_train_sg], y_train, batch_size=32, epochs=10,validation_split=0.2)\n",
    "    \n",
    "#     print('Evaluating model...')\n",
    "#     predictions = model.predict([X_test_ng,X_test_sg])\n",
    "    \n",
    "#     print('Computing Metrics...\\n')\n",
    "#     compute_metrics(predictions)\n",
    "    \n",
    "# #     recs.append(rec.numpy())\n",
    "# #     precs.append(prec.numpy())\n",
    "# #     f1s.append(f1.numpy())\n",
    "\n",
    "# # print('Recall:',sum(recs)/len(recs))\n",
    "# # print('Precision:',sum(precs)/len(precs))\n",
    "# # print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66234f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FUNC_DICT, Ontology, NAMESPACES\n",
    "NUM_CLASSES = 3904\n",
    "\n",
    "train_df_original = pd.read_pickle('data_golabeler/train_data.pkl')\n",
    "test_df_original = pd.read_pickle('data_golabeler/test_data.pkl')\n",
    "annotations = train_df_original['annotations'].values\n",
    "annotations = list(map(lambda x: set(x), annotations))\n",
    "test_annotations = test_df_original['annotations'].values\n",
    "test_annotations = list(map(lambda x: set(x), test_annotations))\n",
    "\n",
    "go_rels = Ontology('data_golabeler/go.obo', with_rels=True)\n",
    "go_rels.calculate_ic(annotations + test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fb6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_annotations(real_annots, pred_annots):\n",
    "    total = 0\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    p_total= 0\n",
    "    fps = []\n",
    "    fns = []\n",
    "    ru = 0.0\n",
    "    mi = 0.0\n",
    "    for i in range(len(real_annots)):\n",
    "        if len(real_annots[i]) == 0:\n",
    "            continue\n",
    "        tp = set(real_annots[i]).intersection(set(pred_annots[i]))\n",
    "        fp = set(pred_annots[i]) - tp\n",
    "        fn = set(real_annots[i]) - tp\n",
    "        for go_id in fp:\n",
    "            mi += go_rels.get_ic(go_id)\n",
    "        for go_id in fn:\n",
    "            ru += go_rels.get_ic(go_id)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        tpn = len(tp)\n",
    "        fpn = len(fp)\n",
    "        fnn = len(fn)\n",
    "        total += 1\n",
    "        recall = tpn / (1.0 * (tpn + fnn))\n",
    "        r += recall\n",
    "        if len(pred_annots[i]) > 0:\n",
    "            p_total += 1\n",
    "            precision = tpn / (1.0 * (tpn + fpn))\n",
    "            p += precision\n",
    "    ru /= total\n",
    "    mi /= total\n",
    "    r /= total\n",
    "    if p_total > 0:\n",
    "        p /= p_total\n",
    "    f = 0.0\n",
    "    if p + r > 0:\n",
    "        f = 2 * p * r / (p + r)\n",
    "    s = math.sqrt(ru * ru + mi * mi)\n",
    "    return f, p, r, fps, fns, s, ru, mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d5d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d734cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('bp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb50bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('bp_predictions',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab990bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "predictions = np.load('bp_predictions.npy')\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "704437fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7624612e-04, 3.6634240e-04, 1.9185306e-06, ..., 3.5401652e-07,\n",
       "        1.6416595e-06, 3.7313028e-05],\n",
       "       [4.1396503e-05, 3.9768761e-06, 5.9689398e-08, ..., 5.8964384e-09,\n",
       "        5.0408776e-08, 5.3412114e-06],\n",
       "       [1.7054519e-05, 5.7801901e-04, 1.2498406e-07, ..., 2.0857888e-08,\n",
       "        2.5354043e-07, 2.4605622e-06],\n",
       "       ...,\n",
       "       [3.0075982e-03, 4.8314566e-03, 1.5338926e-04, ..., 2.5561954e-05,\n",
       "        9.0316636e-05, 1.4699594e-03],\n",
       "       [5.5041299e-03, 1.0889429e-02, 1.3132649e-04, ..., 3.4304350e-04,\n",
       "        6.1967981e-04, 3.5264983e-03],\n",
       "       [4.9882443e-03, 2.6117009e-01, 3.4399766e-03, ..., 1.7506933e-03,\n",
       "        2.9720613e-03, 1.2514018e-02]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2506bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = []\n",
    "for i in range(len(df)):\n",
    "    terms_set = set(df.iloc[i]['Gene Ontology ('+' '.join(aspect)+')'].split(';'))\n",
    "    train_annotations.append(terms_set)\n",
    "\n",
    "prot_index = {}\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    prot_index[row.Entry] = i\n",
    "\n",
    "diamond_scores_file = 'data_golabeler/golabeler_matches_bp.tsv'\n",
    "diamond_scores = {}\n",
    "with open(diamond_scores_file) as f:\n",
    "    for line in f:\n",
    "        it = line.strip().split()\n",
    "        if it[0] not in diamond_scores:\n",
    "            diamond_scores[it[0]] = {}\n",
    "        diamond_scores[it[0]][it[1]] = float(it[2])\n",
    "\n",
    "blast_preds = []\n",
    "#print('Diamond preds')\n",
    "for i, row in enumerate(test_df.itertuples()):\n",
    "    annots = {}\n",
    "    prot_id = row.Entry\n",
    "    # BlastKNN\n",
    "    if prot_id in diamond_scores:\n",
    "        sim_prots = diamond_scores[prot_id]\n",
    "        allgos = set()\n",
    "        total_score = 0.0\n",
    "        for p_id, score in sim_prots.items():\n",
    "            allgos |= train_annotations[prot_index[p_id]]\n",
    "            total_score += score\n",
    "        allgos = list(sorted(allgos))\n",
    "        sim = np.zeros(len(allgos), dtype=np.float32)\n",
    "        for j, go_id in enumerate(allgos):\n",
    "            s = 0.0\n",
    "            for p_id, score in sim_prots.items():\n",
    "                if go_id in train_annotations[prot_index[p_id]]:\n",
    "                    s += score\n",
    "            sim[j] = s / total_score\n",
    "        ind = np.argsort(-sim)\n",
    "        for go_id, score in zip(allgos, sim):\n",
    "            annots[go_id] = score\n",
    "    blast_preds.append(annots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "746a9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for term in blast_preds[0].keys():\n",
    "    if term not in go_terms_bp:\n",
    "        print(term)\n",
    "        count+=1\n",
    "print(count)\n",
    "print(len(blast_preds[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "537c58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "actual_y_test = []\n",
    "\n",
    "current_entry = ''\n",
    "counter = 0\n",
    "total_counts = 0\n",
    "start_index = 0\n",
    "\n",
    "if len(predictions) == len(testing_data):\n",
    "    temp = np.zeros(NUM_CLASSES)\n",
    "    for i in range(len(predictions)):\n",
    "        if current_entry != testing_data[start_index+i][0]:\n",
    "            #compute prev\n",
    "            if i!=0:\n",
    "                temp /= counter\n",
    "                final_predictions.append(temp)\n",
    "\n",
    "            #reset\n",
    "            total_counts += counter\n",
    "            counter = 1\n",
    "            temp = np.zeros(NUM_CLASSES)\n",
    "\n",
    "            #init new\n",
    "            current_entry = testing_data[start_index+i][0]\n",
    "            temp += np.array(predictions[i])\n",
    "            actual_y_test.append(testing_data[start_index+i][2])\n",
    "        else:\n",
    "            temp += np.array(predictions[i])\n",
    "            counter += 1\n",
    "\n",
    "    total_counts += counter\n",
    "    temp /= counter\n",
    "    final_predictions.append(temp)\n",
    "\n",
    "else:\n",
    "    print('Lengths of predictions dont match with test data')\n",
    "\n",
    "final_predictions = np.array(final_predictions, dtype=float)\n",
    "actual_y_test = np.array(actual_y_test, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b7e2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d70bffaae4db0b86d0ffe71d48f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fmax: 0.463, Smin: 30.703, threshold: 0.5, AUPR: 0.443\n"
     ]
    }
   ],
   "source": [
    "best_fmax = 0.0    \n",
    "final_predictions_avg = copy.deepcopy(final_predictions)\n",
    "for i in range(len(final_predictions_avg)):\n",
    "    for j in range(len(go_terms_bp)):\n",
    "        if go_terms_bp[j] in blast_preds[i].keys():\n",
    "            final_predictions_avg[i][j] = (blast_preds[i][go_terms_bp[j]] + final_predictions_avg[i][j])/2\n",
    "\n",
    "fmax = 0.0\n",
    "tmax = 0.0\n",
    "precisions = []\n",
    "recalls = []\n",
    "smin = 1000000.0\n",
    "rus = []\n",
    "mis = []\n",
    "    \n",
    "\n",
    "for t in tqdm.tqdm(range(0, 101)):\n",
    "\n",
    "    threshold = t / 100.0\n",
    "    pred_annots = []\n",
    "    real_annots = []\n",
    "    for i in range(len(final_predictions_avg)):\n",
    "        new_preds = []\n",
    "        new_ys = []\n",
    "        for j in range(NUM_CLASSES):\n",
    "            if final_predictions_avg[i][j]>=threshold:\n",
    "                new_preds.append(go_terms_bp[j]) #GO_TERMS_BP\n",
    "            if actual_y_test[i][j]==1:\n",
    "                new_ys.append(go_terms_bp[j])\n",
    "        pred_annots.append(new_preds)\n",
    "        real_annots.append(new_ys)\n",
    "\n",
    "    fscore, prec, rec, fps, fns, s, ru, mi = evaluate_annotations(real_annots, pred_annots)\n",
    "    avg_fp = sum(map(lambda x: len(x), fps)) / len(fps)\n",
    "    avg_ic = sum(map(lambda x: sum(map(lambda go_id: go_rels.get_ic(go_id), x)), fps)) / len(fps)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "    if fmax < fscore:\n",
    "        fmax = fscore\n",
    "        tmax = threshold\n",
    "    if smin > s:\n",
    "        smin = s\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "sorted_index = np.argsort(recalls)\n",
    "recalls = recalls[sorted_index]\n",
    "precisions = precisions[sorted_index]\n",
    "aupr = np.trapz(precisions, recalls)\n",
    "\n",
    "print(f'Fmax: {fmax:0.3f}, Smin: {smin:0.3f}, threshold: {tmax}, AUPR: {aupr:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9b136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
