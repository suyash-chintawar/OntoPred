{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a056c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  1 22:57:09 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    52W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    52W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    53W / 300W |  31854MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    53W / 300W |      0MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A   2141306      C   /usr/bin/python3                31851MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86add81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb10a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 22:57:17.623586: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 22:57:17.788639: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8046218454174766726\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 32476168192\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7756654305557727663\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 22:57:21.202740: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 22:57:24.489147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8be3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e98a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = ['biological','process']\n",
    "aspect_abbr = 'bp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce40988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'golabeler_train/bp_df.csv'\n",
    "# if not os.path.exists(file):\n",
    "#     url = \"https://drive.google.com/file/d/1RyeLQPFTMWAIr-OzELTWIx60ln-mZ7g_/view?usp=sharing\"\n",
    "#     output = file\n",
    "#     gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd949fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Entry</th>\n",
       "      <th>accessions</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (biological process)</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>140U_DROME</td>\n",
       "      <td>P81928; Q9VFM8;</td>\n",
       "      <td>MNFLWKGRRFLIAGILPTFEGAADEIVDKENKTYKAFLASKPPEET...</td>\n",
       "      <td>GO:0007275;GO:0044707;GO:0032502;GO:0044699;GO...</td>\n",
       "      <td>['IPR003397']</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261</td>\n",
       "      <td>14310_ARATH</td>\n",
       "      <td>P48347; Q9LME5;</td>\n",
       "      <td>MENEREKQVYLAKLSEQTERYDEMVEAMKKVAQLDVELTVEERNLV...</td>\n",
       "      <td>GO:0014070;GO:0043401;GO:0001101;GO:0051716;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>265</td>\n",
       "      <td>14331_ARATH</td>\n",
       "      <td>P42643; Q945M2; Q9M0S7;</td>\n",
       "      <td>MATPGASSARDEFVYMAKLAEQAERYEEMVEFMEKVAKAVDKDELT...</td>\n",
       "      <td>GO:0050789;GO:0019222;GO:0065007;GO:0008150;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266</td>\n",
       "      <td>14331_CAEEL</td>\n",
       "      <td>P41932; Q21537;</td>\n",
       "      <td>MSDTVEELVQRAKLAEQAERYDDMAAAMKKVTEQGQELSNEERNLL...</td>\n",
       "      <td>GO:0009792;GO:0009566;GO:0040001;GO:0044763;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>14332_ARATH</td>\n",
       "      <td>Q01525;</td>\n",
       "      <td>MASGREEFVYMAKLAEQAERYEEMVEFMEKVSAAVDGDELTVEERN...</td>\n",
       "      <td>GO:0014070;GO:0043401;GO:0051716;GO:0065007;GO...</td>\n",
       "      <td>['IPR000308', 'IPR023409', 'IPR023410']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51711</th>\n",
       "      <td>550266</td>\n",
       "      <td>ZYX_CAEEL</td>\n",
       "      <td>Q9U3F4; H2L2F5; H2L2F6; H2L2F7; Q9U3F5;</td>\n",
       "      <td>MGPPPPPPPPPLLPSGEILPSRKWKTEDAPRRNNHPAPAPPKPSRP...</td>\n",
       "      <td>GO:0000003;GO:0008150</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51712</th>\n",
       "      <td>550268</td>\n",
       "      <td>ZYX_HUMAN</td>\n",
       "      <td>Q15942; A4D2G6; B4DQX7; Q6I9S4;</td>\n",
       "      <td>MAAPRPSPAISVSVSAPAFYAPQKKFGPVVAPKPKVNPFRPGDSEP...</td>\n",
       "      <td>GO:1902589;GO:0051716;GO:0065007;GO:0007167;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51713</th>\n",
       "      <td>550269</td>\n",
       "      <td>ZYX_MOUSE</td>\n",
       "      <td>Q62523; P70461; Q3UGQ3;</td>\n",
       "      <td>MAAPRPPPAISVSVSAPAFYAPQKKFAPVVAPKPKVNPFRPGDSEP...</td>\n",
       "      <td>GO:0051716;GO:0065007;GO:0007179;GO:0007167;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51714</th>\n",
       "      <td>550270</td>\n",
       "      <td>ZYX_XENLA</td>\n",
       "      <td>A5H447;</td>\n",
       "      <td>MDPAAPATRMTSSFTINISTPSFYNPPKKFAPVVPPKPKINPFKAP...</td>\n",
       "      <td>GO:0019438;GO:0019222;GO:0044237;GO:0006725;GO...</td>\n",
       "      <td>['IPR001781']</td>\n",
       "      <td>8355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51715</th>\n",
       "      <td>550274</td>\n",
       "      <td>ZZZ3_HUMAN</td>\n",
       "      <td>Q8IYH5; B7WPC6; Q6N004; Q6N070; Q8IYP0; Q8IYR1...</td>\n",
       "      <td>MAASRSTRVTRSTVGLNGLDESFCGRTLRNRSIAHPEEISSNSQVR...</td>\n",
       "      <td>GO:0006325;GO:0071840;GO:0051276;GO:0016043;GO...</td>\n",
       "      <td>['IPR009057', 'IPR017930', 'IPR001005', 'IPR00...</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51716 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        Entry                                         accessions  \\\n",
       "0         259   140U_DROME                                    P81928; Q9VFM8;   \n",
       "1         261  14310_ARATH                                    P48347; Q9LME5;   \n",
       "2         265  14331_ARATH                            P42643; Q945M2; Q9M0S7;   \n",
       "3         266  14331_CAEEL                                    P41932; Q21537;   \n",
       "4         276  14332_ARATH                                            Q01525;   \n",
       "...       ...          ...                                                ...   \n",
       "51711  550266    ZYX_CAEEL            Q9U3F4; H2L2F5; H2L2F6; H2L2F7; Q9U3F5;   \n",
       "51712  550268    ZYX_HUMAN                    Q15942; A4D2G6; B4DQX7; Q6I9S4;   \n",
       "51713  550269    ZYX_MOUSE                            Q62523; P70461; Q3UGQ3;   \n",
       "51714  550270    ZYX_XENLA                                            A5H447;   \n",
       "51715  550274   ZZZ3_HUMAN  Q8IYH5; B7WPC6; Q6N004; Q6N070; Q8IYP0; Q8IYR1...   \n",
       "\n",
       "                                                Sequence  \\\n",
       "0      MNFLWKGRRFLIAGILPTFEGAADEIVDKENKTYKAFLASKPPEET...   \n",
       "1      MENEREKQVYLAKLSEQTERYDEMVEAMKKVAQLDVELTVEERNLV...   \n",
       "2      MATPGASSARDEFVYMAKLAEQAERYEEMVEFMEKVAKAVDKDELT...   \n",
       "3      MSDTVEELVQRAKLAEQAERYDDMAAAMKKVTEQGQELSNEERNLL...   \n",
       "4      MASGREEFVYMAKLAEQAERYEEMVEFMEKVSAAVDGDELTVEERN...   \n",
       "...                                                  ...   \n",
       "51711  MGPPPPPPPPPLLPSGEILPSRKWKTEDAPRRNNHPAPAPPKPSRP...   \n",
       "51712  MAAPRPSPAISVSVSAPAFYAPQKKFGPVVAPKPKVNPFRPGDSEP...   \n",
       "51713  MAAPRPPPAISVSVSAPAFYAPQKKFAPVVAPKPKVNPFRPGDSEP...   \n",
       "51714  MDPAAPATRMTSSFTINISTPSFYNPPKKFAPVVPPKPKINPFKAP...   \n",
       "51715  MAASRSTRVTRSTVGLNGLDESFCGRTLRNRSIAHPEEISSNSQVR...   \n",
       "\n",
       "                      Gene Ontology (biological process)  \\\n",
       "0      GO:0007275;GO:0044707;GO:0032502;GO:0044699;GO...   \n",
       "1      GO:0014070;GO:0043401;GO:0001101;GO:0051716;GO...   \n",
       "2      GO:0050789;GO:0019222;GO:0065007;GO:0008150;GO...   \n",
       "3      GO:0009792;GO:0009566;GO:0040001;GO:0044763;GO...   \n",
       "4      GO:0014070;GO:0043401;GO:0051716;GO:0065007;GO...   \n",
       "...                                                  ...   \n",
       "51711                              GO:0000003;GO:0008150   \n",
       "51712  GO:1902589;GO:0051716;GO:0065007;GO:0007167;GO...   \n",
       "51713  GO:0051716;GO:0065007;GO:0007179;GO:0007167;GO...   \n",
       "51714  GO:0019438;GO:0019222;GO:0044237;GO:0006725;GO...   \n",
       "51715  GO:0006325;GO:0071840;GO:0051276;GO:0016043;GO...   \n",
       "\n",
       "                                               interpros   orgs  \n",
       "0                                          ['IPR003397']   7227  \n",
       "1                ['IPR000308', 'IPR023409', 'IPR023410']   3702  \n",
       "2                ['IPR000308', 'IPR023409', 'IPR023410']   3702  \n",
       "3                ['IPR000308', 'IPR023409', 'IPR023410']   6239  \n",
       "4                ['IPR000308', 'IPR023409', 'IPR023410']   3702  \n",
       "...                                                  ...    ...  \n",
       "51711                                      ['IPR001781']   6239  \n",
       "51712                                      ['IPR001781']   9606  \n",
       "51713                                      ['IPR001781']  10090  \n",
       "51714                                      ['IPR001781']   8355  \n",
       "51715  ['IPR009057', 'IPR017930', 'IPR001005', 'IPR00...   9606  \n",
       "\n",
       "[51716 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724323ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3904\n"
     ]
    }
   ],
   "source": [
    "go_terms_bp = set()\n",
    "for idx, row in df.iterrows():\n",
    "    for term in row['Gene Ontology ('+' '.join(aspect)+')'].split(';'):\n",
    "        go_terms_bp.add(term)\n",
    "go_terms_bp = list(go_terms_bp)\n",
    "go_terms_bp.sort()\n",
    "print(len(go_terms_bp))\n",
    "# print(go_terms_bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(sequence,segment_size=100,gap=30):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    end = segment_size\n",
    "    while end <= len(sequence):\n",
    "        segments.append(sequence[start:end])\n",
    "        start += gap\n",
    "        end += gap\n",
    "    last_segment = sequence[start:]\n",
    "    segments.append(last_segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def get_training_data(df,segment_size=100,gap=30):\n",
    "    training_data = list()\n",
    "    for idx,row in tqdm.tqdm(df.iterrows()):\n",
    "        labels = [0] * len(go_terms_bp)\n",
    "        for term in row['Gene Ontology ('+' '.join(aspect)+')'].split(';'):\n",
    "            labels[go_terms_bp.index(term)] = 1\n",
    "        segments = get_segments(row['Sequence'],segment_size,gap)\n",
    "        for segment in segments:\n",
    "            training_data.append([row['Entry'],segment,labels])\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f1d6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a8f143d6d6413eab6e0ed23005c518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data(df,gap=30)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(segment,n=3):\n",
    "    ngrams = []\n",
    "    for i in range(len(segment)-n+1):\n",
    "        ngrams.append(segment[i:i+n])\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5358736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecd234472c9429a89cfae86245c6b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "# Generate training data of ngrams\n",
    "# if os.path.exists('bp/training_data_4grams.npy'):\n",
    "#     print('Loading saved ngrams...')\n",
    "#     training_data_ngrams = np.load('bp/training_data_4grams.npy',allow_pickle=True)\n",
    "# else:\n",
    "print('Preparing from scratch...')\n",
    "training_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_ngrams.append([training_data[i][0],get_ngrams(training_data[i][1],n=4),training_data[i][2]])\n",
    "        \n",
    "#     np.save('bp/training_data_4grams.npy',training_data_ngrams)\n",
    "    \n",
    "print(len(training_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4acd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skip_grams(segment,skip=1,n=3):\n",
    "    skip_grams = []\n",
    "    window_size = skip + n\n",
    "    for i in range(len(segment)-window_size+1):\n",
    "        window = segment[i:i+window_size]\n",
    "        indices = list(range(window_size))\n",
    "        indices.pop(0)\n",
    "        for idx in indices[::-1]:\n",
    "            temp = ''\n",
    "            for j in range(window_size):\n",
    "                if j!=idx:\n",
    "                    temp+=window[j]\n",
    "            skip_grams.append(temp)\n",
    "\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa91e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6deeec7a6645be94db66083858dc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/848802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists('bp/training_data_skip1_4grams.npy'):\n",
    "#     print('Loading saved skip grams...')\n",
    "#     training_data_skip_grams = np.load('bp/training_data_skip1_4grams.npy',allow_pickle=True)\n",
    "# else:\n",
    "print('Preparing from scratch...')\n",
    "training_data_skip_grams = []\n",
    "for i in tqdm.tqdm(range(len(training_data))):\n",
    "    training_data_skip_grams.append([training_data[i][0],get_skip_grams(training_data[i][1],n=4),training_data[i][2]])\n",
    "#     np.save('bp/training_data_skip1_4grams.npy',training_data_skip_grams)\n",
    "print(len(training_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11d856c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e391f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming training_data as global variable\n",
    "\n",
    "def train_test_split(X,y,fold_no,prev_index,Kfolds=5):\n",
    "    test_split = 1/Kfolds\n",
    "    \n",
    "    start_index = prev_index\n",
    "    end_index = (fold_no + 1) * (test_split) * len(X)\n",
    "    end_index = round(end_index)\n",
    "    \n",
    "    if end_index==len(X):\n",
    "        end_index -= 1\n",
    "    \n",
    "    entry = training_data[end_index][0]\n",
    "    entries = [sample[0] for sample in training_data]\n",
    "    \n",
    "    first_occurence = entries.index(entry)\n",
    "    entries.reverse()\n",
    "    \n",
    "    last_occurence = entries.index(entry)\n",
    "    last_occurence = len(entries) - last_occurence - 1\n",
    "    \n",
    "    del entries\n",
    "    gc.collect()\n",
    "    \n",
    "    end_index = first_occurence if (abs(end_index-first_occurence) < abs(end_index-last_occurence)) else last_occurence\n",
    "    \n",
    "    X_test = X[start_index:end_index+1]\n",
    "    y_test = y[start_index:end_index+1]\n",
    "    X_train = X[:start_index]\n",
    "    X_train.extend(X[end_index+1:])\n",
    "    y_train = y[:start_index]\n",
    "    y_train.extend(y[end_index+1:])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, start_index, end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "730f9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_WORDS = 13824\n",
    "# MAX_LEN_NG = 98 #100\n",
    "# MAX_LEN_SG = 291 #300\n",
    "MAX_WORDS = 331776\n",
    "MAX_LEN_NG = 97 #100\n",
    "MAX_LEN_SG = 384 #300\n",
    "# MAX_WORDS = 7962624\n",
    "# MAX_LEN_NG = 96 #100\n",
    "# MAX_LEN_SG = 475 #300\n",
    "\n",
    "def tokenization(X_train,X_test,maxlen):\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_WORDS)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return X_train, X_test, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a7f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "false_negative_penalty = 6\n",
    "false_positive_penalty = 1\n",
    "\n",
    "def custom_loss(y_true, y_logit):\n",
    "\n",
    "    loss = float(0)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_logit = tf.cast(y_logit, tf.float32)\n",
    "    \n",
    "    first_term = false_negative_penalty * float(y_true) * - K.log(y_logit + K.epsilon())\n",
    "    second_term = false_positive_penalty * (1 - float(y_true)) * - K.log(1 - y_logit + K.epsilon())\n",
    "    \n",
    "    loss = K.mean(first_term+second_term)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    return K.mean(precision)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return K.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    rec = recall(y_true,y_pred)\n",
    "    prec = precision(y_true,y_pred)\n",
    "    f1 = 2*prec*rec/(prec+rec)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36c30cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True,**kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config().copy()\n",
    "      config.update({\n",
    "          'return_sequences': self.return_sequences \n",
    "      })\n",
    "      return config\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3904 #For bp (Change according to aspects)\n",
    "\n",
    "def get_model_ng_sg(vocab_size_ng, vocab_size_sg):\n",
    "    #Input layers\n",
    "\n",
    "    input_ngrams = tf.keras.layers.Input(shape=(MAX_LEN_NG,)) \n",
    "    input_skip_grams = tf.keras.layers.Input(shape=(MAX_LEN_SG,)) \n",
    "\n",
    "    #embeddings\n",
    "    embedding_layer_ngrams = tf.keras.layers.Embedding(vocab_size_ng, 32)(input_ngrams)\n",
    "    embedding_layer_skip_grams = tf.keras.layers.Embedding(vocab_size_sg, 32)(input_skip_grams)\n",
    "\n",
    "    #BI-LSTMs for each of the inputs\n",
    "    sequence_output_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True))(embedding_layer_ngrams)\n",
    "    attention_output_1 = attention(return_sequences=False)(sequence_output_1)\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.3)(attention_output_1)\n",
    "    dense_layer_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_1)\n",
    "\n",
    "    sequence_output_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(embedding_layer_skip_grams)\n",
    "    attention_output_2 = attention(return_sequences=False)(sequence_output_2)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.3)(attention_output_2)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(dropout_2)\n",
    "\n",
    "    max_layer = tf.keras.layers.Maximum()([dense_layer_1,dense_layer_2])\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[\n",
    "            input_ngrams,\n",
    "            input_skip_grams\n",
    "        ], \n",
    "        outputs=max_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84680b09",
   "metadata": {},
   "source": [
    "### Model using skip grams and ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6163d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_train_ng = [' '.join(sample[1]) for sample in training_data_ngrams]\n",
    "X_train_sg = [' '.join(sample[1]) for sample in training_data_skip_grams]\n",
    "y_train = [sample[2] for sample in training_data]\n",
    "\n",
    "del training_data_ngrams\n",
    "del training_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32366243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848802 848802\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_ng),len(X_train_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27dfda2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Entry</th>\n",
       "      <th>accessions</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Gene Ontology (biological process)</th>\n",
       "      <th>interpros</th>\n",
       "      <th>orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>617</td>\n",
       "      <td>1B48_HUMAN</td>\n",
       "      <td>P30486; Q29764;</td>\n",
       "      <td>MLVMAPRTVLLLLSAALALTETWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n",
       "      <td>GO:0045087;GO:0051716;GO:0006952;GO:0071346;GO...</td>\n",
       "      <td>['IPR007110', 'IPR013783', 'IPR003006', 'IPR00...</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>1028</td>\n",
       "      <td>3BHS7_MOUSE</td>\n",
       "      <td>Q9EQC1; A2RTR5;</td>\n",
       "      <td>MADSAQVPTLVYLVTGGCGFLGEHIVRMLLEREPRLRELRVFDLHL...</td>\n",
       "      <td>GO:0044710;GO:0051716;GO:0009605;GO:0048870;GO...</td>\n",
       "      <td>['IPR002225', 'IPR016040']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304</td>\n",
       "      <td>2418</td>\n",
       "      <td>6PGD_DROME</td>\n",
       "      <td>P41572; Q9W519;</td>\n",
       "      <td>MSGQADIALIGLAVMGQNLILNMDEKGFVVCAYNRTVAKVKEFLAN...</td>\n",
       "      <td>GO:0019222;GO:0044237;GO:0065007;GO:0005996;GO...</td>\n",
       "      <td>['IPR008927', 'IPR013328', 'IPR012284', 'IPR00...</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326</td>\n",
       "      <td>2607</td>\n",
       "      <td>8ODP_RAT</td>\n",
       "      <td>P53369;</td>\n",
       "      <td>MSTSRLYTLVLVLQPQRVLLGMKKRGFGAGRWNGFGGKVQEGETIE...</td>\n",
       "      <td>GO:0000003;GO:0007548;GO:0003006;GO:0022414;GO...</td>\n",
       "      <td>['IPR020476', 'IPR020084', 'IPR000086', 'IPR01...</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392</td>\n",
       "      <td>3170</td>\n",
       "      <td>AA3R_MOUSE</td>\n",
       "      <td>Q61618; Q9R202;</td>\n",
       "      <td>MEADNTTETDWLNITYITMEAAIGLCAVVGNMLVIWVVKLNPTLRT...</td>\n",
       "      <td>GO:0002279;GO:0009611;GO:0009605;GO:0002694;GO...</td>\n",
       "      <td>['IPR000466', 'IPR001634', 'IPR000276', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>55718</td>\n",
       "      <td>552022</td>\n",
       "      <td>ZN704_MOUSE</td>\n",
       "      <td>Q9ERQ3; Q7TQL8; Q8BJW9;</td>\n",
       "      <td>MQARRLAKRPSLGSRRGGAAPAPAPEAAALGLPPPGPSPAAAPGSW...</td>\n",
       "      <td>GO:0019222;GO:0044237;GO:0019438;GO:0006725;GO...</td>\n",
       "      <td>['IPR007087']</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>55732</td>\n",
       "      <td>552113</td>\n",
       "      <td>ZN809_MOUSE</td>\n",
       "      <td>G3X9G7; Q4KL58; Q8BIJ2;</td>\n",
       "      <td>MGLVSFEDVAVDFTLEEWQDLDAAQRTLYRDVMLETYSSLVFLDPC...</td>\n",
       "      <td>GO:0006260;GO:0019083;GO:0090305;GO:0060255;GO...</td>\n",
       "      <td>['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>55751</td>\n",
       "      <td>552243</td>\n",
       "      <td>ZNF8_MOUSE</td>\n",
       "      <td>Q8BGV5; Q52KP6; Q8BJ50;</td>\n",
       "      <td>MDHQDKAATVAMASRPQATQLQEPVTFRDVAVDFTQEEWGQLDPTQ...</td>\n",
       "      <td>GO:0006355;GO:0060255;GO:0044763;GO:1901360;GO...</td>\n",
       "      <td>['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>55763</td>\n",
       "      <td>552282</td>\n",
       "      <td>ZNRF4_HUMAN</td>\n",
       "      <td>Q8WWF5; A8K886; O75866;</td>\n",
       "      <td>MPLCRPEHLMPRASRVPVAASLPLSHAVIPTQLPSRPGHRPPGRPR...</td>\n",
       "      <td>GO:0009057;GO:0044237;GO:0043412;GO:0036211;GO...</td>\n",
       "      <td>['IPR003137', 'IPR001841', 'IPR013083']</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>55796</td>\n",
       "      <td>552531</td>\n",
       "      <td>ZOP1_ARATH</td>\n",
       "      <td>Q7XA66; Q94AV7; Q9FX87;</td>\n",
       "      <td>MTEYWVSQGNKWCEFCKIWIQNNPTSIRNHDLGKRHRECVDKKLTD...</td>\n",
       "      <td>GO:0044237;GO:0016458;GO:0019222;GO:0006725;GO...</td>\n",
       "      <td>['IPR000690', 'IPR003604', 'IPR013085']</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1434 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0   index        Entry               accessions  \\\n",
       "0          84     617   1B48_HUMAN          P30486; Q29764;   \n",
       "1         181    1028  3BHS7_MOUSE          Q9EQC1; A2RTR5;   \n",
       "2         304    2418   6PGD_DROME          P41572; Q9W519;   \n",
       "3         326    2607     8ODP_RAT                  P53369;   \n",
       "4         392    3170   AA3R_MOUSE          Q61618; Q9R202;   \n",
       "...       ...     ...          ...                      ...   \n",
       "1429    55718  552022  ZN704_MOUSE  Q9ERQ3; Q7TQL8; Q8BJW9;   \n",
       "1430    55732  552113  ZN809_MOUSE  G3X9G7; Q4KL58; Q8BIJ2;   \n",
       "1431    55751  552243   ZNF8_MOUSE  Q8BGV5; Q52KP6; Q8BJ50;   \n",
       "1432    55763  552282  ZNRF4_HUMAN  Q8WWF5; A8K886; O75866;   \n",
       "1433    55796  552531   ZOP1_ARATH  Q7XA66; Q94AV7; Q9FX87;   \n",
       "\n",
       "                                               Sequence  \\\n",
       "0     MLVMAPRTVLLLLSAALALTETWAGSHSMRYFYTSVSRPGRGEPRF...   \n",
       "1     MADSAQVPTLVYLVTGGCGFLGEHIVRMLLEREPRLRELRVFDLHL...   \n",
       "2     MSGQADIALIGLAVMGQNLILNMDEKGFVVCAYNRTVAKVKEFLAN...   \n",
       "3     MSTSRLYTLVLVLQPQRVLLGMKKRGFGAGRWNGFGGKVQEGETIE...   \n",
       "4     MEADNTTETDWLNITYITMEAAIGLCAVVGNMLVIWVVKLNPTLRT...   \n",
       "...                                                 ...   \n",
       "1429  MQARRLAKRPSLGSRRGGAAPAPAPEAAALGLPPPGPSPAAAPGSW...   \n",
       "1430  MGLVSFEDVAVDFTLEEWQDLDAAQRTLYRDVMLETYSSLVFLDPC...   \n",
       "1431  MDHQDKAATVAMASRPQATQLQEPVTFRDVAVDFTQEEWGQLDPTQ...   \n",
       "1432  MPLCRPEHLMPRASRVPVAASLPLSHAVIPTQLPSRPGHRPPGRPR...   \n",
       "1433  MTEYWVSQGNKWCEFCKIWIQNNPTSIRNHDLGKRHRECVDKKLTD...   \n",
       "\n",
       "                     Gene Ontology (biological process)  \\\n",
       "0     GO:0045087;GO:0051716;GO:0006952;GO:0071346;GO...   \n",
       "1     GO:0044710;GO:0051716;GO:0009605;GO:0048870;GO...   \n",
       "2     GO:0019222;GO:0044237;GO:0065007;GO:0005996;GO...   \n",
       "3     GO:0000003;GO:0007548;GO:0003006;GO:0022414;GO...   \n",
       "4     GO:0002279;GO:0009611;GO:0009605;GO:0002694;GO...   \n",
       "...                                                 ...   \n",
       "1429  GO:0019222;GO:0044237;GO:0019438;GO:0006725;GO...   \n",
       "1430  GO:0006260;GO:0019083;GO:0090305;GO:0060255;GO...   \n",
       "1431  GO:0006355;GO:0060255;GO:0044763;GO:1901360;GO...   \n",
       "1432  GO:0009057;GO:0044237;GO:0043412;GO:0036211;GO...   \n",
       "1433  GO:0044237;GO:0016458;GO:0019222;GO:0006725;GO...   \n",
       "\n",
       "                                              interpros   orgs  \n",
       "0     ['IPR007110', 'IPR013783', 'IPR003006', 'IPR00...   9606  \n",
       "1                            ['IPR002225', 'IPR016040']  10090  \n",
       "2     ['IPR008927', 'IPR013328', 'IPR012284', 'IPR00...   7227  \n",
       "3     ['IPR020476', 'IPR020084', 'IPR000086', 'IPR01...  10116  \n",
       "4     ['IPR000466', 'IPR001634', 'IPR000276', 'IPR01...  10090  \n",
       "...                                                 ...    ...  \n",
       "1429                                      ['IPR007087']  10090  \n",
       "1430  ['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...  10090  \n",
       "1431  ['IPR001909', 'IPR007087', 'IPR015880', 'IPR01...  10090  \n",
       "1432            ['IPR003137', 'IPR001841', 'IPR013083']   9606  \n",
       "1433            ['IPR000690', 'IPR003604', 'IPR013085']   3702  \n",
       "\n",
       "[1434 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('golabeler_test/bp_df.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37914add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46eca473d499490f809cc3767deefa95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "testing_data = get_training_data(test_df,gap=30)\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedb4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e24c753a794bbb9664055045e11f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print('Preparing from scratch...')\n",
    "testing_data_ngrams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(testing_data))):\n",
    "    testing_data_ngrams.append([testing_data[i][0],get_ngrams(testing_data[i][1],n=4),testing_data[i][2]])\n",
    "    \n",
    "print(len(testing_data_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1d8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing from scratch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42add90f6e914a2897ef1ee3742b221c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print('Preparing from scratch...')\n",
    "testing_data_skip_grams = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(testing_data))):\n",
    "    testing_data_skip_grams.append([testing_data[i][0],get_skip_grams(testing_data[i][1],n=4),testing_data[i][2]])\n",
    "    \n",
    "print(len(testing_data_skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eac38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering ngrams and skip grams\n",
    "X_test_ng = [' '.join(sample[1]) for sample in testing_data_ngrams]\n",
    "X_test_sg = [' '.join(sample[1]) for sample in testing_data_skip_grams]\n",
    "y_test = [sample[2] for sample in testing_data]\n",
    "\n",
    "del testing_data_ngrams\n",
    "del testing_data_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2079b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753 22753\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test_ng),len(X_test_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66234f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FUNC_DICT, Ontology, NAMESPACES\n",
    "NUM_CLASSES = 3904\n",
    "\n",
    "train_df = pd.read_pickle('data_golabeler/train_data.pkl')\n",
    "test_df = pd.read_pickle('data_golabeler/test_data.pkl')\n",
    "annotations = train_df['annotations'].values\n",
    "annotations = list(map(lambda x: set(x), annotations))\n",
    "test_annotations = test_df['annotations'].values\n",
    "test_annotations = list(map(lambda x: set(x), test_annotations))\n",
    "\n",
    "go_rels = Ontology('data_golabeler/go.obo', with_rels=True)\n",
    "go_rels.calculate_ic(annotations + test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08fb6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_annotations(real_annots, pred_annots):\n",
    "    total = 0\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    p_total= 0\n",
    "    fps = []\n",
    "    fns = []\n",
    "    ru = 0.0\n",
    "    mi = 0.0\n",
    "    for i in range(len(real_annots)):\n",
    "        if len(real_annots[i]) == 0:\n",
    "            continue\n",
    "        tp = set(real_annots[i]).intersection(set(pred_annots[i]))\n",
    "        fp = set(pred_annots[i]) - tp\n",
    "        fn = set(real_annots[i]) - tp\n",
    "        for go_id in fp:\n",
    "            mi += go_rels.get_ic(go_id)\n",
    "        for go_id in fn:\n",
    "            ru += go_rels.get_ic(go_id)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        tpn = len(tp)\n",
    "        fpn = len(fp)\n",
    "        fnn = len(fn)\n",
    "        total += 1\n",
    "        recall = tpn / (1.0 * (tpn + fnn))\n",
    "        r += recall\n",
    "        if len(pred_annots[i]) > 0:\n",
    "            p_total += 1\n",
    "            precision = tpn / (1.0 * (tpn + fpn))\n",
    "            p += precision\n",
    "    ru /= total\n",
    "    mi /= total\n",
    "    r /= total\n",
    "    if p_total > 0:\n",
    "        p /= p_total\n",
    "    f = 0.0\n",
    "    if p + r > 0:\n",
    "        f = 2 * p * r / (p + r)\n",
    "    s = math.sqrt(ru * ru + mi * mi)\n",
    "    return f, p, r, fps, fns, s, ru, mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d593615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions):\n",
    "    final_predictions = []\n",
    "    actual_y_test = []\n",
    "\n",
    "    current_entry = ''\n",
    "    counter = 0\n",
    "    total_counts = 0\n",
    "    start_index = 0\n",
    "\n",
    "    if len(predictions) == len(testing_data):\n",
    "        temp = np.zeros(NUM_CLASSES)\n",
    "        for i in range(len(predictions)):\n",
    "            if current_entry != testing_data[start_index+i][0]:\n",
    "                #compute prev\n",
    "                if i!=0:\n",
    "                    temp /= counter\n",
    "                    final_predictions.append(temp)\n",
    "\n",
    "                #reset\n",
    "                total_counts += counter\n",
    "                counter = 1\n",
    "                temp = np.zeros(NUM_CLASSES)\n",
    "\n",
    "                #init new\n",
    "                current_entry = testing_data[start_index+i][0]\n",
    "                temp += np.array(predictions[i])\n",
    "                actual_y_test.append(testing_data[start_index+i][2])\n",
    "            else:\n",
    "                temp += np.array(predictions[i])\n",
    "                counter += 1\n",
    "\n",
    "        total_counts += counter\n",
    "        temp /= counter\n",
    "        final_predictions.append(temp)\n",
    "\n",
    "    else:\n",
    "        print('Lengths of predictions dont match with test data')\n",
    "    \n",
    "    final_predictions = np.array(final_predictions, dtype=float)\n",
    "    actual_y_test = np.array(actual_y_test, dtype=float)\n",
    "    \n",
    "    #Computing maximal F1-score\n",
    "    fmax = 0.0\n",
    "    tmax = 0.0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    smin = 1000000.0\n",
    "    rus = []\n",
    "    mis = []\n",
    "    \n",
    "    for t in tqdm.tqdm(range(0, 101)):\n",
    "        \n",
    "        threshold = t / 100.0\n",
    "        pred_annots = []\n",
    "        real_annots = []\n",
    "    \n",
    "        for i in range(len(final_predictions)):\n",
    "            new_preds = []\n",
    "            new_ys = []\n",
    "            for j in range(NUM_CLASSES):\n",
    "                if final_predictions[i][j]>=threshold:\n",
    "                    new_preds.append(go_terms_bp[j]) #GO_TERMS_BP\n",
    "                if actual_y_test[i][j]==1:\n",
    "                    new_ys.append(go_terms_bp[j])\n",
    "            pred_annots.append(new_preds)\n",
    "            real_annots.append(new_ys)\n",
    "    \n",
    "        fscore, prec, rec, fps, fns, s, ru, mi = evaluate_annotations(real_annots, pred_annots)\n",
    "        avg_fp = sum(map(lambda x: len(x), fps)) / len(fps)\n",
    "        avg_ic = sum(map(lambda x: sum(map(lambda go_id: go_rels.get_ic(go_id), x)), fps)) / len(fps)\n",
    "        print(f'{avg_fp} {avg_ic}')\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        print(f'Fscore: {fscore}, Precision: {prec}, Recall: {rec} S: {s}, RU: {ru}, MI: {mi} threshold: {threshold}')\n",
    "        if fmax < fscore:\n",
    "            fmax = fscore\n",
    "            tmax = threshold\n",
    "        if smin > s:\n",
    "            smin = s\n",
    "    print('\\nFinal Results (Maximal F1-score):')\n",
    "    print(f'Fmax: {fmax:0.3f}, Smin: {smin:0.3f}, threshold: {tmax}')\n",
    "    precisions = np.array(precisions)\n",
    "    recalls = np.array(recalls)\n",
    "    sorted_index = np.argsort(recalls)\n",
    "    recalls = recalls[sorted_index]\n",
    "    precisions = precisions[sorted_index]\n",
    "    aupr = np.trapz(precisions, recalls)\n",
    "    print(f'AUPR: {aupr:0.3f}')\n",
    "        \n",
    "    \n",
    "#     rec = recall(actual_y_test,final_predictions)\n",
    "#     prec = precision(actual_y_test,final_predictions)\n",
    "#     f1 = f1_score(actual_y_test,final_predictions)\n",
    "    \n",
    "#     return rec,prec,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f8a951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Shuffling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 23:20:20.875437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30971 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 23:20:23.196321: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 21207808512 exceeds 10% of free system memory.\n",
      "2023-02-01 23:20:38.407195: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 21207808512 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 23:20:56.243498: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21221/21221 [==============================] - 857s 40ms/step - loss: 0.1866 - recall: 0.4964 - precision: 0.2916 - f1_score: 0.3653 - val_loss: 0.1706 - val_recall: 0.5150 - val_precision: 0.3050 - val_f1_score: 0.3817\n",
      "Epoch 2/10\n",
      "21221/21221 [==============================] - 842s 40ms/step - loss: 0.1595 - recall: 0.5241 - precision: 0.3239 - f1_score: 0.3988 - val_loss: 0.1557 - val_recall: 0.5221 - val_precision: 0.3496 - val_f1_score: 0.4174\n",
      "Epoch 3/10\n",
      "21221/21221 [==============================] - 845s 40ms/step - loss: 0.1403 - recall: 0.5577 - precision: 0.3633 - f1_score: 0.4386 - val_loss: 0.1419 - val_recall: 0.5501 - val_precision: 0.3847 - val_f1_score: 0.4514\n",
      "Epoch 4/10\n",
      "21221/21221 [==============================] - 864s 41ms/step - loss: 0.1241 - recall: 0.6010 - precision: 0.3932 - f1_score: 0.4741 - val_loss: 0.1339 - val_recall: 0.5656 - val_precision: 0.4190 - val_f1_score: 0.4801\n",
      "Epoch 5/10\n",
      "21221/21221 [==============================] - 861s 41ms/step - loss: 0.1120 - recall: 0.6392 - precision: 0.4162 - f1_score: 0.5030 - val_loss: 0.1254 - val_recall: 0.6134 - val_precision: 0.4064 - val_f1_score: 0.4877\n",
      "Epoch 6/10\n",
      "21221/21221 [==============================] - 861s 41ms/step - loss: 0.1029 - recall: 0.6717 - precision: 0.4360 - f1_score: 0.5277 - val_loss: 0.1202 - val_recall: 0.6226 - val_precision: 0.4364 - val_f1_score: 0.5119\n",
      "Epoch 7/10\n",
      "21221/21221 [==============================] - 860s 41ms/step - loss: 0.0957 - recall: 0.6983 - precision: 0.4534 - f1_score: 0.5488 - val_loss: 0.1181 - val_recall: 0.6217 - val_precision: 0.4673 - val_f1_score: 0.5323\n",
      "Epoch 8/10\n",
      "21221/21221 [==============================] - 860s 41ms/step - loss: 0.0898 - recall: 0.7203 - precision: 0.4691 - f1_score: 0.5673 - val_loss: 0.1135 - val_recall: 0.6502 - val_precision: 0.4611 - val_f1_score: 0.5384\n",
      "Epoch 9/10\n",
      "21221/21221 [==============================] - 857s 40ms/step - loss: 0.0851 - recall: 0.7386 - precision: 0.4830 - f1_score: 0.5832 - val_loss: 0.1118 - val_recall: 0.6518 - val_precision: 0.4777 - val_f1_score: 0.5501\n",
      "Epoch 10/10\n",
      "21221/21221 [==============================] - 858s 40ms/step - loss: 0.0811 - recall: 0.7534 - precision: 0.4954 - f1_score: 0.5969 - val_loss: 0.1086 - val_recall: 0.6703 - val_precision: 0.4793 - val_f1_score: 0.5578\n",
      "Evaluating model...\n",
      "712/712 [==============================] - 11s 13ms/step\n",
      "Computing Metrics...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5ba0c9b7114a5c94a896291e99ab09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3863.9253835425384 5453.02722688809\n",
      "Fscore: 0.020321429158688863, Precision: 0.010265014461439965, Recall: 1.0 S: 5453.027226886547, RU: 0.0, MI: 5453.027226886547 threshold: 0.0\n",
      "1010.9072524407252 1469.3720851434061\n",
      "Fscore: 0.07359234148463184, Precision: 0.03834332206199451, Recall: 0.9119259425211628 S: 1469.3806659782347, RU: 5.021648246769696, MI: 1469.3720851436938 threshold: 0.01\n",
      "683.489539748954 938.0029561972534\n",
      "Fscore: 0.10063919405660683, Precision: 0.05340288693218167, Recall: 0.8715404111677516 S: 938.0306728729895, RU: 7.21092337409446, MI: 938.0029561971787 threshold: 0.02\n",
      "530.850069735007 697.6062138363592\n",
      "Fscore: 0.12119055591594272, Precision: 0.0652872204727614, Recall: 0.8431683165724713 S: 697.6616629589944, RU: 8.795816040528123, MI: 697.606213836209 threshold: 0.03\n",
      "438.4470013947001 556.8650377964091\n",
      "Fscore: 0.13881419937042166, Precision: 0.0758259744795331, Recall: 0.8199039766415759 S: 556.9558423020036, RU: 10.056836201262348, MI: 556.8650377963725 threshold: 0.04\n",
      "375.2440725244073 463.54516480028946\n",
      "Fscore: 0.15451966343069337, Precision: 0.08551830429089272, Recall: 0.8000425911276138 S: 463.6775140024922, RU: 11.07777873920103, MI: 463.54516480029935 threshold: 0.05\n",
      "328.06694560669456 395.26642308288683\n",
      "Fscore: 0.16918449691143458, Precision: 0.09482145537901233, Recall: 0.7841429127890142 S: 395.44418444920666, RU: 11.855707398623304, MI: 395.2664230829333 threshold: 0.06\n",
      "291.6513249651325 343.75835846989867\n",
      "Fscore: 0.1823549217643031, Precision: 0.103445263963548, Recall: 0.7688317497354716 S: 343.99442812848287, RU: 12.741960817653977, MI: 343.7583584699627 threshold: 0.07\n",
      "262.2712691771269 303.2935356979161\n",
      "Fscore: 0.19501750114253266, Precision: 0.11195467929620967, Recall: 0.7556842558644865 S: 303.5901675109637, RU: 13.41719095639813, MI: 303.2935356979679 threshold: 0.08\n",
      "238.2071129707113 270.87426956349793\n",
      "Fscore: 0.20637590469229833, Precision: 0.11984516704262525, Recall: 0.7424156805955627 S: 271.2406852298119, RU: 14.093949494570078, MI: 270.874269563542 threshold: 0.09\n",
      "217.952580195258 244.0111678005511\n",
      "Fscore: 0.21742163960847397, Precision: 0.12769927945085952, Recall: 0.7310910740452052 S: 244.4499625131051, RU: 14.640155779626635, MI: 244.01116780058808 threshold: 0.1\n",
      "200.67921896792188 221.68737366445063\n",
      "Fscore: 0.22807181904866514, Precision: 0.13548600377674117, Recall: 0.7202891272500094 S: 222.2058076907918, RU: 15.17001414838486, MI: 221.6873736644804 threshold: 0.11\n",
      "185.82008368200837 202.4532207738486\n",
      "Fscore: 0.23760232508345897, Precision: 0.1427546253555126, Recall: 0.7080151868766671 S: 203.06691994023643, RU: 15.775530808787941, MI: 202.453220773875 threshold: 0.12\n",
      "172.91352859135287 186.15380573365817\n",
      "Fscore: 0.2468443332645818, Precision: 0.14992249065927954, Recall: 0.6982465046552995 S: 186.86181635197508, RU: 16.251123691219377, MI: 186.15380573367807 threshold: 0.13\n",
      "161.44211994421198 171.8149301890171\n",
      "Fscore: 0.2554304177785326, Precision: 0.15682597246475746, Recall: 0.6880294218548645 S: 172.62566461480452, RU: 16.710770414346744, MI: 171.81493018903208 threshold: 0.14\n",
      "151.17921896792188 159.1117091154826\n",
      "Fscore: 0.2636816143167942, Precision: 0.16362234155729477, Recall: 0.6787621173132822 S: 160.03365066952827, RU: 17.15323202672217, MI: 159.11170911549544 threshold: 0.15\n",
      "142.00767085076708 147.85283624624148\n",
      "Fscore: 0.27176775319013846, Precision: 0.1705103955525828, Recall: 0.6691291601062329 S: 148.89679902294498, RU: 17.60101057378968, MI: 147.85283624625066 threshold: 0.16\n",
      "133.6910739191074 137.74593055271558\n",
      "Fscore: 0.2796999968588273, Precision: 0.17744115723361714, Recall: 0.6601324979016034 S: 138.9195160001916, RU: 18.019171509588393, MI: 137.74593055272277 threshold: 0.17\n",
      "126.00139470013947 128.43106856188433\n",
      "Fscore: 0.2873047900543903, Precision: 0.18429825960815452, Recall: 0.6513549819889273 S: 129.7448940514379, RU: 18.417333153049317, MI: 128.43106856188825 threshold: 0.18\n",
      "118.97838214783822 120.12961617406114\n",
      "Fscore: 0.29472825275020653, Precision: 0.19119042815251217, Recall: 0.6428699039922197 S: 121.5927683159347, RU: 18.80629215460671, MI: 120.12961617406489 threshold: 0.19\n",
      "112.48884239888424 112.41835142707893\n",
      "Fscore: 0.3019009907140333, Precision: 0.19804038132239618, Recall: 0.6348347006677075 S: 114.03291011181079, RU: 19.12116238584271, MI: 112.41835142708042 threshold: 0.2\n",
      "106.47907949790795 105.35172553461676\n",
      "Fscore: 0.3088499366620101, Precision: 0.2049201006727687, Recall: 0.6266897142203516 S: 107.13650321932703, RU: 19.47419443633639, MI: 105.35172553461398 threshold: 0.21\n",
      "100.94839609483961 98.92594493106368\n",
      "Fscore: 0.31534112886103605, Precision: 0.21154457851688555, Recall: 0.6191176518516277 S: 100.89530051482626, RU: 19.837315480535747, MI: 98.9259449310584 threshold: 0.22\n",
      "95.89818688981869 93.12592788901387\n",
      "Fscore: 0.3219566010361844, Precision: 0.21843541756674983, Recall: 0.611993154182746 S: 95.2834323354906, RU: 20.161697161780804, MI: 93.12592788900766 threshold: 0.23\n",
      "91.18270571827057 87.7941978076257\n",
      "Fscore: 0.32793765117432633, Precision: 0.2250112493907876, Recall: 0.6044129313278852 S: 90.1584329031075, RU: 20.51150542648762, MI: 87.79419780761884 threshold: 0.24\n",
      "86.83054393305439 82.99777397572724\n",
      "Fscore: 0.3339830618484542, Precision: 0.23174779269235551, Recall: 0.5976243475662473 S: 85.5594947585549, RU: 20.779717476768095, MI: 82.99777397572107 threshold: 0.25\n",
      "82.61715481171548 78.29045851897241\n",
      "Fscore: 0.3401531430662769, Precision: 0.23884571151745324, Recall: 0.5907018722285432 S: 81.07769458293828, RU: 21.075973613906374, MI: 78.29045851896731 threshold: 0.26\n",
      "78.78521617852162 74.03929354578008\n",
      "Fscore: 0.34572167355280703, Precision: 0.24557196792875433, Recall: 0.5838139937067965 S: 77.06645503117745, RU: 21.387414577618724, MI: 74.0392935457758 threshold: 0.27\n",
      "75.23779637377963 70.12621676870768\n",
      "Fscore: 0.35133073605009785, Precision: 0.2524954342137841, Recall: 0.5773091912591918 S: 73.3997124398142, RU: 21.67559706112215, MI: 70.12621676870418 threshold: 0.28\n",
      "71.8207810320781 66.47066060085659\n",
      "Fscore: 0.35624570267634703, Precision: 0.25899847640296764, Recall: 0.5704258492243987 S: 70.00474571541596, RU: 21.96168713842688, MI: 66.47066060085385 threshold: 0.29\n",
      "68.60529986052998 62.97268855238093\n",
      "Fscore: 0.3612276654195174, Precision: 0.26568635112558125, Recall: 0.5640673518198911 S: 66.7836786765935, RU: 22.237361220782418, MI: 62.97268855237904 threshold: 0.3\n",
      "65.68828451882845 59.89187779374153\n",
      "Fscore: 0.36571167726746306, Precision: 0.27222188035779216, Recall: 0.5570053150723082 S: 63.9819869119931, RU: 22.50905647836317, MI: 59.89187779374022 threshold: 0.31\n",
      "62.79637377963738 56.783964620945255\n",
      "Fscore: 0.37068290565778206, Precision: 0.2793890650738226, Recall: 0.550597447284777 S: 61.17525544655336, RU: 22.759464863619982, MI: 56.783964620944744 threshold: 0.32\n",
      "60.108089260808924 54.03393349837903\n",
      "Fscore: 0.3749411778169266, Precision: 0.2861430164797278, Recall: 0.5436513637282883 S: 58.72326551828904, RU: 22.994693818884688, MI: 54.03393349837879 threshold: 0.33\n",
      "57.67015341701534 51.433805806007\n",
      "Fscore: 0.3781043111468685, Precision: 0.2918556456806606, Recall: 0.5367127018222398 S: 56.456681599932544, RU: 23.279186360052257, MI: 51.433805806007776 threshold: 0.34\n",
      "55.30264993026499 49.05711484133301\n",
      "Fscore: 0.38127151226553796, Precision: 0.29781211688990733, Recall: 0.5297216446587241 S: 54.4210214615626, RU: 23.559436758207887, MI: 49.05711484133429 threshold: 0.35\n",
      "52.99302649930265 46.67142747765906\n",
      "Fscore: 0.3849356625786883, Precision: 0.304482175708677, Recall: 0.5231742803004399 S: 52.39212020416236, RU: 23.805716050663868, MI: 46.67142747766092 threshold: 0.36\n",
      "50.75523012552301 44.44010176704061\n",
      "Fscore: 0.3883925630764472, Precision: 0.31119539650395467, Recall: 0.5165251792766286 S: 50.527080292938756, RU: 24.04294486671639, MI: 44.44010176704275 threshold: 0.37\n",
      "48.71757322175732 42.343593446507334\n",
      "Fscore: 0.3911998526695276, Precision: 0.317460270339686, Recall: 0.5095603988295702 S: 48.82307652615213, RU: 24.304585894748545, MI: 42.34359344650968 threshold: 0.38\n",
      "46.7510460251046 40.30576701573704\n",
      "Fscore: 0.39380412740351284, Precision: 0.3236176845153292, Recall: 0.5028660990833971 S: 47.199779607826336, RU: 24.561440110472592, MI: 40.305767015739164 threshold: 0.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.92747559274756 38.445747015166205\n",
      "Fscore: 0.39586031179574316, Precision: 0.3295688215494787, Recall: 0.49553531939473716 S: 45.76318361462718, RU: 24.82324537589196, MI: 38.44574701516853 threshold: 0.4\n",
      "43.08716875871688 36.62179021266202\n",
      "Fscore: 0.39854733108913326, Precision: 0.3358700886019878, Recall: 0.489984014254612 S: 44.36855497626184, RU: 25.04821654931109, MI: 36.621790212664195 threshold: 0.41\n",
      "41.43793584379358 35.07188326353863\n",
      "Fscore: 0.40067755071611105, Precision: 0.3417729833343446, Recall: 0.48411471249692656 S: 43.214050740971025, RU: 25.247122326946243, MI: 35.07188326354077 threshold: 0.42\n",
      "39.735006973500695 33.41026005521905\n",
      "Fscore: 0.40332728758352937, Precision: 0.3487873034354531, Recall: 0.4780857048379902 S: 42.01273148231956, RU: 25.472026414244592, MI: 33.41026005522122 threshold: 0.43\n",
      "38.14644351464435 31.902546116842426\n",
      "Fscore: 0.40524379206558075, Precision: 0.35494559632010736, Recall: 0.47215075250412536 S: 40.97181113696764, RU: 25.708303310525217, MI: 31.902546116844395 threshold: 0.44\n",
      "36.60739191073919 30.417701568381805\n",
      "Fscore: 0.4073003200595463, Precision: 0.36182910263150675, Recall: 0.46584300945711316 S: 39.96713515348874, RU: 25.9255727742703, MI: 30.417701568383663 threshold: 0.45\n",
      "35.21757322175732 29.073525116726653\n",
      "Fscore: 0.4086154021806887, Precision: 0.36767930568194485, Recall: 0.45980887480512805 S: 39.09433201884867, RU: 26.136123149521246, MI: 29.07352511672838 threshold: 0.46\n",
      "33.81241283124128 27.78751000114971\n",
      "Fscore: 0.40962039739570727, Precision: 0.3738080912842229, Recall: 0.4530216813896656 S: 38.30624571380218, RU: 26.367076982898762, MI: 27.7875100011512 threshold: 0.47\n",
      "32.42677824267783 26.435761745850986\n",
      "Fscore: 0.411649078733844, Precision: 0.3809521003466921, Recall: 0.44772673208060504 S: 37.48311962811658, RU: 26.573196231771355, MI: 26.43576174585236 threshold: 0.48\n",
      "31.12691771269177 25.24727813403492\n",
      "Fscore: 0.4134102676222247, Precision: 0.38794164581331836, Recall: 0.442457918235422 S: 36.803311947341136, RU: 26.777952070984067, MI: 25.247278134036215 threshold: 0.49\n",
      "29.89121338912134 24.107607593406016\n",
      "Fscore: 0.41458642879819735, Precision: 0.395042863159267, Recall: 0.43616435753929833 S: 36.18983984124997, RU: 26.991253469552262, MI: 24.107607593407245 threshold: 0.5\n",
      "28.69804741980474 23.02234884847442\n",
      "Fscore: 0.4150419498811716, Precision: 0.4011784575261731, Recall: 0.429897897666815 S: 35.637420233127145, RU: 27.202889081338466, MI: 23.022348848475403 threshold: 0.51\n",
      "27.532775453277544 21.941638355793195\n",
      "Fscore: 0.4158752844894627, Precision: 0.40816217513262243, Recall: 0.42388552055246875 S: 35.107557282260615, RU: 27.40629644061294, MI: 21.94163835579414 threshold: 0.52\n",
      "26.48326359832636 20.936938399961576\n",
      "Fscore: 0.41623209691181495, Precision: 0.41431142886312844, Recall: 0.41817065559290045 S: 34.6486663011445, RU: 27.60751142142739, MI: 20.936938399962465 threshold: 0.53\n",
      "25.45397489539749 19.975892812158836\n",
      "Fscore: 0.4170695227555737, Precision: 0.42168330758656347, Recall: 0.4125556072919585 S: 34.23884839597604, RU: 27.807596908753933, MI: 19.975892812159607 threshold: 0.54\n",
      "24.464435146443513 19.08123316490403\n",
      "Fscore: 0.41771441490386824, Precision: 0.42852030159051974, Recall: 0.40744010220574967 S: 33.88029410256611, RU: 27.996086679800783, MI: 19.081233164904653 threshold: 0.55\n",
      "23.474198047419804 18.210887366603213\n",
      "Fscore: 0.4183417502488922, Precision: 0.43561232065489086, Recall: 0.4023883971987969 S: 33.53931764697566, RU: 28.164683728840302, MI: 18.210887366603835 threshold: 0.56\n",
      "22.53207810320781 17.3231613237204\n",
      "Fscore: 0.41816026577596754, Precision: 0.4425156074254776, Recall: 0.39634602319479595 S: 33.235349621960246, RU: 28.3636483239775, MI: 17.323161323720957 threshold: 0.57\n",
      "21.619246861924687 16.490163241226025\n",
      "Fscore: 0.417506310083563, Precision: 0.44863277612643837, Recall: 0.3904187735835034 S: 32.99229631154178, RU: 28.575621291343307, MI: 16.490163241226576 threshold: 0.58\n",
      "20.676429567642955 15.678740213225383\n",
      "Fscore: 0.417003616847137, Precision: 0.45587599664402917, Recall: 0.3842396427895176 S: 32.77284993792672, RU: 28.779103502021037, MI: 15.67874021322581 threshold: 0.59\n",
      "19.841701534170152 14.946333346787354\n",
      "Fscore: 0.4170543821261751, Precision: 0.46368611492926737, Recall: 0.3789448615634803 S: 32.58860590626444, RU: 28.959011626789266, MI: 14.946333346787698 threshold: 0.6\n",
      "19.01115760111576 14.24228045810867\n",
      "Fscore: 0.4166575215786987, Precision: 0.4717084858209702, Recall: 0.3731131707009904 S: 32.45241260038011, RU: 29.16018742974533, MI: 14.24228045810895 threshold: 0.61\n",
      "18.250348675034868 13.552930384112663\n",
      "Fscore: 0.4149797533282332, Precision: 0.47798394081494405, Recall: 0.366650666581061 S: 32.3265009301674, RU: 29.348266394993477, MI: 13.55293038411289 threshold: 0.62\n",
      "17.49860529986053 12.898792744799751\n",
      "Fscore: 0.4136536316977203, Precision: 0.48481806192278926, Recall: 0.360706955451537 S: 32.24588094444451, RU: 29.553645859859444, MI: 12.898792744799886 threshold: 0.63\n",
      "16.744769874476987 12.25903325834246\n",
      "Fscore: 0.41151592198607023, Precision: 0.49135370444723064, Recall: 0.3539966497072503 S: 32.19088608870001, RU: 29.76523560710568, MI: 12.259033258342525 threshold: 0.64\n",
      "16.04463040446304 11.67713275890035\n",
      "Fscore: 0.4105176611261583, Precision: 0.49891243145214603, Recall: 0.34873123272864515 S: 32.15118454399074, RU: 29.955687909189557, MI: 11.677132758900337 threshold: 0.65\n",
      "15.348675034867503 11.089542988627453\n",
      "Fscore: 0.4093720061930878, Precision: 0.5071328870353269, Recall: 0.3432106898713577 S: 32.0953816589768, RU: 30.118691208928205, MI: 11.089542988627388 threshold: 0.66\n",
      "14.675034867503486 10.53829012248138\n",
      "Fscore: 0.406850941812539, Precision: 0.514228931063805, Recall: 0.33657045646229405 S: 32.09269967928661, RU: 30.31312939963963, MI: 10.538290122481275 threshold: 0.67\n",
      "14.05857740585774 10.008903574810093\n",
      "Fscore: 0.4053294777972163, Precision: 0.5216838620447161, Recall: 0.3314124954211221 S: 32.09935684816143, RU: 30.499025546659087, MI: 10.008903574809992 threshold: 0.68\n",
      "13.44979079497908 9.49333614212419\n",
      "Fscore: 0.40307725234299147, Precision: 0.5290748996684773, Recall: 0.325548762225841 S: 32.11384616100575, RU: 30.678586736441844, MI: 9.493336142124049 threshold: 0.69\n",
      "12.854951185495118 8.992687795906281\n",
      "Fscore: 0.4005389958718499, Precision: 0.5364294220239655, Recall: 0.3195813757938077 S: 32.16145428941665, RU: 30.878644857175928, MI: 8.992687795906154 threshold: 0.7\n",
      "12.283821478382148 8.534341578131611\n",
      "Fscore: 0.398312309163657, Precision: 0.5446077544038275, Recall: 0.3139715843793991 S: 32.21023968084124, RU: 31.059049472336007, MI: 8.534341578131485 threshold: 0.71\n",
      "11.709205020920502 8.012329450888851\n",
      "Fscore: 0.39601637515979443, Precision: 0.5527785105608015, Recall: 0.30852262412927595 S: 32.2607172950105, RU: 31.2499033143946, MI: 8.012329450888748 threshold: 0.72\n",
      "11.161087866108787 7.556946887749003\n",
      "Fscore: 0.39299105978954335, Precision: 0.5607343570745871, Recall: 0.30249876290421157 S: 32.34703459934113, RU: 31.451918877974897, MI: 7.556946887748924 threshold: 0.73\n",
      "10.649232914923292 7.13149760581094\n",
      "Fscore: 0.38968299384263316, Precision: 0.5681126746792775, Recall: 0.2965455962052848 S: 32.43045179273053, RU: 31.636623482586327, MI: 7.131497605810881 threshold: 0.74\n",
      "10.175732217573222 6.762644994601492\n",
      "Fscore: 0.3864774195635073, Precision: 0.5751510979235189, Recall: 0.29101296408076793 S: 32.53417449053104, RU: 31.82356269271737, MI: 6.7626449946014375 threshold: 0.75\n",
      "9.649930264993026 6.354296681685063\n",
      "Fscore: 0.382378417789824, Precision: 0.583962173976811, Recall: 0.2842539481909081 S: 32.625860801784306, RU: 32.00108914925448, MI: 6.35429668168497 threshold: 0.76\n",
      "9.152719665271967 5.972023986398229\n",
      "Fscore: 0.37851942735302974, Precision: 0.5920700597687026, Recall: 0.2781830483634515 S: 32.738681055162175, RU: 32.18937971967649, MI: 5.972023986398128 threshold: 0.77\n",
      "8.698047419804743 5.612856759660017\n",
      "Fscore: 0.3737161155412234, Precision: 0.5988168896602917, Recall: 0.27161393882222984 S: 32.835550805397844, RU: 32.352267860065126, MI: 5.612856759659908 threshold: 0.78\n",
      "8.269177126917713 5.259037250409894\n",
      "Fscore: 0.3698252653560158, Precision: 0.6064663693150624, Recall: 0.2660237194796195 S: 32.97133079853809, RU: 32.54921169284179, MI: 5.259037250409805 threshold: 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.860529986052999 4.939848844323051\n",
      "Fscore: 0.3651442698090721, Precision: 0.6127210241991824, Recall: 0.2600629416302224 S: 33.09502132115844, RU: 32.72427737388822, MI: 4.939848844322979 threshold: 0.8\n",
      "7.455369595536959 4.661502733942053\n",
      "Fscore: 0.3602732040632611, Precision: 0.6211049965967232, Recall: 0.25372281771383426 S: 33.251574307455, RU: 32.92320741036105, MI: 4.661502733941993 threshold: 0.81\n",
      "7.032078103207811 4.366895950783899\n",
      "Fscore: 0.35494370786213547, Precision: 0.6307226541261187, Recall: 0.24696154688732108 S: 33.41332230129704, RU: 33.12673130517682, MI: 4.366895950783854 threshold: 0.82\n",
      "6.617852161785216 4.05861304530284\n",
      "Fscore: 0.3508031501963824, Precision: 0.6418773575963805, Recall: 0.24135507944125073 S: 33.550723381317056, RU: 33.30433454609404, MI: 4.058613045302805 threshold: 0.83\n",
      "6.182008368200837 3.7402945788647006\n",
      "Fscore: 0.3449114939834101, Precision: 0.6523811128518462, Recall: 0.23442576730343417 S: 33.70933157550935, RU: 33.50118254227674, MI: 3.7402945788646704 threshold: 0.84\n",
      "5.7698744769874475 3.462460407941272\n",
      "Fscore: 0.33882066509734143, Precision: 0.6610727269214135, Recall: 0.22778343796151435 S: 33.881503097628716, RU: 33.70411874056439, MI: 3.4624604079412364 threshold: 0.85\n",
      "5.344490934449094 3.153108757794505\n",
      "Fscore: 0.332302265836673, Precision: 0.671785557597686, Recall: 0.22074828378984476 S: 34.05388455395584, RU: 33.90759440561468, MI: 3.1531087577944765 threshold: 0.86\n",
      "4.968619246861925 2.8941240588368617\n",
      "Fscore: 0.3267131525046517, Precision: 0.682673021990399, Recall: 0.21474214515522405 S: 34.23618042745682, RU: 34.11363504807776, MI: 2.894124058836843 threshold: 0.87\n",
      "4.5948396094839605 2.6414031177435913\n",
      "Fscore: 0.3187092669120187, Precision: 0.6923770637266088, Recall: 0.2069959666565791 S: 34.43530875790735, RU: 34.333853247516295, MI: 2.6414031177435753 threshold: 0.88\n",
      "4.2196652719665275 2.4276981751646227\n",
      "Fscore: 0.31025416433530706, Precision: 0.703978593881152, Recall: 0.19897211330680728 S: 34.66134957468775, RU: 34.576226455601095, MI: 2.427698175164608 threshold: 0.89\n",
      "3.836122733612273 2.1674561993488237\n",
      "Fscore: 0.30032919172007805, Precision: 0.7165591810180748, Recall: 0.18997678058196232 S: 34.863382680387915, RU: 34.795942084431, MI: 2.167456199348813 threshold: 0.9\n",
      "3.4776847977684797 1.9323323810815392\n",
      "Fscore: 0.2902777684784377, Precision: 0.728472932153593, Recall: 0.18125077551921745 S: 35.08898034670841, RU: 35.03573366351435, MI: 1.9323323810815318 threshold: 0.91\n",
      "3.116457461645746 1.7092539762861367\n",
      "Fscore: 0.27885137049476805, Precision: 0.7438748143452428, Recall: 0.1715864094024773 S: 35.3284497095295, RU: 35.28707709237626, MI: 1.7092539762861345 threshold: 0.92\n",
      "2.715481171548117 1.4677491614087672\n",
      "Fscore: 0.2661293191226843, Precision: 0.7628700135131272, Recall: 0.16117843076553454 S: 35.57746830785708, RU: 35.547179404219385, MI: 1.4677491614087683 threshold: 0.93\n",
      "2.297071129707113 1.2212507691737327\n",
      "Fscore: 0.2515230342579389, Precision: 0.7860987751458326, Recall: 0.1497128525996937 S: 35.84683539255082, RU: 35.826026213067884, MI: 1.2212507691737338 threshold: 0.94\n",
      "1.9253835425383543 1.0073088472107283\n",
      "Fscore: 0.23520496087762233, Precision: 0.8098801463160918, Recall: 0.13758050961274765 S: 36.11933514583816, RU: 36.10528632020124, MI: 1.0073088472107303 threshold: 0.95\n",
      "1.5111576011157601 0.7651903824309089\n",
      "Fscore: 0.21567670723263568, Precision: 0.8417088387283586, Recall: 0.12368462451369912 S: 36.393999350783055, RU: 36.385954328881255, MI: 0.7651903824309098 threshold: 0.96\n",
      "1.0781032078103208 0.5283352975954004\n",
      "Fscore: 0.18908557677848825, Precision: 0.8865267741225457, Recall: 0.10582879795184576 S: 36.74469010352942, RU: 36.74089155991901, MI: 0.528335297595401 threshold: 0.97\n",
      "0.6701534170153417 0.3232642616402161\n",
      "Fscore: 0.15922916053637412, Precision: 0.9351925268516786, Recall: 0.0870230009931374 S: 37.12437755042662, RU: 37.12297009566673, MI: 0.3232642616402167 threshold: 0.98\n",
      "0.3089260808926081 0.14000708483604304\n",
      "Fscore: 0.13169072612713106, Precision: 0.9699877255416571, Recall: 0.07064063869371034 S: 37.51484341071392, RU: 37.514582153431775, MI: 0.14000708483604288 threshold: 0.99\n",
      "0.0 0.0\n",
      "Fscore: 0.005517998280883335, Precision: 1.0, Recall: 0.0027666322765144895 S: 37.79770169216264, RU: 37.79770169216264, MI: 0.0 threshold: 1.0\n",
      "\n",
      "Final Results (Maximal F1-score):\n",
      "Fmax: 0.418, Smin: 32.093, threshold: 0.56\n",
      "AUPR: 0.391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recs = []\n",
    "precs = []\n",
    "f1s = []\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "#     print('Splitting into train-test...')\n",
    "#     X_train_ng, y_train, X_test_ng, y_test, start_index, prev_index1 = train_test_split(X_ng,y,i,prev_index,Kfolds)\n",
    "#     X_train_sg, _, X_test_sg, _, _, _= train_test_split(X_sg,y,i,prev_index,Kfolds)\n",
    "    \n",
    "#     prev_index = prev_index1\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    X_train_ng, X_test_ng, vocab_size_ng, tokenizer1 = tokenization(X_train_ng, X_test_ng, MAX_LEN_NG)  \n",
    "    X_train_sg, X_test_sg, vocab_size_sg, tokenizer2 = tokenization(X_train_sg, X_test_sg, MAX_LEN_SG)\n",
    "    \n",
    "   \n",
    "    print('Shuffling...')   \n",
    "    shuffled = [[X_train_ng[i],X_train_sg[i],y_train[i]] for i in range(len(X_train_ng))]\n",
    "    np.random.shuffle(shuffled)\n",
    "\n",
    "    X_train_ng = [shuffled[i][0] for i in range(len(shuffled))]\n",
    "    X_train_sg = [shuffled[i][1] for i in range(len(shuffled))]\n",
    "    y_train = [shuffled[i][2] for i in range(len(shuffled))]\n",
    "    X_train_ng = np.array(X_train_ng)\n",
    "    X_train_sg = np.array(X_train_sg)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    model = get_model_ng_sg(vocab_size_ng, vocab_size_sg)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=custom_loss, \n",
    "        optimizer='adam', \n",
    "        metrics=[\n",
    "            recall,\n",
    "            precision,\n",
    "            f1_score\n",
    "        ])\n",
    "\n",
    "    print('Training...')\n",
    "    history = model.fit([X_train_ng,X_train_sg], y_train, batch_size=32, epochs=10,validation_split=0.2)\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    predictions = model.predict([X_test_ng,X_test_sg])\n",
    "    \n",
    "    print('Computing Metrics...\\n')\n",
    "    compute_metrics(predictions)\n",
    "    \n",
    "#     recs.append(rec.numpy())\n",
    "#     precs.append(prec.numpy())\n",
    "#     f1s.append(f1.numpy())\n",
    "\n",
    "# print('Recall:',sum(recs)/len(recs))\n",
    "# print('Precision:',sum(precs)/len(precs))\n",
    "# print('F1-Score:',sum(f1s)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3d5d51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d734cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb50bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bp_predictions',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab990bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35365\n"
     ]
    }
   ],
   "source": [
    "predictions = np.load('bp_predictions.npy')\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2506bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
